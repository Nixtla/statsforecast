{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Time Series Generation for Benchmarking\n",
    "\n",
    "This tutorial introduces `TimeSeriesSimulator`, a tool for generating synthetic time series data with customizable statistical distributions. This is invaluable for systematically testing how forecasting models perform on data with specific, known characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Synthetic Data?\n",
    "\n",
    "When developing forecasting solutions, you often need to answer questions like:\n",
    "\n",
    "- **\"How does my model handle sudden demand spikes?\"** (e.g., from promotions or viral events)\n",
    "- **\"Which model is most robust to heavy-tailed distributions?\"** (e.g., insurance claims, website traffic)\n",
    "- **\"How do different models behave with multiple seasonalities?\"** (e.g., daily + weekly + yearly patterns)\n",
    "\n",
    "Real-world data is messy, expensive to obtain, and you can't control its characteristics. With synthetic data:\n",
    "\n",
    "1. **You know the ground truth** - You designed the data generation process\n",
    "2. **You can isolate specific behaviors** - Test one characteristic at a time\n",
    "3. **You can generate unlimited samples** - No data scarcity issues\n",
    "4. **Reproducibility** - Same seed = same data, every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'  # Required for evaluate compatibility\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For development - direct import\n",
    "import sys\n",
    "sys.path.insert(0, '../../../python')\n",
    "\n",
    "from statsforecast.synthetic import TimeSeriesSimulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage: Built-in Distributions\n",
    "\n",
    "`TimeSeriesSimulator` comes with 7 built-in distributions:\n",
    "- `normal`, `poisson`, `exponential`, `gamma`, `uniform`, `binomial`, `lognormal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate normally distributed time series\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=100,\n",
    "    distribution=\"normal\",\n",
    "    dist_params={\"loc\": 100, \"scale\": 15},\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate(n_series=3)\n",
    "print(f\"Generated {df['unique_id'].nunique()} series with {len(df)} total rows\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "for uid in df['unique_id'].unique():\n",
    "    subset = df[df['unique_id'] == uid]\n",
    "    ax.plot(subset['ds'], subset['y'], label=f'Series {uid}', alpha=0.7)\n",
    "ax.set_title('Normal Distribution (loc=100, scale=15)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Trend and Seasonality\n",
    "\n",
    "Real time series often have trend and seasonal components. `TimeSeriesSimulator` supports:\n",
    "\n",
    "**Trends:** `linear`, `quadratic`, `exponential`, or custom callable\n",
    "\n",
    "**Seasonality:** Single or multiple periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma distribution with linear trend and weekly seasonality\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=180,  # ~6 months\n",
    "    distribution=\"gamma\",\n",
    "    dist_params={\"shape\": 5, \"scale\": 10},  # mean = 50\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.2, \"intercept\": 0},\n",
    "    seasonality=7,  # weekly\n",
    "    seasonality_strength=15.0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(df['ds'], df['y'])\n",
    "ax.set_title('Gamma + Linear Trend + Weekly Seasonality')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple seasonalities (weekly + monthly)\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=365,\n",
    "    distribution=\"normal\",\n",
    "    dist_params={\"loc\": 100, \"scale\": 5},\n",
    "    seasonality=[7, 30],  # weekly and monthly\n",
    "    seasonality_strength=[10.0, 20.0],\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(df['ds'], df['y'])\n",
    "ax.set_title('Multiple Seasonalities: Weekly (amplitude=10) + Monthly (amplitude=20)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Key Feature: Custom Distributions\n",
    "\n",
    "**This is why `TimeSeriesSimulator` exists.**\n",
    "\n",
    "Built-in distributions are useful, but real-world data often has complex patterns that don't fit standard distributions. The `distribution` parameter accepts any callable with signature:\n",
    "\n",
    "```python\n",
    "def my_distribution(size: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    # Generate `size` values using `rng` for reproducibility\n",
    "    return values\n",
    "```\n",
    "\n",
    "This gives you **complete control** over the data generation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Demand with Promotional Spikes\n",
    "\n",
    "In retail forecasting, demand usually follows a gamma-like distribution, but promotional events cause sudden spikes. How do different models handle this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_with_spikes(size, rng):\n",
    "    \"\"\"Simulate retail demand with random promotional spikes.\"\"\"\n",
    "    # Base demand follows gamma distribution\n",
    "    base_demand = rng.gamma(shape=5, scale=10, size=size)\n",
    "    \n",
    "    # 5% of days have promotional spikes\n",
    "    spike_mask = rng.random(size) < 0.05\n",
    "    spike_multiplier = rng.uniform(2.5, 5.0, size=size)\n",
    "    \n",
    "    demand = base_demand.copy()\n",
    "    demand[spike_mask] *= spike_multiplier[spike_mask]\n",
    "    \n",
    "    return demand\n",
    "\n",
    "\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=365,\n",
    "    distribution=demand_with_spikes,\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.05},  # slight growth\n",
    "    seasonality=7,\n",
    "    seasonality_strength=10.0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate(n_series=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(df['ds'], df['y'], alpha=0.8)\n",
    "ax.axhline(df['y'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"y\"].mean():.1f}')\n",
    "ax.set_title('Retail Demand with Promotional Spikes')\n",
    "ax.set_ylabel('Demand')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Normal range: {df['y'].quantile(0.05):.1f} - {df['y'].quantile(0.95):.1f}\")\n",
    "print(f\"Max (spike): {df['y'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Bimodal Distribution (Two Customer Segments)\n",
    "\n",
    "Imagine you have two customer segments with different spending patterns - some spend ~$20, others spend ~$80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bimodal_spending(size, rng):\n",
    "    \"\"\"Two customer segments with different spending patterns.\"\"\"\n",
    "    # 60% low spenders, 40% high spenders\n",
    "    segment = rng.random(size) < 0.6\n",
    "    \n",
    "    values = np.zeros(size)\n",
    "    values[segment] = rng.normal(20, 5, size=segment.sum())  # Low spenders\n",
    "    values[~segment] = rng.normal(80, 10, size=(~segment).sum())  # High spenders\n",
    "    \n",
    "    return np.maximum(values, 0)  # No negative spending\n",
    "\n",
    "\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=200,\n",
    "    distribution=bimodal_spending,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(df['ds'], df['y'], alpha=0.7)\n",
    "axes[0].set_title('Bimodal Spending Over Time')\n",
    "axes[0].set_ylabel('Spending ($)')\n",
    "\n",
    "axes[1].hist(df['y'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Spending Distribution (Two Segments)')\n",
    "axes[1].set_xlabel('Spending ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Regime Changes (Market Conditions)\n",
    "\n",
    "Financial or economic data often has regime changes - periods of low volatility followed by high volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regime_switching(size, rng):\n",
    "    \"\"\"Alternating regimes of low and high volatility.\"\"\"\n",
    "    values = np.zeros(size)\n",
    "    regime_length = 50\n",
    "    \n",
    "    for i in range(0, size, regime_length):\n",
    "        end = min(i + regime_length, size)\n",
    "        segment_size = end - i\n",
    "        \n",
    "        # Alternate between calm and volatile regimes\n",
    "        if (i // regime_length) % 2 == 0:\n",
    "            # Calm regime: low volatility around 100\n",
    "            values[i:end] = rng.normal(100, 5, size=segment_size)\n",
    "        else:\n",
    "            # Volatile regime: high volatility around 100\n",
    "            values[i:end] = rng.normal(100, 25, size=segment_size)\n",
    "    \n",
    "    return values\n",
    "\n",
    "\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=300,\n",
    "    distribution=regime_switching,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(df['ds'], df['y'], alpha=0.8)\n",
    "\n",
    "# Shade the volatile regimes\n",
    "for i in range(1, 6, 2):\n",
    "    start_idx = i * 50\n",
    "    end_idx = min((i + 1) * 50, 300)\n",
    "    if start_idx < 300:\n",
    "        ax.axvspan(df['ds'].iloc[start_idx], df['ds'].iloc[min(end_idx-1, 299)], \n",
    "                   alpha=0.2, color='red', label='High volatility' if i == 1 else '')\n",
    "\n",
    "ax.set_title('Regime Switching: Alternating Calm and Volatile Periods')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Benchmarking with Cross-Validation\n",
    "\n",
    "Now let's see the real power: **comparing how different models perform on our custom distributions**.\n",
    "\n",
    "We'll use StatsForecast's `cross_validation` method and `utilsforecast.evaluation.evaluate` to benchmark models on spike-prone demand data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    SeasonalNaive,\n",
    "    AutoETS,\n",
    "    AutoARIMA,\n",
    "    MSTL,\n",
    ")\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mae, rmse, smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate Synthetic Data with Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate demand data with promotional spikes\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=200,  # 200 days of data\n",
    "    distribution=demand_with_spikes,\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.1},\n",
    "    seasonality=7,  # weekly pattern\n",
    "    seasonality_strength=10.0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate(n_series=10)  # 10 product series\n",
    "\n",
    "print(f\"Generated {df['unique_id'].nunique()} series\")\n",
    "print(f\"Total observations: {len(df)}\")\n",
    "print(f\"Date range: {df['ds'].min().date()} to {df['ds'].max().date()}\")\n",
    "\n",
    "# Visualize one series\n",
    "sample = df[df['unique_id'] == 0]\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "ax.plot(sample['ds'], sample['y'])\n",
    "ax.set_title('Sample Series: Demand with Promotional Spikes')\n",
    "ax.set_ylabel('Demand')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Models to Compare\n",
    "\n",
    "We'll compare several models to see which handles spikes best:\n",
    "- **SeasonalNaive**: Simple baseline\n",
    "- **AutoETS**: Exponential smoothing (automatic selection)\n",
    "- **AutoARIMA**: ARIMA with automatic order selection\n",
    "- **MSTL**: Multiple Seasonal-Trend decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StatsForecast with multiple models\n",
    "sf = StatsForecast(\n",
    "    models=[\n",
    "        SeasonalNaive(season_length=7),\n",
    "        AutoETS(season_length=7),\n",
    "        MSTL(season_length=7),\n",
    "    ],\n",
    "    freq='D',\n",
    "    n_jobs=-1,  # Use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run Cross-Validation\n",
    "\n",
    "Cross-validation evaluates model performance across multiple time windows, giving us robust error estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation\n",
    "# h=14: forecast 2 weeks ahead\n",
    "# n_windows=3: evaluate on 3 different time windows\n",
    "cv_results = sf.cross_validation(\n",
    "    df=df,\n",
    "    h=14,\n",
    "    n_windows=3,\n",
    "    step_size=14,\n",
    ")\n",
    "\n",
    "print(f\"Cross-validation results shape: {cv_results.shape}\")\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model column names (exclude metadata columns)\n",
    "model_cols = [c for c in cv_results.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']]\n",
    "print(f\"Models evaluated: {model_cols}\")\n",
    "\n",
    "# Evaluate using utilsforecast\n",
    "evaluation = evaluate(\n",
    "    cv_results,\n",
    "    metrics=[mae, rmse, smape],\n",
    "    models=model_cols,\n",
    ")\n",
    "\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results across all series\n",
    "avg_metrics = evaluation.groupby('metric')[model_cols].mean()\n",
    "print(\"\\n=== Average Performance Across All Series ===\")\n",
    "avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for idx, metric in enumerate(['mae', 'rmse']):\n",
    "    if metric in avg_metrics.index:\n",
    "        values = avg_metrics.loc[metric]\n",
    "        bars = axes[idx].bar(values.index, values.values, color=['#2ecc71', '#3498db', '#9b59b6'])\n",
    "        axes[idx].set_title(f'{metric.upper()} by Model')\n",
    "        axes[idx].set_ylabel(metric.upper())\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, val in zip(bars, values.values):\n",
    "            axes[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                           f'{val:.1f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.suptitle('Model Comparison on Spike-Prone Demand Data', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compare Different Data Characteristics\n",
    "\n",
    "Let's run the same benchmark on **different synthetic distributions** to see how model rankings change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_on_distribution(dist_func, dist_name, seed=42):\n",
    "    \"\"\"Run benchmark on a specific distribution and return average MAE.\"\"\"\n",
    "    sim = TimeSeriesSimulator(\n",
    "        length=200,\n",
    "        distribution=dist_func,\n",
    "        trend=\"linear\",\n",
    "        trend_params={\"slope\": 0.1},\n",
    "        seasonality=7,\n",
    "        seasonality_strength=10.0,\n",
    "        seed=seed,\n",
    "    )\n",
    "    df = sim.simulate(n_series=5)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=[\n",
    "            SeasonalNaive(season_length=7),\n",
    "            AutoETS(season_length=7),\n",
    "            MSTL(season_length=7),\n",
    "        ],\n",
    "        freq='D',\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    cv = sf.cross_validation(df=df, h=14, n_windows=2, step_size=14)\n",
    "    model_cols = [c for c in cv.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']]\n",
    "    \n",
    "    eval_df = evaluate(cv, metrics=[mae], models=model_cols)\n",
    "    # Return average MAE per model\n",
    "    return eval_df[model_cols].mean()\n",
    "\n",
    "\n",
    "# Define different distribution scenarios\n",
    "def smooth_gamma(size, rng):\n",
    "    \"\"\"Smooth gamma distribution - no spikes.\"\"\"\n",
    "    return rng.gamma(shape=5, scale=10, size=size)\n",
    "\n",
    "def high_spike_demand(size, rng):\n",
    "    \"\"\"Higher spike probability (15%).\"\"\"\n",
    "    base = rng.gamma(shape=5, scale=10, size=size)\n",
    "    mask = rng.random(size) < 0.15\n",
    "    base[mask] *= rng.uniform(3.0, 6.0, size=mask.sum())\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks on different distributions\n",
    "print(\"Running benchmarks on different distributions...\\n\")\n",
    "\n",
    "results = {}\n",
    "distributions = [\n",
    "    (smooth_gamma, \"Smooth (No Spikes)\"),\n",
    "    (demand_with_spikes, \"5% Spikes\"),\n",
    "    (high_spike_demand, \"15% Spikes\"),\n",
    "]\n",
    "\n",
    "for dist_func, name in distributions:\n",
    "    print(f\"Benchmarking: {name}\")\n",
    "    results[name] = benchmark_on_distribution(dist_func, name)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "comparison_df.columns = [c.replace('-mae', '') for c in comparison_df.columns]\n",
    "print(\"\\n=== MAE by Distribution Type ===\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how model rankings change\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(comparison_df.columns))\n",
    "width = 0.25\n",
    "\n",
    "for i, (dist_name, row) in enumerate(comparison_df.iterrows()):\n",
    "    ax.bar(x + i*width, row.values, width, label=dist_name, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('MAE')\n",
    "ax.set_title('How Spike Frequency Affects Model Performance')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(comparison_df.columns)\n",
    "ax.legend(title='Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "\n",
    "By using `TimeSeriesSimulator` with different custom distributions, we can systematically answer questions like:\n",
    "\n",
    "1. **Which model is most robust to spikes?** Compare performance across spike frequencies\n",
    "2. **Does adding complexity help?** Compare simple (SeasonalNaive) vs complex (AutoARIMA) models\n",
    "3. **What's the cost of outliers?** Compare smooth vs spike-prone distributions\n",
    "\n",
    "This **controlled experimentation** is impossible with real-world data alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "`TimeSeriesSimulator` enables systematic model evaluation by generating synthetic data with:\n",
    "\n",
    "| Feature | Options |\n",
    "|---------|--------|\n",
    "| **Distribution** | 7 built-in + any custom callable |\n",
    "| **Trend** | linear, quadratic, exponential, custom |\n",
    "| **Seasonality** | Single or multiple periods |\n",
    "| **Noise** | Additional Gaussian noise |\n",
    "| **Output** | StatsForecast-compatible DataFrame |\n",
    "\n",
    "**Workflow:**\n",
    "1. Define custom distribution with domain knowledge (spikes, regimes, etc.)\n",
    "2. Generate synthetic data with `TimeSeriesSimulator`\n",
    "3. Run `StatsForecast.cross_validation()` on multiple models\n",
    "4. Evaluate with `utilsforecast.evaluation.evaluate()`\n",
    "5. Compare results across different distribution scenarios\n",
    "\n",
    "**Key insight:** The custom callable interface lets you model domain-specific behaviors that don't fit standard distributions, making your model benchmarking more realistic and actionable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
