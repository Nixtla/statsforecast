{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "524620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15392f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa25a4",
   "metadata": {},
   "source": [
    "# Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ce0ed1-3b26-478e-8f74-3419adbbdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from nbdev.showdoc import add_docs, show_doc\n",
    "from statsforecast.models import naive, ses, seasonal_window_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc16100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import inspect\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from os import cpu_count\n",
    "from typing import Any, Callable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8d5b82-2be9-41f5-8cd0-3903d0761e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(name)s %(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353aca25-18cd-401a-b6af-007a9aec8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f64258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import test_eq, test_fail\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aacb71d9-3438-48cb-9247-bad463fa9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class GroupedArray:\n",
    "    \n",
    "    def __init__(self, data, indptr):\n",
    "        self.data = data\n",
    "        self.indptr = indptr\n",
    "        self.n_groups = self.indptr.size - 1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.data[self.indptr[idx] : self.indptr[idx + 1]]\n",
    "        elif isinstance(idx, slice):\n",
    "            idx = slice(idx.start, idx.stop + 1, idx.step)\n",
    "            new_indptr = self.indptr[idx].copy()\n",
    "            new_data = self.data[new_indptr[0] : new_indptr[-1]].copy()            \n",
    "            new_indptr -= new_indptr[0]\n",
    "            return GroupedArray(new_data, new_indptr)\n",
    "        raise ValueError(f'idx must be either int or slice, got {type(idx)}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_groups\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'GroupedArray(n_data={self.data.size:,}, n_groups={self.n_groups:,})'\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not hasattr(other, 'data') or not hasattr(other, 'indptr'):\n",
    "            return False\n",
    "        return np.allclose(self.data, other.data) and np.array_equal(self.indptr, other.indptr)\n",
    "    \n",
    "    def fit(self, model):\n",
    "        fm = np.full(self.n_groups, np.nan, dtype=object)\n",
    "        for i, grp in enumerate(self):\n",
    "            y = grp[:, 0] if grp.ndim == 2 else grp\n",
    "            X = grp[:, 1:] if (grp.ndim == 2 and grp.shape[1] > 1) else None\n",
    "            fm[i] = deepcopy(model).fit(y=y, X=X)\n",
    "        return fm\n",
    "    \n",
    "    def predict(self, fm, h, X=None, level=tuple()):\n",
    "        #fm stands for fitted_models\n",
    "        #and fm should have fitted_model\n",
    "        #from the same class\n",
    "        has_level = 'level' in inspect.signature(fm[0].predict).parameters and len(level)\n",
    "        kwargs = {}\n",
    "        if has_level:\n",
    "            kwargs['level'] = level\n",
    "        fcsts = np.full((h * self.n_groups, 2 * len(level) + 1), np.nan, dtype=np.float32)\n",
    "        for i, _ in enumerate(self):\n",
    "            if X is not None:\n",
    "                X_ = X[i]\n",
    "            else:\n",
    "                X_ = None\n",
    "            fcsts_i = fm[i].predict(h=h, X=X_, **kwargs)\n",
    "            fcsts[h * i : h * (i + 1), : 2 * has_level * len(level) + 1] = fcsts_i                \n",
    "        return fcsts\n",
    "    \n",
    "    def predict_in_sample(self, fm, level=tuple()):\n",
    "        has_level = 'level' in inspect.signature(fm[0].predict_in_sample).parameters and len(level)\n",
    "        kwargs = {}\n",
    "        if has_level:\n",
    "            kwargs['level'] = level\n",
    "        in_sample = np.full((self.data.shape[0],  2 * len(level) + 1), np.nan, dtype=np.float32)\n",
    "        for i, _ in enumerate(self):\n",
    "            if has_level:\n",
    "                in_sample_i = fm[i].predict_in_sample(level=level)\n",
    "            else:\n",
    "                in_sample_i = fm[i].predict_in_sample()\n",
    "            in_sample[self.indptr[i] : self.indptr[i + 1], : 2 * has_level * len(level) + 1] = in_sample_i\n",
    "        return in_sample\n",
    "    \n",
    "    def fit_predict(self, model, h, X=None, level=tuple()):\n",
    "        #fitted models\n",
    "        fm = self.fit(model=model)\n",
    "        #forecasts\n",
    "        fcsts = self.predict(fm=fm, h=h, X=X, level=level)\n",
    "        return fm, fcsts\n",
    "    \n",
    "    def compute_cv(self, model, h, test_size, step_size=1, input_size=None):\n",
    "        # output of size: (ts, window, h)\n",
    "        if (test_size - h) % step_size:\n",
    "            raise Exception('`test_size - h` should be module `step_size`')\n",
    "        n_windows = int((test_size - h) / step_size) + 1\n",
    "        out = np.full((self.n_groups, n_windows, h), np.nan, dtype=np.float32)\n",
    "        out_test = np.full((self.n_groups, n_windows, h), np.nan, dtype=np.float32)\n",
    "        for i_ts, grp in enumerate(self):\n",
    "            for i_window, cutoff in enumerate(range(-test_size, -h + 1, step_size), start=0):\n",
    "                end_cutoff = cutoff + h\n",
    "                in_size_disp = cutoff if input_size is None else input_size\n",
    "                #train dataset\n",
    "                y_train = grp[(cutoff - in_size_disp):cutoff]\n",
    "                y_train = y_train[:, 0] if y_train.ndim == 2 else y_train\n",
    "                X_train = y_train[:, 1:] if (y_train.ndim == 2 and y_train.shape[1] > 1) else None\n",
    "                #test dataset\n",
    "                y_test = grp[cutoff:] if end_cutoff == 0 else grp[cutoff:end_cutoff]\n",
    "                y_test = y_test[:, 0] if y_test.ndim == 2 else y_test\n",
    "                X_test = y_test[:, 1:] if (y_test.ndim == 2 and y_test.shape[1] > 1) else None\n",
    "                # fit model\n",
    "                out[i_ts, i_window] = model.fit(y=y_train, X=X_train).predict(h=h, X=X_test)\n",
    "                out_test[i_ts, i_window] = y_test\n",
    "        result = {'forecasts': out, 'y': out_test}\n",
    "        return result\n",
    "\n",
    "    def split(self, n_chunks):\n",
    "        return [self[x[0] : x[-1] + 1] for x in np.array_split(range(self.n_groups), n_chunks) if x.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab1b98a-e08c-43e0-88f7-ac6928ad4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#class to test the core methods\n",
    "from scipy.stats import norm\n",
    "class Naive:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, y: np.ndarray, X: np.ndarray = None):\n",
    "        self.last_value = y[-1]\n",
    "        self.fitted_vals = np.full(y.size, np.nan, np.float32)\n",
    "        self.fitted_vals[1:] = np.roll(y, 1)[1:]\n",
    "        self.errors = y - self.fitted_vals\n",
    "        return self\n",
    "        \n",
    "    def predict(self, h: int, X: np.ndarray = None, level = tuple()):\n",
    "        preds = np.repeat(self.last_value, h)[:, None]\n",
    "        if len(level):\n",
    "            se = np.mean(self.errors[1:] ** 2)\n",
    "            quantiles = norm.ppf(0.5 * (1 + np.asarray(level) / 100))\n",
    "            lower = preds.reshape(-1, 1) - quantiles * se.reshape(-1, 1)\n",
    "            upper = preds.reshape(-1, 1) + quantiles * se.reshape(-1, 1)\n",
    "            preds = np.hstack([preds, lower, upper])\n",
    "        return preds\n",
    "    \n",
    "    def predict_in_sample(self, level = tuple()):\n",
    "        return self.fitted_vals[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "822cacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#data used for tests\n",
    "data = np.arange(12)\n",
    "indptr = np.array([0, 4, 8, 12])\n",
    "\n",
    "# test we can recover the \n",
    "# number of series\n",
    "ga = GroupedArray(data, indptr)\n",
    "test_eq(len(ga), 3)\n",
    "\n",
    "#test splits of data\n",
    "splits = ga.split(2)\n",
    "test_eq(splits[0], GroupedArray(data[:8], indptr[:3]))\n",
    "test_eq(splits[1], GroupedArray(data[8:], np.array([0, 4])))\n",
    "\n",
    "# fitting models for each ts\n",
    "model = Naive()\n",
    "fitted_models = ga.fit(model=model)\n",
    "test_eq(len(fitted_models), 3)\n",
    "\n",
    "# test forecasts\n",
    "exp_fcsts = np.hstack([2 * [data[i]] for i in indptr[1:] - 1])\n",
    "np.testing.assert_equal(\n",
    "    ga.predict(fm=fitted_models, h=2),\n",
    "    exp_fcsts[:, None],\n",
    ")\n",
    "\n",
    "# test expected fitted_values\n",
    "exp_fitted = np.array([np.nan, 1., 1., 1.])\n",
    "exp_fitted = np.hstack([ga[i] - exp_fitted for i in range(3)])\n",
    "np.testing.assert_equal(\n",
    "    ga.predict_in_sample(fm=fitted_models),\n",
    "    exp_fitted[:, None],\n",
    ")\n",
    "\n",
    "#test fit and predict pipelie\n",
    "fitted_models, fcsts = ga.fit_predict(model=model, h=2) \n",
    "test_eq(len(fitted_models), 3)\n",
    "np.testing.assert_equal(exp_fcsts[:, None], fcsts)\n",
    "\n",
    "#test levels\n",
    "fitted_models, fcsts = ga.fit_predict(model=model, h=2, level=(50, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69e325a2-aaa4-406c-9008-b5987e1372f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# tests for cross valiation\n",
    "data = np.hstack([np.arange(10), np.arange(100, 200), np.arange(20, 40)])\n",
    "indptr = np.array([0, 10, 110, 130])\n",
    "ga = GroupedArray(data, indptr)\n",
    "\n",
    "# sum ahead just returns the last value\n",
    "# added with h future values \n",
    "class SumAhead:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, y, X):\n",
    "        self.last_value = y[-1]\n",
    "        self.fitted_values = np.full(y.size, np.nan, np.float32)\n",
    "        self.fitted_values[1:] = y[:1]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, h, X=None):\n",
    "        return self.last_value + np.arange(1, h + 1)\n",
    "model = SumAhead()\n",
    "res_cv = ga.compute_cv(model=model, h=2, test_size=5)\n",
    "test_eq(res_cv['forecasts'], res_cv['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "061d3a28-f591-4c70-96ac-9bed83a3b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "actual_step_size = np.unique(np.diff(res_cv['forecasts'], axis=1))\n",
    "test_eq(actual_step_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8523c6be-242e-4eab-bb32-8956d9e25d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "horizons = [1, 2, 3, 2]\n",
    "test_sizes = [3, 4, 6, 6]\n",
    "step_sizes = [2, 2, 3, 4]\n",
    "for h, test_size, step_size in zip(horizons, test_sizes, step_sizes):\n",
    "    res_cv = ga.compute_cv(model=model, h=h, test_size=test_size, step_size=step_size)\n",
    "    test_eq(res_cv['forecasts'], res_cv['y'])\n",
    "    actual_step_size = np.unique(np.diff(res_cv['forecasts'], axis=1))\n",
    "    test_eq(actual_step_size, step_size)\n",
    "    actual_n_windows = res_cv['forecasts'].shape[1]\n",
    "    test_eq(actual_n_windows, int((test_size - h)/step_size) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2521161-1947-4b4c-9d2e-e1da646a6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "def fail_cv(h, test_size, step_size):\n",
    "    return ga.compute_cv(model=model, h=h, test_size=test_size, step_size=step_size)\n",
    "test_fail(fail_cv, contains='module', kwargs=dict(h=2, test_size=5, step_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b63f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _grouped_array_from_df(df, sort_df):\n",
    "    df = df.set_index('ds', append=True)\n",
    "    if not df.index.is_monotonic_increasing and sort_df:\n",
    "        df = df.sort_index()\n",
    "    data = df.values.astype(np.float32)\n",
    "    indices_sizes = df.index.get_level_values('unique_id').value_counts(sort=False)\n",
    "    indices = indices_sizes.index\n",
    "    sizes = indices_sizes.values\n",
    "    cum_sizes = sizes.cumsum()\n",
    "    dates = df.index.get_level_values('ds')[cum_sizes - 1]\n",
    "    indptr = np.append(0, cum_sizes).astype(np.int32)\n",
    "    return GroupedArray(data, indptr), indices, dates, df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d450cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "series = generate_series(10_000, n_static_features=2, equal_ends=False)\n",
    "sorted_series = series.sort_values(['unique_id', 'ds'])\n",
    "unsorted_series = sorted_series.sample(frac=1.0)\n",
    "ga, indices, dates, ds = _grouped_array_from_df(unsorted_series, sort_df=True)\n",
    "\n",
    "np.testing.assert_allclose(ga.data, sorted_series.drop(columns='ds').values)\n",
    "test_eq(indices, sorted_series.index.unique(level='unique_id'))\n",
    "test_eq(dates, series.groupby('unique_id')['ds'].max().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2248ad77-7658-416a-8eb5-fac9b17d8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _cv_dates(last_dates, freq, h, test_size, step_size=1):\n",
    "    #assuming step_size = 1\n",
    "    if (test_size - h) % step_size:\n",
    "        raise Exception('`test_size - h` should be module `step_size`')\n",
    "    n_windows = int((test_size - h) / step_size) + 1\n",
    "    if len(np.unique(last_dates)) == 1:\n",
    "        if issubclass(last_dates.dtype.type, np.integer):\n",
    "            total_dates = np.arange(last_dates[0] - test_size + 1, last_dates[0] + 1)\n",
    "            out = np.empty((h * n_windows, 2), dtype=last_dates.dtype)\n",
    "            freq = 1\n",
    "        else:\n",
    "            total_dates = pd.date_range(end=last_dates[0], periods=test_size, freq=freq)\n",
    "            out = np.empty((h * n_windows, 2), dtype='datetime64[s]')\n",
    "        for i_window, cutoff in enumerate(range(-test_size, -h + 1, step_size), start=0):\n",
    "            end_cutoff = cutoff + h\n",
    "            out[h * i_window : h * (i_window + 1), 0] = total_dates[cutoff:] if end_cutoff == 0 else total_dates[cutoff:end_cutoff]\n",
    "            out[h * i_window : h * (i_window + 1), 1] = np.tile(total_dates[cutoff] - freq, h)\n",
    "        dates = pd.DataFrame(np.tile(out, (len(last_dates), 1)), columns=['ds', 'cutoff'])\n",
    "    else:\n",
    "        dates = pd.concat([_cv_dates(np.array([ld]), freq, h, test_size, step_size) for ld in last_dates])\n",
    "        dates = dates.reset_index(drop=True)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39444de3-107c-4024-8dfa-d4c5278db639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "ds_int_cv_test = pd.DataFrame({\n",
    "    'ds': np.hstack([\n",
    "        [46, 47, 48],\n",
    "        [47, 48, 49],\n",
    "        [48, 49, 50]\n",
    "    ]),\n",
    "    'cutoff': [45] * 3 + [46] * 3 + [47] * 3\n",
    "}, dtype=np.int64)\n",
    "test_eq(ds_int_cv_test, _cv_dates(np.array([50], dtype=np.int64), 'D', 3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "863c212e-6331-4915-9f3a-2d20174b8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "ds_int_cv_test = pd.DataFrame({\n",
    "    'ds': np.hstack([\n",
    "        [46, 47, 48],\n",
    "        [48, 49, 50]\n",
    "    ]),\n",
    "    'cutoff': [45] * 3 + [47] * 3\n",
    "}, dtype=np.int64)\n",
    "test_eq(ds_int_cv_test, _cv_dates(np.array([50], dtype=np.int64), 'D', 3, 5, step_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b988d4f2-e99d-4608-aba9-530d15e95d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "for e_e in [True, False]:\n",
    "    n_series = 2\n",
    "    ga, indices, dates, ds = _grouped_array_from_df(generate_series(n_series, equal_ends=e_e), sort_df=True)\n",
    "    freq = pd.tseries.frequencies.to_offset('D')\n",
    "    horizon = 3\n",
    "    test_size = 5\n",
    "    df_dates = _cv_dates(last_dates=dates, freq=freq, h=horizon, test_size=test_size)\n",
    "    test_eq(len(df_dates), n_series * horizon * (test_size - horizon + 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafa169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _build_forecast_name(model, *args, idx_remove=4) -> str:\n",
    "    model_name = f'{model.__name__}'\n",
    "    func_params = inspect.signature(model).parameters\n",
    "    func_args = list(func_params.items())[idx_remove:]  # remove input array, horizon and xreg\n",
    "    changed_params = [\n",
    "        f'{name}-{value}'\n",
    "        for value, (name, arg) in zip(args, func_args)\n",
    "        if arg.default != value\n",
    "    ]\n",
    "    if changed_params:\n",
    "        model_name += '_' + '_'.join(changed_params)\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(_build_forecast_name(ses, 0.1), 'ses_alpha-0.1')\n",
    "test_eq(_build_forecast_name(seasonal_window_average, 7, 4), 'seasonal_window_average_season_length-7_window_size-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba3f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _as_tuple(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x\n",
    "    return (x,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(_as_tuple((1,)), (1,))\n",
    "test_eq(_as_tuple(1), (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa571eb5-f4b8-4e6b-b910-75bf8514eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _get_n_jobs(n_groups, n_jobs, ray_address):\n",
    "    if ray_address is not None:\n",
    "        logger.info(\n",
    "            'Using ray address,'\n",
    "            'using available resources insted of `n_jobs`'\n",
    "        )\n",
    "        try:\n",
    "            import ray\n",
    "        except ModuleNotFoundError as e:\n",
    "            msg = (\n",
    "                '{e}. To use a ray cluster you have to install '\n",
    "                'ray. Please run `pip install ray`. '\n",
    "            )\n",
    "            raise ModuleNotFoundError(msg) from e\n",
    "        if not ray.is_initialized():\n",
    "            ray.init(ray_address, ignore_reinit_error=True)\n",
    "        actual_n_jobs = int(ray.available_resources()['CPU'])\n",
    "    else:\n",
    "        if n_jobs == -1 or (n_jobs is None):\n",
    "            actual_n_jobs = cpu_count()\n",
    "        else:\n",
    "            actual_n_jobs = n_jobs\n",
    "    return min(n_groups, actual_n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8b257-9d7b-4578-a8bf-57e72f19e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#tests for more series than resources\n",
    "test_eq(_get_n_jobs(10, -1, None), cpu_count()) \n",
    "test_eq(_get_n_jobs(10, None, None), cpu_count())\n",
    "test_eq(_get_n_jobs(10, 2, None), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a43806-e6d7-495c-b98f-3729b8bcb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#tests for less series than resources\n",
    "test_eq(_get_n_jobs(1, -1, None), 1) \n",
    "test_eq(_get_n_jobs(1, None, None), 1)\n",
    "test_eq(_get_n_jobs(2, 10, None), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StatsForecast:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            df: pd.DataFrame, # DataFrame with columns `ds` and `y`, indexed by `unique_id` \n",
    "            models: List[Tuple[Callable, Any]], # List of tuples, each containing a fn and its parameters \n",
    "            freq: str, # Frequency of the data\n",
    "            n_jobs: int = 1, # Number of jobs used to parallel processing. Use `-1` to use all cores\n",
    "            ray_address: Optional[str] = None,  # Optional ray address to distribute jobs\n",
    "            sort_df: bool = True # Sort `df` according to index and `ds`?\n",
    "        ):\n",
    "        # needed for residuals, think about it later\n",
    "        self.ga, self.uids, self.last_dates, self.ds = _grouped_array_from_df(df, sort_df)\n",
    "        self.models = models\n",
    "        self.freq = pd.tseries.frequencies.to_offset(freq)\n",
    "        self.n_jobs = _get_n_jobs(len(self.ga), n_jobs, ray_address)\n",
    "        self.ray_address = ray_address\n",
    "        self.sort_df = sort_df\n",
    "        \n",
    "    def forecast(\n",
    "            self, \n",
    "            h: int, # Forecast horizon\n",
    "            xreg: Optional[pd.DataFrame] = None, # Future exogenous regressors\n",
    "            fitted: bool = False, # Save fitted values for each model?\n",
    "            level: Optional[List[int]] = None, # Levels of propabilistic intervals \n",
    "        ):\n",
    "        if xreg is not None:\n",
    "            expected_shape = (h * len(self.ga), self.ga.data.shape[1])\n",
    "            if xreg.shape != expected_shape:\n",
    "                raise ValueError(f'Expected xreg to have shape {expected_shape}, but got {xreg.shape}')\n",
    "            xreg, _, _, _ = _grouped_array_from_df(xreg, sort_df=self.sort_df)\n",
    "        forecast_kwargs = dict(\n",
    "            h=h, test_size=None, step_size=None,\n",
    "            input_size=None, \n",
    "            xreg=xreg, fitted=fitted, \n",
    "            level=level, mode='forecast',\n",
    "        )\n",
    "        if self.n_jobs == 1:\n",
    "            res_fcsts = self._sequential(**forecast_kwargs)\n",
    "        else:\n",
    "            res_fcsts = self._data_parallel(**forecast_kwargs)\n",
    "        if fitted:\n",
    "            self.fcst_fitted_ = res_fcsts['fitted']\n",
    "        fcsts = res_fcsts['fcsts']\n",
    "        if issubclass(self.last_dates.dtype.type, np.integer):\n",
    "            last_date_f = lambda x: np.arange(x + 1, x + 1 + h, dtype=self.last_dates.dtype)\n",
    "        else:\n",
    "            last_date_f = lambda x: pd.date_range(x + self.freq, periods=h, freq=self.freq)\n",
    "        if len(np.unique(self.last_dates)) == 1:\n",
    "            dates = np.tile(last_date_f(self.last_dates[0]), len(self.ga))\n",
    "        else:\n",
    "            dates = np.hstack([\n",
    "                last_date_f(last_date)\n",
    "                for last_date in self.last_dates            \n",
    "            ])\n",
    "        idx = pd.Index(np.repeat(self.uids, h), name='unique_id')\n",
    "        return pd.DataFrame({'ds': dates, **fcsts}, index=idx)\n",
    "    \n",
    "    def forecast_fitted_values(self):\n",
    "        if not hasattr(self, 'fcst_fitted_'):\n",
    "            raise Exception('Please run `forecast` mehtod using `fitted=True`')\n",
    "        fcst_fitted = {key: val['values'] for key, val in self.fcst_fitted_.items()}\n",
    "        fcst_fitted['y'] = self.ga.data[:, 0]\n",
    "        return pd.DataFrame({**fcst_fitted}, index=self.ds).reset_index(level=1)\n",
    "    \n",
    "    def cross_validation(\n",
    "            self, \n",
    "            h: int, # Forecast horizon \n",
    "            n_windows: int = 1, # Number of windows used for cross validation\n",
    "            step_size: int = 1, # Step size between each window \n",
    "            test_size: Optional[int] = None, # Lenght of test size. If passed, set `n_windows=None`\n",
    "            input_size: Optional[int] = None, # Input size for each window \n",
    "            fitted=False, # Save fitted values for each window and each model?\n",
    "        ):\n",
    "        if test_size is None:\n",
    "            test_size = h + step_size * (n_windows - 1)\n",
    "        elif n_windows is None:\n",
    "            if (test_size - h) % step_size:\n",
    "                raise Exception('`test_size - h` should be module `step_size`')\n",
    "            n_windows = int((test_size - h) / step_size) + 1\n",
    "        elif (n_windows is None) and (test_size is None):\n",
    "            raise Exception('you must define `n_windows` or `test_size`')\n",
    "        else:\n",
    "            raise Exception('you must define `n_windows` or `test_size` but not both')\n",
    "            \n",
    "        cv_kwargs = dict(\n",
    "            h=h, test_size=test_size, step_size=step_size, input_size=input_size, \n",
    "            xreg=None, fitted=fitted, level=None, mode='cv',\n",
    "        )\n",
    "        if self.n_jobs == 1:\n",
    "            res_fcsts = self._sequential(**cv_kwargs)\n",
    "        else:\n",
    "            res_fcsts = self._data_parallel(**cv_kwargs)\n",
    "        if fitted:\n",
    "            self.cv_fitted_ = res_fcsts['fitted']\n",
    "            self.n_cv_ = n_windows\n",
    "        fcsts = res_fcsts['fcsts']   \n",
    "        dates = _cv_dates(last_dates=self.last_dates, freq=self.freq, h=h, test_size=test_size, step_size=step_size)\n",
    "        dates = {'ds': dates['ds'].values, 'cutoff': dates['cutoff'].values}\n",
    "        idx = pd.Index(np.repeat(self.uids, h * n_windows), name='unique_id')\n",
    "        return pd.DataFrame({**dates, **fcsts}, index=idx)\n",
    "    \n",
    "    def cross_validation_fitted_values(self):\n",
    "        if not hasattr(self, 'cv_fitted_'):\n",
    "            raise Exception('Please run `cross_validation` mehtod using `fitted=True`')\n",
    "        index = pd.MultiIndex.from_tuples(np.tile(self.ds, self.n_cv_), names=['unique_id', 'ds'])\n",
    "        res = pd.DataFrame(index=index, columns=['cutoff', 'y'] + list(self.cv_fitted_.keys()))\n",
    "        for model, res_ in self.cv_fitted_.items():\n",
    "            res[model] = res_['values'].flatten('F')\n",
    "        res['cutoff'] = res_['last_idxs'].flatten('F')\n",
    "        res['y'] = np.tile(self.ga.data.flatten(), self.n_cv_)\n",
    "        idxs = res_['idxs'].flatten('F')\n",
    "        res = res.iloc[idxs].reset_index(level=1)\n",
    "        res['cutoff'] = res['ds'].where(res['cutoff']).bfill()\n",
    "        return res\n",
    "\n",
    "    def _sequential(self, h, test_size, step_size, input_size, xreg, fitted, level, mode='forecast'):\n",
    "        result = {'fcsts': {}, 'fitted': {}}\n",
    "        logger.info('Computing forecasts')\n",
    "        for model_args in self.models:\n",
    "            model, *args = _as_tuple(model_args)\n",
    "            model_name = _build_forecast_name(model, *args)\n",
    "            if mode == 'forecast':\n",
    "                res_fcsts = self.ga.compute_forecasts(h, model, xreg, fitted, level, *args)\n",
    "                values = res_fcsts['forecasts']\n",
    "                keys = res_fcsts['keys']\n",
    "            elif mode == 'cv':\n",
    "                res_fcsts = self.ga.compute_cv(h, test_size, model, step_size, input_size, fitted, *args)\n",
    "                values = res_fcsts['forecasts']\n",
    "                test_values = res_fcsts['y']\n",
    "                keys = None\n",
    "            if keys is not None:\n",
    "                for j, key in enumerate(keys):\n",
    "                    result['fcsts'][f'{model_name}_{key}'] = values[:, j]\n",
    "            else:\n",
    "                result['fcsts'][model_name] = values.flatten()\n",
    "            if fitted:\n",
    "                result['fitted'][model_name] = res_fcsts['fitted']\n",
    "            logger.info(f'Computed forecasts for {model_name}.')\n",
    "        if mode == 'cv':\n",
    "            result['fcsts'] = {'y': test_values.flatten(), **result['fcsts']}\n",
    "        return result\n",
    "    \n",
    "    def _data_parallel(self, h, test_size, step_size, input_size, xreg, fitted, level, mode='forecast'):\n",
    "        result = {'fcsts': {}, 'fitted': {}}\n",
    "        logger.info('Computing forecasts')\n",
    "        gas = self.ga.split(self.n_jobs)\n",
    "        if xreg is not None:\n",
    "            xregs = xreg.split(self.n_jobs)\n",
    "        else:\n",
    "            from itertools import repeat\n",
    "            \n",
    "            xregs = repeat(None)\n",
    "        \n",
    "        if self.ray_address is not None:\n",
    "            try:\n",
    "                from ray.util.multiprocessing import Pool\n",
    "            except ModuleNotFoundError as e:\n",
    "                msg = (\n",
    "                    f'{e}. To use a ray cluster you have to install '\n",
    "                    'ray. Please run `pip install ray`. '\n",
    "                )\n",
    "                raise ModuleNotFoundError(msg) from e\n",
    "            kwargs = dict(ray_address=self.ray_address)\n",
    "        else:\n",
    "            from multiprocessing import Pool\n",
    "            kwargs = dict()\n",
    "        \n",
    "        with Pool(self.n_jobs, **kwargs) as executor:\n",
    "            for model_args in self.models:\n",
    "                model, *args = _as_tuple(model_args)\n",
    "                model_name = _build_forecast_name(model, *args)\n",
    "                futures = []\n",
    "                for ga, xr in zip(gas, xregs):\n",
    "                    if mode == 'forecast':\n",
    "                        future = executor.apply_async(ga.compute_forecasts, (h, model, xr, fitted, level, *args,))\n",
    "                    elif mode == 'cv':\n",
    "                        future = executor.apply_async(ga.compute_cv, (h, test_size, model, step_size, input_size, fitted, *args))\n",
    "                    futures.append(future)\n",
    "                if mode == 'forecast':\n",
    "                    res_fcsts = [f.get() for f in futures]\n",
    "                    values = [d['forecasts'] for d in res_fcsts]\n",
    "                    keys = [d['keys'] for d in res_fcsts]\n",
    "                    keys = keys[0]\n",
    "                elif mode == 'cv':\n",
    "                    res_fcsts = [f.get() for f in futures]\n",
    "                    values = [d['forecasts'] for d in res_fcsts]\n",
    "                    test_values = [d['y'] for d in res_fcsts]\n",
    "                    keys = None\n",
    "                if keys is not None:\n",
    "                    values = np.vstack(values)\n",
    "                    for j, key in enumerate(keys):\n",
    "                        result['fcsts'][f'{model_name}_{key}'] = values[:, j]\n",
    "                else:\n",
    "                    values = np.hstack([val.flatten() for val in values])\n",
    "                    result['fcsts'][model_name] = values.flatten()\n",
    "                if fitted:\n",
    "                    res = {}\n",
    "                    for k in res_fcsts[0]['fitted'].keys():\n",
    "                        res[k] = np.concatenate([d['fitted'][k] for d in res_fcsts])\n",
    "                    result['fitted'][model_name] = res\n",
    "                logger.info(f'Computed forecasts for {model_name}.')\n",
    "        if mode == 'cv':\n",
    "            test_values = np.vstack(test_values)\n",
    "            result['fcsts'] = {'y': test_values.flatten(), **result['fcsts']}\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78030f31-2d2f-471d-8dd8-3afd2fff1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "add_docs(\n",
    "    StatsForecast, \"Compute forecasts using distinct models in paralell.\",\n",
    "    forecast=\"Compute forecasts\",\n",
    "    cross_validation=\"Perform cross validation\",\n",
    "    forecast_fitted_values=\"Return fitted values for each model\",\n",
    "    cross_validation_fitted_values=\"Return fitted values for the cross validation phase\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ad5ce-010c-44fb-9e92-3e364ca292b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(StatsForecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e513d9-31f7-4c0f-8d7b-80647ec940fd",
   "metadata": {},
   "source": [
    "The class `StatsForecast` receives a pandas dataframe with columns `ds` (indicating the timestamp of each observation) and `y` (the target variable). It must be indexed by the identifier of each time series (named `unique_id`). \n",
    "\n",
    "The class can compute forecasts for several models. The `models` argument is a list of tuples. Each tuple consists of a function (model) and its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916780f5-67eb-47ef-a6c5-55bde8232220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import (\n",
    "    adida,\n",
    "    auto_arima,\n",
    "    croston_classic,\n",
    "    croston_optimized,\n",
    "    croston_sba,\n",
    "    ets,\n",
    "    historic_average,\n",
    "    imapa,\n",
    "    naive,\n",
    "    random_walk_with_drift,\n",
    "    seasonal_exponential_smoothing,\n",
    "    seasonal_naive,\n",
    "    seasonal_window_average,\n",
    "    ses,\n",
    "    tsb,\n",
    "    window_average,\n",
    ")\n",
    "from statsforecast.utils import generate_series\n",
    "\n",
    "series = generate_series(10_000, n_static_features=2, equal_ends=False)\n",
    "\n",
    "models = [\n",
    "    naive, adida, croston_classic, croston_optimized,\n",
    "    croston_sba, historic_average, imapa, naive, \n",
    "    random_walk_with_drift, (seasonal_exponential_smoothing, 7, 0.1),\n",
    "    (seasonal_naive, 7), (seasonal_window_average, 7, 4),\n",
    "    (ses, 0.1), (tsb, 0.1, 0.3), (window_average, 4)\n",
    "]\n",
    "\n",
    "fcst = StatsForecast(\n",
    "    df=series,\n",
    "    models=models,\n",
    "    freq='D',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33759814-8ae5-4973-a329-9db88ae542bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(StatsForecast.forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad320d-ddfe-41f5-96d5-06deafd3e6c0",
   "metadata": {},
   "source": [
    "With the `StatsForecast.forecast` method you can compute the forecasts for each model in `models`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54281e8b-4844-4a79-8079-b8fc1bb8aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fcst.forecast(14)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(res.index.unique(), fcst.uids)\n",
    "last_dates = series.groupby('unique_id')['ds'].max()\n",
    "test_eq(res.groupby('unique_id')['ds'].min().values, last_dates + pd.offsets.Day())\n",
    "test_eq(res.groupby('unique_id')['ds'].max().values, last_dates + 14 * pd.offsets.Day())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d2545-3f2f-4e63-b8e5-023f9a268f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for equal ends time series\n",
    "series_eq_ends = generate_series(100, equal_ends=True)\n",
    "\n",
    "fcst = StatsForecast(\n",
    "    series_eq_ends,\n",
    "    [adida, croston_classic, croston_optimized,\n",
    "     croston_sba, historic_average, imapa, naive, \n",
    "     random_walk_with_drift, (seasonal_exponential_smoothing, 7, 0.1),\n",
    "     (seasonal_naive, 7), (seasonal_window_average, 7, 4),\n",
    "     (ses, 0.1), (tsb, 0.1, 0.3), (window_average, 4)],\n",
    "    freq='D',\n",
    ")\n",
    "res = fcst.forecast(14)\n",
    "\n",
    "test_eq(res.index.unique(), fcst.uids)\n",
    "last_dates = series_eq_ends.groupby('unique_id')['ds'].max()\n",
    "test_eq(res.groupby('unique_id')['ds'].min().values, last_dates + pd.offsets.Day())\n",
    "test_eq(res.groupby('unique_id')['ds'].max().values, last_dates + 14 * pd.offsets.Day())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d35ac3-8e2b-44cf-a84c-4093d91731d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#tests for monthly data\n",
    "monthly_series = generate_series(10_000, freq='M', min_length=10, max_length=20, equal_ends=True)\n",
    "monthly_series\n",
    "\n",
    "fcst = StatsForecast(\n",
    "    monthly_series,\n",
    "    [adida, (ses, 0.1), historic_average, croston_classic],\n",
    "    freq='M'\n",
    ")\n",
    "%time monthly_res = fcst.forecast(4)\n",
    "monthly_res\n",
    "\n",
    "last_dates = monthly_series.groupby('unique_id')['ds'].max()\n",
    "test_eq(monthly_res.groupby('unique_id')['ds'].min().values, fcst.last_dates + pd.offsets.MonthEnd())\n",
    "test_eq(monthly_res.groupby('unique_id')['ds'].max().values, fcst.last_dates + 4 * pd.offsets.MonthEnd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e988f-89cb-47fa-a170-7e1062acdaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(StatsForecast.forecast_fitted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6e945-8024-4c95-a225-e591b8c9cb77",
   "metadata": {},
   "source": [
    "Additionaly, you can compute the fitted values for each model. To get them, you need to pass `fitted=True` to the `StatsForecast.forecast` method and then use the `StatsForecast.forecast_fitted_values` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c221b-6333-4fcd-8faa-23866050c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    df=series,\n",
    "    models=[naive],\n",
    "    freq='D',\n",
    ")\n",
    "forecasts = fcst.forecast(14, fitted=True)\n",
    "fitted = fcst.forecast_fitted_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4be34-72c4-4ff7-b8c5-ccaa848fcde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#tests for fitted values\n",
    "def test_fcst_fitted(n_jobs=1):\n",
    "    fitted_fcst = StatsForecast(\n",
    "        series,\n",
    "        [naive],\n",
    "        freq='D',\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "    fitted_res = fitted_fcst.forecast(14, fitted=True)\n",
    "    fitted = fitted_fcst.forecast_fitted_values()\n",
    "    test_eq(series['ds'], fitted['ds'])\n",
    "    test_eq(series['y'].astype(np.float32), fitted['y'])\n",
    "test_fcst_fitted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89108e-7585-4008-ac14-dee7a1d73c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(StatsForecast.cross_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574facd5-9054-4e04-9e21-7342595ff1da",
   "metadata": {},
   "source": [
    "You can also perform cross validation with `StatsForecast`, using `StatsForecast.cross_validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aba573-eda2-402c-8c3b-efbdae53cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    df=series,\n",
    "    models=[naive],\n",
    "    freq='D',\n",
    ")\n",
    "forecasts_cv = fcst.cross_validation(14, n_windows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9604d9-9b43-4412-9cd8-f379bdb7ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for cross_validation\n",
    "series_cv = pd.DataFrame({\n",
    "    'ds': np.hstack([\n",
    "        pd.date_range(end='2021-01-01', freq='D', periods=10),\n",
    "        pd.date_range(end='2022-01-01', freq='D', periods=100),\n",
    "        pd.date_range(end='2020-01-01', freq='D', periods=20)\n",
    "    ]),\n",
    "    'y': np.hstack([np.arange(10.), np.arange(100, 200), np.arange(20, 40)])\n",
    "}, index=pd.Index(\n",
    "    data=np.hstack([np.zeros(10), np.zeros(100) + 1, np.zeros(20) + 2]),\n",
    "    name='unique_id'\n",
    "))\n",
    "\n",
    "fcst = StatsForecast(\n",
    "    series_cv,\n",
    "    [sum_ahead, naive],\n",
    "    freq='D'\n",
    ")\n",
    "res_cv = fcst.cross_validation(h=2, test_size=5, n_windows=None)\n",
    "test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))\n",
    "\n",
    "n_windows = fcst.cross_validation(h=2, n_windows=2).groupby('unique_id').size().unique()\n",
    "test_eq(n_windows, 2 * 2)\n",
    "test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))\n",
    "\n",
    "n_windows = fcst.cross_validation(h=3, n_windows=3, step_size=3, fitted=True).groupby('unique_id').size().unique()\n",
    "test_eq(n_windows, 3 * 3)\n",
    "test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71f530-c7cf-4381-b831-9c85b5ab6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for equal ends cross_validation\n",
    "series_cv = pd.DataFrame({\n",
    "    'ds': np.hstack([\n",
    "        pd.date_range(end='2022-01-01', freq='D', periods=10),\n",
    "        pd.date_range(end='2022-01-01', freq='D', periods=100),\n",
    "        pd.date_range(end='2022-01-01', freq='D', periods=20)\n",
    "    ]),\n",
    "    'y': np.hstack([np.arange(10), np.arange(100, 200), np.arange(20, 40)])\n",
    "}, index=pd.Index(\n",
    "    data=np.hstack([np.zeros(10), np.zeros(100) + 1, np.zeros(20) + 2]),\n",
    "    name='unique_id'\n",
    "))\n",
    "\n",
    "fcst = StatsForecast(\n",
    "    series_cv,\n",
    "    [sum_ahead],\n",
    "    freq='D',\n",
    ")\n",
    "res_cv = fcst.cross_validation(h=2, test_size=5, n_windows=None)\n",
    "test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))\n",
    "\n",
    "n_windows = fcst.cross_validation(h=2, n_windows=2).groupby('unique_id').size().unique()\n",
    "test_eq(n_windows, 2 * 2)\n",
    "test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))\n",
    "\n",
    "n_windows = fcst.cross_validation(h=3, n_windows=3, step_size=3).groupby('unique_id').size().unique()\n",
    "test_eq(n_windows, 3 * 3)\n",
    "test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551bd4d-d71a-4455-9c48-3df44bbf4fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(StatsForecast.cross_validation_fitted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ba82f-13b5-46a6-ba77-ee356b78c7b9",
   "metadata": {},
   "source": [
    "To recover the fitted values for each window and each model in the cross validation phase, you have to pass `fitted=True` to the `StatsForecast.cross_validation` method and the use `StatsForecast.cross_validation_fitted_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e837869-3229-438b-8507-31e5242f1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(\n",
    "    df=series[['ds', 'y']],\n",
    "    models=[naive],\n",
    "    freq='D',\n",
    ")\n",
    "forecasts_cv = fcst.cross_validation(7, n_windows=2, fitted=True)\n",
    "fitted_cv = fcst.cross_validation_fitted_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba27b00-70f0-4d89-a027-f1a8a5f550ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#tests for fitted values cross_validation\n",
    "def test_cv_fitted(n_jobs=1):\n",
    "    resids_fcst = StatsForecast(\n",
    "        series_cv,\n",
    "        [sum_ahead, naive],\n",
    "        freq='D',\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    resids_res_cv = resids_fcst.cross_validation(h=2, n_windows=4, fitted=True)\n",
    "    resids_cv = resids_fcst.cross_validation_fitted_values()\n",
    "    for uid in resids_cv.index.unique():\n",
    "        for cutoff in resids_cv.loc[uid]['cutoff'].unique():\n",
    "            pd.testing.assert_frame_equal(\n",
    "                resids_cv.loc[uid].query('cutoff == @cutoff')[['ds', 'y']], \n",
    "                series_cv.query('ds <= @cutoff & unique_id == @uid')[['ds', 'y']],\n",
    "                check_dtype=False\n",
    "            )\n",
    "test_cv_fitted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73536e57-fa38-4b7c-967d-a5ddd54733d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#tests for parallel processing\n",
    "try: from nbdev.imports import IN_NOTEBOOK\n",
    "except: IN_NOTEBOOK=False\n",
    "if __name__==\"__main__\" and not IN_NOTEBOOK:\n",
    "    fcst = StatsForecast(\n",
    "        series,\n",
    "        [adida, (ses, 0.1), historic_average, croston_classic],\n",
    "        freq='D',\n",
    "        n_jobs=2\n",
    "    )\n",
    "    res = fcst.forecast(14)\n",
    "    res_cv = fcst.cross_validation(h=3, test_size=10, n_windows=None)\n",
    "    print(res)\n",
    "    print(res_cv)\n",
    "    fcst = StatsForecast(\n",
    "        series_cv,\n",
    "        [sum_ahead],\n",
    "        freq='D',\n",
    "    )\n",
    "    res_cv = fcst.cross_validation(h=2, test_size=5, n_windows=None)\n",
    "    test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))\n",
    "    \n",
    "    test_fcst_fitted(n_jobs=2)\n",
    "    test_cv_fitted(n_jobs=2)\n",
    "    # check n_windows argument\n",
    "    n_windows = fcst.cross_validation(h=2, n_windows=2).groupby('unique_id').size().unique()\n",
    "    test_eq(n_windows, 2 * 2)\n",
    "    test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))\n",
    "    # check step_size argument\n",
    "    n_windows = fcst.cross_validation(h=3, n_windows=3, step_size=3).groupby('unique_id').size().unique()\n",
    "    test_eq(n_windows, 3 * 3)\n",
    "    test_eq(0., np.mean(res_cv['y'] - res_cv['sum_ahead']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ddc742-cae0-43f8-89eb-f5ae2effeb15",
   "metadata": {},
   "source": [
    "## Integer datestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1985e76-32d6-472a-b38e-fc35a933dac5",
   "metadata": {},
   "source": [
    "The `StatsForecast` class can also receive integers as datestamp, the following example shows how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc45251-a56b-4dad-9d84-9a843de0e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e072d-5f62-4c1a-8b0c-1592a7f992b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ds_df = pd.DataFrame({'ds': np.arange(1, len(ap) + 1), 'y': ap})\n",
    "int_ds_df.insert(0, 'unique_id', 'AirPassengers')\n",
    "int_ds_df.set_index('unique_id', inplace=True)\n",
    "int_ds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1575c5-ad2b-419d-aff1-f757ce39f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ds_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfbe2a7-3205-4976-9e78-3225b7808444",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = StatsForecast(int_ds_df, models=[historic_average], freq='D')\n",
    "horizon = 7\n",
    "forecast = fcst.forecast(horizon)\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df545ed2-7b28-44a6-875d-58a3ea7a934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = int_ds_df['ds'].max()\n",
    "test_eq(forecast['ds'].values, np.arange(last_date + 1, last_date + 1 + horizon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589bdae-0303-4878-b387-07935afa855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ds_cv = fcst.cross_validation(h=7, test_size=8, n_windows=None)\n",
    "int_ds_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eb42c4-8275-430f-b074-d93f71c0ca22",
   "metadata": {},
   "source": [
    "## External regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320eba6-603d-431e-9f5c-0ba2df7876d8",
   "metadata": {},
   "source": [
    "Every column after **y** is considered an external regressor and will be passed to the models that allow them. If you use them you must supply the future values to the `StatsForecast.forecast` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99fb36-c574-47d7-bff6-d95a1172c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, h, future_xreg, residuals):\n",
    "    y = X[:, 0]\n",
    "    xreg = X[:, 1:]\n",
    "    coefs, *_ = np.linalg.lstsq(xreg, y, rcond=None)\n",
    "    return {'mean': future_xreg @ coefs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be1d0a-7943-4082-8987-40535635bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_xreg = series = generate_series(10_000, equal_ends=True)\n",
    "series_xreg['intercept'] = 1\n",
    "series_xreg['dayofweek'] = series_xreg['ds'].dt.dayofweek\n",
    "series_xreg = pd.get_dummies(series_xreg, columns=['dayofweek'], drop_first=True)\n",
    "series_xreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830bc4c7-9f0f-4cdc-a639-965cc2ea0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sorted(series_xreg['ds'].unique())\n",
    "valid_start = dates[-14]\n",
    "train_mask = series_xreg['ds'] < valid_start\n",
    "series_train = series_xreg[train_mask]\n",
    "series_valid = series_xreg[~train_mask]\n",
    "X_valid = series_valid.drop(columns=['y'])\n",
    "fcst = StatsForecast(\n",
    "    series_train,\n",
    "    [linear_regression],\n",
    "    freq='D',\n",
    ")\n",
    "%time xreg_res = fcst.forecast(14, xreg=X_valid)\n",
    "xreg_res['y'] = series_valid['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b339f52-af88-4dc8-93af-cbbc751e231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xreg_res.groupby('ds').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af9dd2-eeb8-4ef6-9eef-13608ace264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xreg_res_cv = fcst.cross_validation(h=3, test_size=5, n_windows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d885f-9ef9-4237-aece-a87777c46caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# the following cells contain tests for external regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8c27e-1cb1-4e02-8243-6d3ccfc76860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def return_xreg(X, h, xreg, *args):\n",
    "    return {'mean': xreg[:, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da58f77-7194-4108-a32d-d3f01b39b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'ds': np.hstack([np.arange(10), np.arange(10)]),\n",
    "        'y': np.random.rand(20),\n",
    "        'x': np.arange(20, dtype=np.float32),\n",
    "    },\n",
    "    index=pd.Index([0] * 10 + [1] * 10, name='unique_id'),\n",
    ")\n",
    "train_mask = df['ds'] < 6\n",
    "train_df = df[train_mask]\n",
    "test_df = df[~train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca34f367-211b-40c2-a98a-8413abbe8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fcst = StatsForecast(\n",
    "    train_df,\n",
    "    [return_xreg],\n",
    "    freq='M',\n",
    "    n_jobs=1,\n",
    ")\n",
    "xreg = test_df.drop(columns='y')\n",
    "res = fcst.forecast(4, xreg=xreg)\n",
    "expected_res = xreg.rename(columns={'x': 'return_xreg'})\n",
    "pd.testing.assert_frame_equal(res, expected_res, check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6095cae-4788-49f5-9a15-9a61ea49c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "if __name__==\"__main__\" and not IN_NOTEBOOK:\n",
    "    fcst = StatsForecast(\n",
    "        train_df,\n",
    "        [return_xreg],\n",
    "        freq='M',\n",
    "        n_jobs=2,\n",
    "    )\n",
    "    xreg = test_df.drop(columns='y')\n",
    "    res = fcst.forecast(4, xreg=xreg)\n",
    "    expected_res = xreg.rename(columns={'x': 'return_xreg'})\n",
    "    pd.testing.assert_frame_equal(res, expected_res, check_dtype=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df775a7-fa4a-42eb-b556-bea2c851f23f",
   "metadata": {},
   "source": [
    "## Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d34eca7-8f71-4668-8521-20e1637f6140",
   "metadata": {},
   "source": [
    "You can pass the argument `level` to the `StatsForecast.forecast` method to calculate confidence intervals. Not all models can calculate them at the moment, so we will only obtain the intervals of those models that have it implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9fd95-52c4-4c42-a350-8e667fba2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_df = pd.DataFrame({'ds': np.arange(ap.size), 'y': ap}, index=pd.Index([0] * ap.size, name='unique_id'))\n",
    "fcst = StatsForecast(\n",
    "    ap_df,\n",
    "    [(seasonal_naive, 12), (auto_arima, 12)],\n",
    "    freq='M',\n",
    ")\n",
    "ap_ci = fcst.forecast(12, level=(80, 95))\n",
    "ap_ci.set_index('ds').plot(marker='.', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e2b7a-f3b2-4200-b902-b4c5d369e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test number of jobs greater than the available cores\n",
    "if __name__==\"__main__\" and not IN_NOTEBOOK:\n",
    "    ap_df = pd.DataFrame({'ds': np.arange(ap.size), 'y': ap}, index=pd.Index([0] * ap.size, name='unique_id'))\n",
    "    fcst = StatsForecast(\n",
    "        ap_df,\n",
    "        [(seasonal_naive, 12), (auto_arima, 12)],\n",
    "        freq='M',\n",
    "        n_jobs=101\n",
    "    )\n",
    "    ap_ci = fcst.forecast(12, level=(80, 95))\n",
    "    ap_ci.set_index('ds').plot(marker='.', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8d0b3-30ea-47aa-9824-732c90e24ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# The following cells contain parallel backends\n",
    "# we should create a separate submodule for this\n",
    "# for the moment we skip them from docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class ParallelBackend:\n",
    "    def forecast(self, df, models, freq, **kwargs: Any) -> Any:\n",
    "        model = StatsForecast(df.set_index(\"unique_id\"), models, freq)\n",
    "        return model.forecast(**kwargs)\n",
    "\n",
    "    def cross_validation(self, df, models, freq, **kwargs: Any) -> Any:\n",
    "        model = StatsForecast(df.set_index(\"unique_id\"), models, freq)\n",
    "        return model.cross_validation(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class MultiprocessBackend(ParallelBackend):\n",
    "    def __init__(self, n_jobs: int) -> None:\n",
    "        self.n_jobs = n_jobs\n",
    "        super().__init__()\n",
    "\n",
    "    def forecast(self, df, models, freq, **kwargs: Any) -> Any:\n",
    "        model = StatsForecast(df.set_index(\"unique_id\"), models, freq, n_jobs=self.n_jobs)\n",
    "        return model.forecast(**kwargs)\n",
    "\n",
    "    def cross_validation(self, df, models, freq, **kwargs: Any) -> Any:\n",
    "        model = StatsForecast(df.set_index(\"unique_id\"), models, freq, n_jobs=self.n_jobs)\n",
    "        return model.cross_validation(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class RayBackend(ParallelBackend):\n",
    "    def __init__(self, ray_address) -> None:\n",
    "        self.ray_address = ray_address\n",
    "\n",
    "    def forecast(self, df, models, freq, **kwargs: Any) -> Any:\n",
    "        model = StatsForecast(df.set_index(\"unique_id\"), models, freq, ray_address=self.ray_address)\n",
    "        return model.forecast(**kwargs)\n",
    "\n",
    "    def cross_validation(self, df, models, freq, **kwargs: Any) -> Any:\n",
    "        model = StatsForecast(df.set_index(\"unique_id\"), models, freq, ray_address=self.ray_address)\n",
    "        return model.cross_validation(df, models, freq, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579e7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def forecast(\n",
    "    df,\n",
    "    models,\n",
    "    freq,\n",
    "    h,\n",
    "    xreg=None,\n",
    "    level=None,\n",
    "    parallel: Optional[\"ParallelBackend\"] = None,\n",
    "):\n",
    "    backend = parallel if parallel is not None else ParallelBackend()\n",
    "    return backend.forecast(df, models, freq, h=h, xreg=xreg, level=level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def cross_validation(\n",
    "    df,\n",
    "    models,\n",
    "    freq,\n",
    "    h,\n",
    "    n_windows=1,\n",
    "    step_size=1,\n",
    "    test_size=None,\n",
    "    input_size=None,\n",
    "    parallel: Optional[\"ParallelBackend\"] = None,\n",
    "):\n",
    "    backend = parallel if parallel is not None else ParallelBackend()\n",
    "    return backend.cross_validation(\n",
    "        df,\n",
    "        models,\n",
    "        freq,\n",
    "        h=h,\n",
    "        n_windows=n_windows,\n",
    "        step_size=step_size,\n",
    "        test_size=test_size,\n",
    "        input_size=input_size,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
