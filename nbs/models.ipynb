{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Uniserie models implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from itertools import count\n",
    "from numbers import Number\n",
    "from typing import Collection, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from statsforecast.arima import auto_arima_f, forecast_arima, fitted_arima\n",
    "from statsforecast.ets import ets_f, forecast_ets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def auto_arima(X: np.ndarray, # time series\n",
    "               h: int, # forecasting horizon\n",
    "               future_xreg=None, #future regressors \n",
    "               fitted: bool=False, # fitted values\n",
    "               season_length: int=1, # season_length\n",
    "               approximation: bool=False, # approximation \n",
    "               level: Optional[Tuple[int]] = None # level\n",
    "    ) -> np.ndarray: \n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    xreg = X[:, 1:] if (X.ndim == 2 and X.shape[1] > 1) else None\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        mod = auto_arima_f(\n",
    "            y, \n",
    "            xreg=xreg,\n",
    "            period=season_length, \n",
    "            approximation=approximation,\n",
    "            allowmean=False, allowdrift=False #not implemented yet\n",
    "        )\n",
    "    fcst = forecast_arima(mod, h, xreg=future_xreg, level=level)\n",
    "    mean = fcst['mean']\n",
    "    if fitted:\n",
    "        return {'mean': mean, 'fitted': fitted_arima(mod)}\n",
    "    if level is None:\n",
    "        return {'mean': mean}\n",
    "    return {\n",
    "        'mean': mean,\n",
    "        **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "        **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(auto_arima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auto ARIMA**: Automatically selects the best ARIMA (AutoRegressive Integrated Moving Average) model using an information criterion. Default is the corrected Akaike Information Criterion (AICc). Information criterions are tests used to check how well a model fits the data it is trying to describe. \n",
    "\n",
    "The ARIMA models are based in the autocorrelations in the data and the autocorrelations of the forecast errors. Every model has three components: AR, I, and MA. \n",
    "\n",
    "An AR(p) model captures the autocorrelations in the data at lags $1,2,\\dots p$. \n",
    "\n",
    "$$y_t = \\beta_0+\\beta_1y_{t-1}+\\beta_2y_{t-2}+\\dots+\\beta_py{t_p}+\\epsilon_t$$\n",
    "\n",
    "If the autocorrelations of the forecast errors are added up to lag $q$, an ARMA(p,q) model is obtained. \n",
    "\n",
    "$$y_t = \\beta_0+\\beta_1y_{t-1}+\\beta_2y_{t-2}+\\dots+\\beta_py{t_p} + \\epsilon_t+\\theta_1 \\epsilon_{t-1}+\\theta_2\\epsilon_{t-2}+\\dots\\theta_q\\epsilon_{t-q}$$\n",
    "\n",
    "The last component of an ARIMA model is the integrated (I) part, which is a differencing operation. The order of differencing, denoted by $d$, indicates how many rounds of lag-1 differencing are performed. \n",
    "\n",
    "ARIMA models requiere the user to select $p$, $q$, and $d$. The values for $\\beta_i, i=1,2,\\dots,p$ and $\\theta_j, j=1,2,\\dots,q$ are then estimated. Auto ARIMA automatically makes this selection, searching over a range of possible values for $p$, $q$, and $d$, and then choosing the best model using an information criterion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential smoothing methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ets(X: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        future_xreg=None, # future regressors\n",
    "        fitted: bool = False, # fitted values\n",
    "        season_length: int = 1, # season length\n",
    "        model: str = 'ZZZ' # model type\n",
    "    )-> np.ndarray: \n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    xreg = X[:, 1:] if (X.ndim == 2 and X.shape[1] > 1) else None\n",
    "    mod = ets_f(y, m=season_length, model=model)\n",
    "    fcst = forecast_ets(mod, h)\n",
    "    keys = ['mean']\n",
    "    if fitted:\n",
    "        keys.append('fitted')\n",
    "    return {key: fcst[key] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error, Trend, and Seasonality**: Statistical models for exponential smoothing. These models are stochastic data generating processes than can produce complete forecast distributions. Each model consists of a set of equations to describe the observed data and the unobserved components or states, which are level, trend, and seasonal. Errors can be either additive or multiplicative. The notation ETS(Z,Z,Z) is used to describe the ETS model being used, where Z can take one of the following values. \n",
    "\n",
    "Notation| \n",
    "----- |\n",
    "N = None |     \n",
    "A = Additive |   \n",
    "Ad = Additive (damped) | \n",
    "M = Multiplicative | \n",
    "\n",
    "The possibilities for each state are shown below. \n",
    "\n",
    "State | Possible values \n",
    "----- | -----\n",
    "Error | A, M\n",
    "Trend | N, A, Ad\n",
    "Seasonal | N, A, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@njit\n",
    "def _ses_fcst_mse(x: np.ndarray, alpha: float) -> Tuple[float, float]:\n",
    "    \"\"\"Perform simple exponential smoothing on a series.\n",
    "\n",
    "    This function returns the one step ahead prediction\n",
    "    as well as the mean squared error of the fit.\n",
    "    \"\"\"\n",
    "    smoothed = x[0]\n",
    "    n = x.size\n",
    "    mse = 0.\n",
    "    fitted = np.full(n, np.nan, np.float32)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        smoothed = (alpha * x[i - 1] + (1 - alpha) * smoothed).item()\n",
    "        error = x[i] - smoothed\n",
    "        mse += error * error\n",
    "        fitted[i] = smoothed\n",
    "\n",
    "    mse /= n\n",
    "    forecast = alpha * x[-1] + (1 - alpha) * smoothed\n",
    "    return forecast, mse, fitted\n",
    "\n",
    "\n",
    "def _ses_mse(alpha: float, x: np.ndarray) -> float:\n",
    "    \"\"\"Compute the mean squared error of a simple exponential smoothing fit.\"\"\"\n",
    "    _, mse, _ = _ses_fcst_mse(x, alpha)\n",
    "    return mse\n",
    "\n",
    "\n",
    "@njit\n",
    "def _ses_forecast(x: np.ndarray, alpha: float) -> float:\n",
    "    \"\"\"One step ahead forecast with simple exponential smoothing.\"\"\"\n",
    "    forecast, _, fitted = _ses_fcst_mse(x, alpha)\n",
    "    return forecast, fitted\n",
    "\n",
    "\n",
    "@njit\n",
    "def _demand(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract the positive elements of a vector.\"\"\"\n",
    "    return x[x > 0]\n",
    "\n",
    "\n",
    "@njit\n",
    "def _intervals(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the intervals between non zero elements of a vector.\"\"\"\n",
    "    y = []\n",
    "\n",
    "    ctr = 1\n",
    "    for val in x:\n",
    "        if val == 0:\n",
    "            ctr += 1\n",
    "        else:\n",
    "            y.append(ctr)\n",
    "            ctr = 1\n",
    "\n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "@njit\n",
    "def _probability(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the element probabilities of being non zero.\"\"\"\n",
    "    return (x != 0).astype(np.int32)\n",
    "\n",
    "\n",
    "def _optimized_ses_forecast(\n",
    "        x: np.ndarray,\n",
    "        bounds: Sequence[Tuple[float, float]] = [(0.1, 0.3)]\n",
    "    ) -> float:\n",
    "    \"\"\"Searches for the optimal alpha and computes SES one step forecast.\"\"\"\n",
    "    alpha = minimize(\n",
    "        fun=_ses_mse,\n",
    "        x0=(0,),\n",
    "        args=(x,),\n",
    "        bounds=bounds,\n",
    "        method='L-BFGS-B'\n",
    "    ).x[0]\n",
    "    forecast, fitted = _ses_forecast(x, alpha)\n",
    "    return forecast, fitted\n",
    "\n",
    "\n",
    "@njit\n",
    "def _chunk_sums(array: np.ndarray, chunk_size: int) -> np.ndarray:\n",
    "    \"\"\"Splits an array into chunks and returns the sum of each chunk.\"\"\"\n",
    "    n = array.size\n",
    "    n_chunks = n // chunk_size\n",
    "    sums = np.empty(n_chunks)\n",
    "    for i, start in enumerate(range(0, n, chunk_size)):\n",
    "        sums[i] = array[start : start + chunk_size].sum()\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "#@njit\n",
    "def ses_(X: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon \n",
    "        future_xreg: np.ndarray, # future regressors\n",
    "        fitted: bool, # fitted values\n",
    "        alpha: float): # smoothing parameter\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    fcst, _, fitted_vals = _ses_fcst_mse(y, alpha)\n",
    "    mean = np.full(h, fcst, np.float32)\n",
    "    fcst = {'mean': mean}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ses(X: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon \n",
    "        future_xreg: np.ndarray, # future regressors\n",
    "        fitted: bool, # fitted values\n",
    "        alpha: float): # smoothing parameter\n",
    "    \n",
    "    return ses_(X, h, future_xreg, fitted, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fcst_ses = ses(ap, 12, None, True, 0.1)\n",
    "test_close(fcst_ses['mean'], np.repeat(460.3028, 12), eps=1e-4)\n",
    "#to recover these residuals from R\n",
    "#you have to pass initial=\"simple\"\n",
    "#in the `ses` function\n",
    "np.testing.assert_allclose(fcst_ses['fitted'][[0, 1, -1]], np.array([np.nan, 118 - 6., 432 + 31.447525]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ses, name = 'ses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple (or single) exponential smoothing**: Uses a weighted average of all past observations where the weights decrease exponentially into the past. Suitable for data with no clear trend or seasonality. Assuming there are $t$ observations, the one-step forecast is given by\n",
    "\n",
    "$$\\hat{y}_{t+1}= \\alpha y_{t} + \\alpha(1-\\alpha)y_{t-1} + \\alpha(1-\\alpha)^2 y_{t-2} \\dots$$\n",
    "\n",
    "which can also be written as \n",
    "\n",
    "$$\\hat{y}_{t+1} = \\alpha y_t + \\alpha(1-\\alpha) \\hat{y}_{t-1}$$\n",
    "\n",
    "The rate $0 \\leq \\alpha \\leq 1$ at which the weights decrease is called the smoothing parameter. When $\\alpha = 1$, SES is equal to the naive method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ses_optimized(X: np.ndarray, # time series \n",
    "                  h: int, # forecasting horizon\n",
    "                  future_xreg: np.ndarray, # future regressors\n",
    "                  fitted: bool): # fitted values\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    fcst, res = _optimized_ses_forecast(y, [(0.01, 0.99)])\n",
    "    mean = np.full(h, fcst, np.float32)\n",
    "    fcst = {'mean': mean}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fcst_ses_optimized = ses_optimized(ap, 12, None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ses_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple exponential smoothing optimized**: A version of SES where the smoothing parameter $\\alpha$ is chosen automatically by minimizing the mean squared error of the fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def seasonal_exponential_smoothing_(X: np.ndarray, # time series\n",
    "                                   h: int, # forecasting horizon \n",
    "                                   future_xreg: np.ndarray, # future regressors \n",
    "                                   fitted: bool, # fitted values \n",
    "                                   season_length: int, # length of season\n",
    "                                   alpha: float): # smoothing parameter\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if y.size < season_length:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    season_vals = np.empty(season_length, np.float32)\n",
    "    fitted_vals = np.full(y.size, np.nan, np.float32)\n",
    "    for i in range(season_length):\n",
    "        season_vals[i], fitted_vals[i::season_length] = _ses_forecast(y[i::season_length], alpha)\n",
    "    out = np.empty(h, np.float32)\n",
    "    for i in range(h):\n",
    "        out[i] = season_vals[i % season_length]\n",
    "    fcst = {'mean': out}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def seasonal_exponential_smoothing(X: np.ndarray, # time series\n",
    "                                   h: int, # forecasting horizon \n",
    "                                   future_xreg: np.ndarray, # future regressors \n",
    "                                   fitted: bool, # fitted values \n",
    "                                   season_length: int, # length of season\n",
    "                                   alpha: float): # smoothing parameter\n",
    "    \n",
    "    return seasonal_exponential_smoothing_(X,h,future_xreg,fitted,season_length,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# `seasonal_exponential_smoothing`\n",
    "# should recover seasonal_naive when alpha=1.\n",
    "fcst_seas_ses = seasonal_exponential_smoothing(ap, 12, None, True, 12, 1.)\n",
    "test_eq(fcst_seas_ses['fitted'][-3:],  np.array([461 - 54., 390 - 28., 432 - 27.]))\n",
    "#np.testing.assert_array_equal(\n",
    "#    fcst_seas_ses['fitted'], \n",
    "#    fcst_seas_naive['fitted']\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(seasonal_exponential_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seasonal exponential smoothing**: A seasonal version of exponential smoothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def seasonal_ses_optimized(X: np.ndarray, # time series \n",
    "                           h: int, # forecasting horizon\n",
    "                           future_xreg: np.ndarray, # future regressors  \n",
    "                           fitted: bool , # fitted values \n",
    "                           season_length: int): # season length\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if y.size < season_length:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    season_vals = np.empty(season_length, np.float32)\n",
    "    fitted_vals = np.full(y.size, np.nan, np.float32)\n",
    "    for i in range(season_length):\n",
    "        season_vals[i], fitted_vals[i::season_length] = _optimized_ses_forecast(y[i::season_length], [(0.01, 0.99)])\n",
    "    out = np.empty(h, np.float32)\n",
    "    for i in range(h):\n",
    "        out[i] = season_vals[i % season_length]\n",
    "    fcst = {'mean': out}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fcst_seas_seas_opt = seasonal_ses_optimized(ap, 12, None, True, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(seasonal_ses_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seasonal SES optimized**: A seasonal version of SES optimized "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def historic_average_(X: np.ndarray, # time series \n",
    "                     h: int, # forecasting horizon\n",
    "                     future_xreg: np.ndarray, # future regressors\n",
    "                     fitted: bool): # fitted values\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    mean = np.repeat(y.mean(), h)\n",
    "    fcst = {'mean': mean}\n",
    "    if fitted:\n",
    "        fitted_vals = np.full(y.size, np.nan, y.dtype)\n",
    "        fitted_vals[1:] = y.cumsum()[:-1] / np.arange(1, y.size)\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def historic_average(X: np.ndarray, # time series \n",
    "                     h: int, # forecasting horizon\n",
    "                     future_xreg: np.ndarray, # future regressors\n",
    "                     fitted: bool): # fitted values\n",
    "    \n",
    "    return historic_average_(X, h, future_xreg, fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fcst_ha = historic_average(ap, 12, None, True)\n",
    "test_eq(fcst_ha['mean'], np.repeat(ap.mean(), 12))\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_ha['fitted'][:4],\n",
    "    np.array([np.nan, 112., 115., 120.6666667])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(historic_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historic average:** Also known as mean method. Uses a simple average of all past observations. Assuming there are $t$ observations, the one-step forecast is given by \n",
    "\n",
    "$$ \\hat{y}_{t+1} = \\frac{1}{t} \\sum_{j=1}^t y_j $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def naive_(X: np.ndarray, # time series\n",
    "          h: int, # forecasting horizon\n",
    "          future_xreg: np.ndarray, # future regressors \n",
    "          fitted: bool): # fitted values \n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    mean = np.repeat(y[-1], h).astype(np.float32)\n",
    "    if fitted:\n",
    "        fitted_vals = np.full(y.size, np.nan, np.float32)\n",
    "        fitted_vals[1:] = np.roll(y, 1)[1:]\n",
    "        return {'mean': mean, 'fitted': fitted_vals}\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def naive(X: np.ndarray, # time series\n",
    "          h: int, # forecasting horizon\n",
    "          future_xreg: np.ndarray, # future regressors \n",
    "          fitted: bool): # fitted values \n",
    "    \n",
    "    return naive_(X, h, future_xreg, fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive**: A random walk model, defined as \n",
    "\n",
    "$$ \\hat{y}_{t+1} = y_t $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def random_walk_with_drift_(X: np.ndarray, # time series\n",
    "                           h: int, # forecasting horizon\n",
    "                           future_xreg: np.ndarray, # future regressors\n",
    "                           fitted: bool): # fitted values\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    slope = (y[-1] - y[0]) / (y.size - 1)\n",
    "    mean = slope * (1 + np.arange(h)) + y[-1]\n",
    "    fcst = {'mean': mean.astype(np.float32)}\n",
    "    if fitted:\n",
    "        fitted_vals = np.full(y.size, np.nan, dtype=np.float32)\n",
    "        fitted_vals[1:] = (slope + y[:-1]).astype(np.float32)\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def random_walk_with_drift(X: np.ndarray, # time series\n",
    "                           h: int, # forecasting horizon\n",
    "                           future_xreg: np.ndarray, # future regressors\n",
    "                           fitted: bool): # fitted values\n",
    "    \n",
    "    return random_walk_with_drift_(X, h, future_xreg, fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fcst_rwd = random_walk_with_drift(ap, 12, None, True)\n",
    "test_close(fcst_rwd['mean'][:2], np.array([434.2378, 436.4755]), eps=1e-4)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_rwd['fitted'][:3], \n",
    "    np.array([np.nan, 118 - 3.7622378, 132 - 11.7622378]),\n",
    "    decimal=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(random_walk_with_drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random walk with drift**: A variation of the naive method allows the forecasts to change over time. The amout of change, called drift, is the average change seen in the historical data. \n",
    "\n",
    "$$ \\hat{y}_{t+1} = y_t+\\frac{1}{t-1}\\sum_{j=1}^t (y_j-y_{j-1}) = y_t+ \\frac{y_t-y_1}{t-1} $$\n",
    "\n",
    "From the previous equation, we can see that this is equivalent to extrapolating a line between the first and the last observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def seasonal_naive_(X: np.ndarray, # time series\n",
    "                   h: int, # forecasting horizon\n",
    "                   future_xreg: np.ndarray, #future regressors\n",
    "                   fitted: bool, #fitted values \n",
    "                   season_length: int): # season length\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if y.size < season_length:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    season_vals = np.empty(season_length, np.float32)\n",
    "    fitted_vals = np.full(y.size, np.nan, np.float32)\n",
    "    for i in range(season_length):\n",
    "        s_naive = naive_(y[i::season_length], 1, None, fitted)\n",
    "        season_vals[i] = s_naive['mean'].item()\n",
    "        if fitted:\n",
    "            fitted_vals[i::season_length] = s_naive['fitted']\n",
    "    out = np.empty(h, np.float32)\n",
    "    for i in range(h):\n",
    "        out[i] = season_vals[i % season_length]\n",
    "    fcst = {'mean': out}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def seasonal_naive(X: np.ndarray, # time series\n",
    "                   h: int, # forecasting horizon\n",
    "                   future_xreg: np.ndarray, #future regressors\n",
    "                   fitted: bool, #fitted values \n",
    "                   season_length: int): # length of season\n",
    "    \n",
    "    return seasonal_naive_(X, h, future_xreg, fitted, season_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fcst_seas_naive = seasonal_naive(ap, 12, None, True, 12)\n",
    "test_eq(fcst_seas_naive['fitted'][-3:], np.array([461 - 54., 390 - 28., 432 - 27.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(seasonal_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seasonal naive**: Similar to the naive method, but uses the last known observation of the same period (e.g. the same month of the previous year) in order to capture seasonal variations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def window_average_(X: np.ndarray, # time series \n",
    "                   h: int, # forecasting horizon \n",
    "                   future_xreg: np.ndarray, # future regressors\n",
    "                   fitted: bool, # fitted values\n",
    "                   window_size: int): # window size\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if y.size < window_size:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    wavg = y[-window_size:].mean()\n",
    "    mean = np.repeat(wavg, h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def window_average(X: np.ndarray, # time series \n",
    "                   h: int, # forecasting horizon \n",
    "                   future_xreg: np.ndarray, # future regressors\n",
    "                   fitted: bool, # fitted values\n",
    "                   window_size: int): # window size\n",
    "    \n",
    "    return window_average_(X, h, future_xreg, fitted, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(window_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Window average**: Uses the average of the last $k$ observations, with $k$ the length of the window. Wider windows will capture global trends, while narrow windows will reveal local trends. The length of the window selected should take into account the importance of past observations and how fast the series changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def seasonal_window_average_(\n",
    "    X: np.ndarray,\n",
    "    h: int,\n",
    "    future_xreg: np.ndarray,\n",
    "    fitted: bool,\n",
    "    season_length: int,\n",
    "    window_size: int,\n",
    ") -> np.ndarray:\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    min_samples = season_length * window_size\n",
    "    if y.size < min_samples:\n",
    "        return {'mean': np.full(h, np.nan, np.float32)}\n",
    "    season_avgs = np.zeros(season_length, np.float32)\n",
    "    for i, value in enumerate(y[-min_samples:]):\n",
    "        season = i % season_length\n",
    "        season_avgs[season] += value / window_size\n",
    "    out = np.empty(h, np.float32)\n",
    "    for i in range(h):\n",
    "        out[i] = season_avgs[i % season_length]\n",
    "    return {'mean': out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def seasonal_window_average(\n",
    "    X: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    future_xreg: np.ndarray, # future regressors\n",
    "    fitted: bool, # fitted values\n",
    "    season_length: int, # length of season\n",
    "    window_size: int, # window size\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    return seasonal_window_average_(X,h,future_xreg, fitted, season_length, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(seasonal_window_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seasonal window average**: An average of the last $k$ observations of the same period, with $k$ the length of the window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse or intermittent series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse or intermittent series are series with very few non-zero observations. They are notoriously hard to forecast, and so, different methods have been developed especifically for them. Before the development of Croston's method and its variants, SES was usually used to forecast them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def adida(X: np.ndarray, # time series\n",
    "          h: int, # forecasting horizon\n",
    "          future_xreg: np.ndarray, # future regressors \n",
    "          fitted: bool): # fitted values\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return {'mean': np.repeat(np.float32(0), h)}\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean()\n",
    "    aggregation_level = round(mean_interval)\n",
    "    lost_remainder_data = len(y) % aggregation_level\n",
    "    y_cut = y[lost_remainder_data:]\n",
    "    aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "    sums_forecast, _ = _optimized_ses_forecast(aggregation_sums)\n",
    "    forecast = sums_forecast / aggregation_level\n",
    "    mean = np.repeat(forecast, h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(adida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate-Dissagregate Intermittent Demand Approach**: Uses temporal aggregation to reduce the number of zero observations. Once the data has been agregated, it uses the optimized SES to generate the forecasts at the new level. It then breaks down the forecast to the original level using equal weights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def croston_classic_(X: np.ndarray, # time series\n",
    "                    h: int, # forecasting horizon  \n",
    "                    future_xreg: np.ndarray, # future regressors\n",
    "                    fitted: bool): # fitted values\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    yd = _demand(y)\n",
    "    yi = _intervals(y)\n",
    "    ydp, _ = _ses_forecast(yd, 0.1)\n",
    "    yip, _ = _ses_forecast(yi, 0.1)\n",
    "    mean = ydp / yip\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def croston_classic(X: np.ndarray, # time series\n",
    "                    h: int, # forecasting horizon  \n",
    "                    future_xreg: np.ndarray, # future regressors\n",
    "                    fitted: bool): # fitted values\n",
    "    \n",
    "    return croston_classic_(X, h, future_xreg, fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(croston_classic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Croston classic**: A method to forecast time series that exhibit intermittent demand. It decomposes the original time series into a non-zero demand size $z_t$ and inter-demand intervals $p_t$. Then the forecast is given by \n",
    "\n",
    "$$ \\hat{y}_t = \\frac{\\hat{z}_t}{\\hat{p}_t} $$ \n",
    "\n",
    "where $\\hat{z}_t$ and $\\hat{p}_t$ are forecasted using SES. The smoothing parameter of both components is set equal to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def croston_optimized(X: np.ndarray, # time series\n",
    "                      h: int, # forecasting horizon\n",
    "                      future_xreg: np.ndarray, # future regressors\n",
    "                      fitted: bool): # fitted values\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    yd = _demand(y)\n",
    "    yi = _intervals(y)\n",
    "    ydp, _ = _optimized_ses_forecast(yd)\n",
    "    yip, _ = _optimized_ses_forecast(yi)\n",
    "    mean = ydp / yip\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(croston_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Croston Optimized**: A variation of the classic Croston's method where the smooting paramater is optimally selected from the range $[0.1,0.3]$. Both the non-zero demand $z_t$ and the inter-demand intervals $p_t$ are smoothed separately, so their smoothing parameters can be different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def croston_sba_(X: np.ndarray, # time series\n",
    "                h: int, # forecasting horizon\n",
    "                future_xreg: np.ndarray, # future regressors\n",
    "                fitted: bool): # fitted values\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    mean = croston_classic_(y, h, future_xreg, fitted)\n",
    "    mean['mean'] *= 0.95\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def croston_sba(X: np.ndarray, # time series\n",
    "                h: int, # forecasting horizon\n",
    "                future_xreg: np.ndarray, # future regressors\n",
    "                fitted: bool): # fitted values\n",
    "    \n",
    "    return croston_sba_(X, h, future_xreg, fitted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(croston_sba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Croston with Syntetos-Boylan Approximation**: A variation of the classic Croston's method that uses a debiasing factor, so that the forecast is given by \n",
    "\n",
    "$$ \\hat{y}_t = 0.95  \\frac{\\hat{z}_t}{\\hat{p}_t} $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def imapa(X: np.ndarray, # time series\n",
    "          h: int, # forecasting horizon\n",
    "          future_xreg: np.ndarray, # future regressors \n",
    "          fitted: bool): # fitted values\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return {'mean': np.repeat(np.float32(0), h)}\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean().item()\n",
    "    max_aggregation_level = round(mean_interval)\n",
    "    forecasts = np.empty(max_aggregation_level, np.float32)\n",
    "    for aggregation_level in range(1, max_aggregation_level + 1):\n",
    "        lost_remainder_data = len(y) % aggregation_level\n",
    "        y_cut = y[lost_remainder_data:]\n",
    "        aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "        forecast, _ = _optimized_ses_forecast(aggregation_sums)\n",
    "        forecasts[aggregation_level - 1] = (forecast / aggregation_level)\n",
    "    forecast = forecasts.mean()\n",
    "    mean = np.repeat(forecast, h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(imapa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intermittent Multiple Aggregation Prediction Algorithm**: Similar to ADIDA, but instead of using a single aggregation level, it considers multiple in order to capture different dynamics of the data. Uses the optimized SES to generate the forecasts at the new levels and then combines them using a simple average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "@njit\n",
    "def tsb_(X: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon \n",
    "        future_xreg: np.ndarray, # future regressors\n",
    "        fitted: int, # fitted values \n",
    "        alpha_d: float,\n",
    "        alpha_p: float):\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    y = X[:, 0] if X.ndim == 2 else X\n",
    "    if (y == 0).all():\n",
    "        return {'mean': np.repeat(np.float32(0), h)}\n",
    "    yd = _demand(y)\n",
    "    yp = _probability(y)\n",
    "    ypf, _ = _ses_forecast(yp, alpha_p)\n",
    "    ydf, _ = _ses_forecast(yd, alpha_d)\n",
    "    forecast = np.float32(ypf * ydf)\n",
    "    mean = np.repeat(forecast, h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#@njit\n",
    "def tsb(X: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon \n",
    "        future_xreg: np.ndarray, # future regressors\n",
    "        fitted: int, # fitted values \n",
    "        alpha_d: float,\n",
    "        alpha_p: float):\n",
    "    \n",
    "    return tsb_(X, h, future_xreg, fitted, alpha_d, alpha_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(tsb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teunter-Syntetos-Babai**: A modification of Croston's method that replaces the inter-demand intervals with the demand probability $d_t$, which is defined as follows. \n",
    "\n",
    "$$\n",
    "d_t = \\begin{cases}\n",
    "    1  & \\text{if demand occurs at time t}\\\\ \n",
    "    0 & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Hence, the forecast is given by \n",
    "\n",
    "$$\\hat{y}_t= \\hat{d}_t\\hat{z_t}$$\n",
    "\n",
    "Both $d_t$ and $z_t$ are forecasted using SES. The smooting paramaters of each may differ, like in the optimized Croston's method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **General**\n",
    "- Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. [OTexts.com/fpp3](https://otexts.com/fpp3/). Accessed on July 2022.\n",
    "\n",
    "- Shmueli, G., & Lichtendahl Jr, K. C. (2016). Practical time series forecasting with r: A hands-on guide. Axelrod Schnall Publishers.\n",
    "\n",
    "#### **For sparse or intermittent series**\n",
    "\n",
    "- [Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.](https://link.springer.com/article/10.1057/jors.1972.50)\n",
    "\n",
    "\n",
    "- [Nikolopoulos, K., Syntetos, A. A., Boylan, J. E., Petropoulos, F., & Assimakopoulos, V. (2011). An aggregateâ€“disaggregate intermittent demand approach (ADIDA) to forecasting: an empirical proposition and analysis. Journal of the Operational Research Society, 62(3), 544-554.](https://researchportal.bath.ac.uk/en/publications/an-aggregate-disaggregate-intermittent-demand-approach-adida-to-f)\n",
    "\n",
    "- [Syntetos, A. A., & Boylan, J. E. (2005). The accuracy of intermittent demand estimates. International Journal of forecasting, 21(2), 303-314.](https://www.academia.edu/1527250/The_accuracy_of_intermittent_demand_estimates)\n",
    "\n",
    "- Syntetos, A. A., & Boylan, J. E. (2021). Intermittent demand forecasting: Context, methods and applications. John Wiley & Sons.\n",
    "\n",
    "- [Teunter, R. H., Syntetos, A. A., & Babai, M. Z. (2011). Intermittent demand: Linking forecasting to inventory obsolescence. European Journal of Operational Research, 214(3), 606-615.](https://www.sciencedirect.com/science/article/abs/pii/S0377221711004437)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima(ap, 12, season_length=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets(ap, 12, season_length=12, fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = np.arange(1, ap.size + 1)\n",
    "X = np.vstack([ap, np.log(drift), np.sqrt(drift)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdrift = np.arange(ap.size + 1, ap.size + 7 + 1).reshape(-1, 1)\n",
    "newxreg = np.concatenate([np.log(newdrift), np.sqrt(newdrift)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima(X, 7, future_xreg=newxreg, season_length=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(auto_arima(ap, 12, season_length=12, level=(80, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
