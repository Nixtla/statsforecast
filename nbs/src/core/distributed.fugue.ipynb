{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp distributed.fugue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15392f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa25a4",
   "metadata": {},
   "source": [
    "# FugueBackend\n",
    "\n",
    "The computational efficiency of `StatsForecast` can be tracked to its two core components:\n",
    "1. Its `models` written in NumBa that optimizes Python code to reach C speeds.\n",
    "2. Its `core.StatsForecast` class that enables distributed computing.\n",
    "\n",
    "Here we use [Fugue](https://github.com/fugue-project/fugue) which is a unified interface for `Dask` and `Spark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06732b96-bd80-4a4d-b9a2-4f95c7a82331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import fugue.api as fa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fugue import transform, DataFrame, FugueWorkflow, ExecutionEngine, AnyDataFrame\n",
    "from fugue.collections.yielded import Yielded\n",
    "from fugue.constants import FUGUE_CONF_WORKFLOW_EXCEPTION_INJECT\n",
    "from triad import Schema\n",
    "\n",
    "import statsforecast.config as sf_config\n",
    "from statsforecast.core import _StatsForecast, ParallelBackend, _param_descriptions, make_backend\n",
    "from statsforecast.utils import ConformalIntervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a14ea-b3e7-466c-bd38-ab94ebbd279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _cotransform(\n",
    "    df1: Any,\n",
    "    df2: Any,\n",
    "    using: Any,\n",
    "    schema: Any = None,\n",
    "    params: Any = None,\n",
    "    partition: Any = None,\n",
    "    engine: Any = None,\n",
    "    engine_conf: Any = None,\n",
    "    force_output_fugue_dataframe: bool = False,\n",
    "    as_local: bool = False,\n",
    ") -> Any:\n",
    "    dag = FugueWorkflow(compile_conf={FUGUE_CONF_WORKFLOW_EXCEPTION_INJECT: 0})\n",
    "    \n",
    "    src = dag.create_data(df1).zip(dag.create_data(df2), partition=partition)\n",
    "    tdf = src.transform(\n",
    "        using=using,\n",
    "        schema=schema,\n",
    "        params=params,\n",
    "        pre_partition=partition,\n",
    "    )\n",
    "    tdf.yield_dataframe_as(\"result\", as_local=as_local)\n",
    "    dag.run(engine, conf=engine_conf)\n",
    "    result = dag.yields[\"result\"].result  # type:ignore\n",
    "    if force_output_fugue_dataframe or isinstance(df1, (DataFrame, Yielded)):\n",
    "        return result\n",
    "    return result.as_pandas() if result.is_local else result.native  # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d5b82-2be9-41f5-8cd0-3903d0761e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FugueBackend(ParallelBackend):\n",
    "    \"\"\"FugueBackend for Distributed Computation.\n",
    "    [Source code](https://github.com/Nixtla/statsforecast/blob/main/statsforecast/distributed/fugue.py).\n",
    "\n",
    "    This class uses [Fugue](https://github.com/fugue-project/fugue) backend capable of distributing \n",
    "    computation on Spark, Dask and Ray without any rewrites.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    engine : fugue.ExecutionEngine\n",
    "        A selection between Spark, Dask, and Ray.\n",
    "    conf : fugue.Config\n",
    "        Engine configuration.\n",
    "    **transform_kwargs\n",
    "        Additional kwargs for Fugue's transform method.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    A short introduction to Fugue, with examples on how to scale pandas code to Spark, Dask or Ray\n",
    "     is available [here](https://fugue-tutorials.readthedocs.io/tutorials/quick_look/ten_minutes.html).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            engine: Any = None,\n",
    "            conf: Any = None,\n",
    "            **transform_kwargs: Any\n",
    "        ):        \n",
    "        self._engine = engine\n",
    "        self._conf = conf\n",
    "        self._transform_kwargs = dict(transform_kwargs)\n",
    "\n",
    "    def __getstate__(self) -> Dict[str, Any]:\n",
    "        return {}\n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        *,\n",
    "        df: AnyDataFrame,\n",
    "        freq: Union[str, int],\n",
    "        models: List[Any],\n",
    "        fallback_model: Optional[Any],\n",
    "        X_df: Optional[AnyDataFrame],\n",
    "        h: int,\n",
    "        level: Optional[List[int]],\n",
    "        fitted: bool,\n",
    "        prediction_intervals: Optional[ConformalIntervals],\n",
    "        id_col: str,\n",
    "        time_col: str,\n",
    "        target_col: str,\n",
    "    ) -> Any:\n",
    "        \"\"\"Memory Efficient core.StatsForecast predictions with FugueBackend.\n",
    "\n",
    "        This method uses Fugue's transform function, in combination with \n",
    "        `core.StatsForecast`'s forecast to efficiently fit a list of StatsForecast models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        {df}\n",
    "        {freq}\n",
    "        {models}\n",
    "        {fallback_model}\n",
    "        {X_df}\n",
    "        {h}\n",
    "        {level}\n",
    "        {fitted}\n",
    "        {prediction_intervals}\n",
    "        {id_col}\n",
    "        {time_col}\n",
    "        {target_col}\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fcsts_df : pandas.DataFrame\n",
    "            DataFrame with `models` columns for point predictions and probabilistic predictions for all fitted `models`\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        For more information check the \n",
    "        [Fugue's transform](https://fugue-tutorials.readthedocs.io/tutorials/beginner/transform.html)\n",
    "        tutorial.\n",
    "        The [core.StatsForecast's forecast](https://nixtla.github.io/statsforecast/core.html#statsforecast.forecast)\n",
    "        method documentation.\n",
    "        Or the list of available [StatsForecast's models](https://nixtla.github.io/statsforecast/src/core/models.html).\n",
    "        \"\"\"\n",
    "        schema = self._get_output_schema(\n",
    "            df=df,\n",
    "            models=models,\n",
    "            level=level,\n",
    "            mode='forecast',\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        params = dict(\n",
    "            models=models,\n",
    "            freq=freq,\n",
    "            fallback_model=fallback_model,\n",
    "            h=h,\n",
    "            level=level,\n",
    "            fitted=fitted,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        if X_df is None:\n",
    "            res = transform(\n",
    "                df,\n",
    "                self._forecast_series,\n",
    "                params=params,\n",
    "                schema=schema,\n",
    "                partition={\"by\": id_col},\n",
    "                engine=self._engine,\n",
    "                engine_conf=self._conf,\n",
    "            )\n",
    "        else:\n",
    "            res = _cotransform(\n",
    "                df,\n",
    "                X_df,\n",
    "                self._forecast_series_X,\n",
    "                params=params,\n",
    "                schema=schema,\n",
    "                partition={\"by\": id_col},\n",
    "                engine=self._engine,\n",
    "                engine_conf=self._conf,\n",
    "            )\n",
    "        return res\n",
    "\n",
    "    forecast.__doc__ = forecast.__doc__.format(**_param_descriptions)  # type: ignore[union-attr]\n",
    "\n",
    "    def cross_validation(\n",
    "        self,\n",
    "        *,\n",
    "        df: AnyDataFrame,        \n",
    "        freq: Union[str, int],\n",
    "        models: List[Any],\n",
    "        fallback_model: Optional[Any],        \n",
    "        h: int,\n",
    "        n_windows: int,\n",
    "        step_size: int,\n",
    "        test_size: int,\n",
    "        input_size: int,\n",
    "        level: Optional[List[int]],\n",
    "        refit: bool,\n",
    "        fitted: bool,\n",
    "        prediction_intervals: Optional[ConformalIntervals],\n",
    "        id_col: str,\n",
    "        time_col: str,\n",
    "        target_col: str,\n",
    "    ) -> Any:\n",
    "        \"\"\"Temporal Cross-Validation with core.StatsForecast and FugueBackend.\n",
    "\n",
    "        This method uses Fugue's transform function, in combination with \n",
    "        `core.StatsForecast`'s cross-validation to efficiently fit a list of StatsForecast \n",
    "        models through multiple training windows, in either chained or rolled manner.\n",
    "\n",
    "        `StatsForecast.models`' speed along with Fugue's distributed computation allow to \n",
    "        overcome this evaluation technique high computational costs. Temporal cross-validation \n",
    "        provides better model's generalization measurements by increasing the test's length \n",
    "        and diversity.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        {df}\n",
    "        {freq}\n",
    "        {models}\n",
    "        {fallback_model}\n",
    "        {h}\n",
    "        {n_windows}\n",
    "        {step_size}\n",
    "        {test_size}\n",
    "        {input_size}\n",
    "        {level}\n",
    "        {refit}\n",
    "        {fitted}\n",
    "        {prediction_intervals}\n",
    "        {id_col}\n",
    "        {time_col}\n",
    "        {target_col}\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            DataFrame, with `models` columns for point predictions and probabilistic predictions for all fitted `models`.\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        The [core.StatsForecast's cross validation](https://nixtla.github.io/statsforecast/core.html#statsforecast.cross_validation)\n",
    "        method documentation.\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Temporal Cross-Validation\"](https://otexts.com/fpp3/tscv.html).\n",
    "        \"\"\"\n",
    "        schema = self._get_output_schema(\n",
    "            df=df,\n",
    "            models=models,\n",
    "            level=level,\n",
    "            mode='cv',\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        return transform(\n",
    "            df,\n",
    "            self._cv,\n",
    "            params=dict(\n",
    "                models=models,\n",
    "                freq=freq,\n",
    "                fallback_model=fallback_model,\n",
    "                h=h,\n",
    "                n_windows=n_windows,\n",
    "                step_size=step_size,\n",
    "                test_size=test_size,\n",
    "                input_size=input_size,\n",
    "                level=level,\n",
    "                refit=refit,\n",
    "                fitted=fitted,\n",
    "                prediction_intervals=prediction_intervals,\n",
    "                id_col=id_col,\n",
    "                time_col=time_col,\n",
    "                target_col=target_col,              \n",
    "            ),\n",
    "            schema=schema,\n",
    "            partition={\"by\": id_col},\n",
    "            engine=self._engine,\n",
    "            engine_conf=self._conf,\n",
    "            **self._transform_kwargs,\n",
    "        )\n",
    "\n",
    "    cross_validation.__doc__ = cross_validation.__doc__.format(**_param_descriptions)  # type: ignore[union-attr]\n",
    "\n",
    "    def _forecast_series(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        *,\n",
    "        models,\n",
    "        fallback_model,        \n",
    "        freq,\n",
    "        h,\n",
    "        level,\n",
    "        fitted,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> pd.DataFrame:\n",
    "        model = _StatsForecast(\n",
    "            models=models,\n",
    "            freq=freq, \n",
    "            fallback_model=fallback_model,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "        result = model.forecast(\n",
    "            df=df,\n",
    "            h=h,\n",
    "            X_df=None,\n",
    "            level=level,\n",
    "            fitted=fitted,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        if sf_config.id_as_index:\n",
    "            result = result.reset_index()\n",
    "        return result\n",
    "\n",
    "    def _forecast_series_X(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        X_df: pd.DataFrame,\n",
    "        *,\n",
    "        models,\n",
    "        fallback_model,        \n",
    "        freq,\n",
    "        h,\n",
    "        level,\n",
    "        fitted,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> pd.DataFrame:\n",
    "        model = _StatsForecast(\n",
    "            models=models,\n",
    "            freq=freq, \n",
    "            fallback_model=fallback_model,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "        result = model.forecast(\n",
    "            df=df,\n",
    "            X_df=X_df,\n",
    "            h=h,\n",
    "            level=level,\n",
    "            fitted=fitted,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,            \n",
    "        )\n",
    "        if sf_config.id_as_index:\n",
    "            result = result.reset_index()\n",
    "        return result\n",
    "\n",
    "    def _cv(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        *,\n",
    "        models,\n",
    "        freq,\n",
    "        fallback_model,\n",
    "        h,\n",
    "        n_windows,\n",
    "        step_size,\n",
    "        test_size,\n",
    "        input_size,\n",
    "        level,\n",
    "        refit,\n",
    "        fitted,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> pd.DataFrame:\n",
    "        model = _StatsForecast(\n",
    "            models=models,\n",
    "            freq=freq, \n",
    "            fallback_model=fallback_model,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "        result = model.cross_validation(\n",
    "            df=df,\n",
    "            h=h,\n",
    "            n_windows=n_windows,\n",
    "            step_size=step_size,\n",
    "            test_size=test_size,\n",
    "            input_size=input_size,\n",
    "            level=level,\n",
    "            fitted=fitted,\n",
    "            refit=refit,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        if sf_config.id_as_index:\n",
    "            result = result.reset_index()\n",
    "        return result\n",
    "\n",
    "    def _get_output_schema(\n",
    "        self,\n",
    "        *,\n",
    "        df,\n",
    "        models,\n",
    "        level,\n",
    "        mode,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> Schema:\n",
    "        keep_schema = fa.get_schema(df).extract([id_col, time_col])\n",
    "        cols: List[Any] = []\n",
    "        if level is None:\n",
    "            level = []\n",
    "        for model in models:\n",
    "            has_levels = (\n",
    "                \"level\" in inspect.signature(getattr(model, \"forecast\")).parameters\n",
    "                and len(level) > 0\n",
    "            )\n",
    "            cols.append((repr(model), np.float32))\n",
    "            if has_levels:\n",
    "                cols.extend([(f\"{repr(model)}-lo-{l}\", np.float32) for l in reversed(level)])\n",
    "                cols.extend([(f\"{repr(model)}-hi-{l}\", np.float32) for l in level])\n",
    "        if mode == \"cv\":\n",
    "            cols = [(\"cutoff\", keep_schema[time_col].type), (target_col, np.float32)] + cols\n",
    "        return keep_schema + Schema(cols)\n",
    "\n",
    "\n",
    "@make_backend.candidate(lambda obj, *args, **kwargs: isinstance(obj, ExecutionEngine))\n",
    "def _make_fugue_backend(obj:ExecutionEngine, *args, **kwargs) -> ParallelBackend:\n",
    "    return FugueBackend(obj, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ba783-2d77-47de-aa85-fd41ec068889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import ( \n",
    "    AutoARIMA,\n",
    "    AutoETS,\n",
    ")\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5549b2-14d3-4bb6-9247-6e66acca8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_series = 4\n",
    "horizon = 7\n",
    "\n",
    "series = generate_series(n_series)\n",
    "\n",
    "sf = StatsForecast(\n",
    "    models=[AutoETS(season_length=7)],\n",
    "    freq='D',\n",
    ")\n",
    "\n",
    "sf.cross_validation(df=series, h=horizon, step_size = 24,\n",
    "    n_windows = 2, level=[90]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d3791-9d0a-4510-900e-51db0b5abe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd5dc4-54c8-4022-a85d-69583fc6bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Make unique_id a column\n",
    "series['unique_id'] = series['unique_id'].astype(str)\n",
    "\n",
    "# Convert to Spark\n",
    "sdf = spark.createDataFrame(series)\n",
    "\n",
    "# Returns a Spark DataFrame\n",
    "sf.cross_validation(df=sdf, h=horizon, step_size = 24,\n",
    "    n_windows = 2, level=[90]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53913de1-81b9-401c-93a2-83e42047e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FugueBackend, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97656b86-ae6d-4f5a-b9ff-32091a093942",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FugueBackend.forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65067ded-be81-4ce6-b459-702b76ddc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FugueBackend.cross_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037f72d-4ace-44e8-b4d5-b8399d5e294d",
   "metadata": {},
   "source": [
    "## Dask Distributed Predictions\n",
    "\n",
    "Here we provide an example for the distribution of the `StatsForecast` predictions using `Fugue` to execute the code in a Dask cluster.\n",
    "\n",
    "To do it we instantiate the `FugueBackend` class with a `DaskExecutionEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e38ec9-b093-40fe-9a31-85d84ccb1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from fugue_dask import DaskExecutionEngine\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0174b4d3-1262-48ca-9ca1-9f1ace044b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic Panel Data\n",
    "df = generate_series(10).reset_index()\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = dd.from_pandas(df, npartitions=10)\n",
    "\n",
    "# Instantiate FugueBackend with DaskExecutionEngine\n",
    "dask_client = Client()\n",
    "engine = DaskExecutionEngine(dask_client=dask_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832937cc-2b7b-4ddc-84d0-e68a650bdc12",
   "metadata": {},
   "source": [
    "We have simply create the class to the usual `StatsForecast` instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08c1f2-3b0a-460f-a1a6-1d25d982104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "sf = StatsForecast(models=[Naive()], freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a44ec-787f-4ef7-8129-71409d2dd32a",
   "metadata": {},
   "source": [
    "### Distributed Forecast\n",
    "\n",
    "For extremely fast distributed predictions we use FugueBackend as backend that operates like the original [StatsForecast.forecast](https://nixtla.github.io/statsforecast/src/core/core.html#statsforecast.forecast) method.\n",
    "\n",
    "It receives as input a pandas.DataFrame with columns [`unique_id`,`ds`,`y`] and exogenous, where the `ds` (datestamp) column should be of a format expected by Pandas. The `y` column must be numeric, and represents the measurement we wish to forecast. And the `unique_id` uniquely identifies the series in the panel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2454a-7683-40d1-8828-877dba0345fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Distributed predictions with FugueBackend.\n",
    "sf.forecast(df=df, h=12).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e7b42-8129-472a-99fd-0725ae4cb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "sf = StatsForecast(models=[Naive()], freq='D', fallback_model=Naive())\n",
    "dask_fcst = sf.forecast(df=df, h=12).compute()\n",
    "fcst_stats = sf.forecast(df=df.compute(), h=12)\n",
    "test_eq(dask_fcst.sort_values(by=['unique_id', 'ds']).reset_index(drop=True).astype({\"unique_id\": str}), \n",
    "        fcst_stats.reset_index().astype({\"unique_id\": str}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "class ReturnX:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, y, X):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, h, X):\n",
    "        mean = X\n",
    "        return X\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'ReturnX'\n",
    "    \n",
    "    def forecast(self, y, h, X=None, X_future=None, fitted=False):\n",
    "        return {'mean': X_future.flatten()}\n",
    "    \n",
    "    def new(self):\n",
    "        b = type(self).__new__(type(self))\n",
    "        b.__dict__.update(self.__dict__)\n",
    "        return b\n",
    "    \n",
    "df_w_ex = pd.DataFrame(\n",
    "    {\n",
    "        'ds': np.hstack([np.arange(10), np.arange(10)]),\n",
    "        'y': np.random.rand(20),\n",
    "        'x': np.arange(20, dtype=np.float32),\n",
    "    },\n",
    "    index=pd.Index([0] * 10 + [1] * 10, name='unique_id'),\n",
    ").reset_index()\n",
    "train_mask = df_w_ex['ds'] < 6\n",
    "train_df = dd.from_pandas(df_w_ex[train_mask], npartitions=10)\n",
    "test_df = df_w_ex[~train_mask]\n",
    "xreg = dd.from_pandas(test_df.drop(columns='y').reset_index(drop=True), npartitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee084bc4-7303-4dd6-99df-5a23fa7cb419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "fcst_x = StatsForecast(models=[ReturnX()], freq='D')\n",
    "res = fcst_x.forecast(df=train_df, \n",
    "                      X_df=xreg, \n",
    "                      h=4).compute()\n",
    "expected_res = xreg.rename(columns={'x': 'ReturnX'}).compute()\n",
    "# we expect strings for unique_id, and ds using exogenous\n",
    "expected_res[['unique_id', 'ds']] = expected_res[['unique_id', 'ds']].astype(str)\n",
    "pd.testing.assert_frame_equal(res.sort_values('unique_id').reset_index(drop=True), \n",
    "                              expected_res, \n",
    "                              check_dtype=False, \n",
    "                              check_index_type=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4f3de-910d-46eb-842b-579935cfbd10",
   "metadata": {},
   "source": [
    "### Distributed Cross-Validation\n",
    "\n",
    "For extremely fast distributed temporcal cross-validation we use `cross_validation` method that operates like the original [StatsForecast.cross_validation](https://nixtla.github.io/statsforecast/src/core/core.html#statsforecast.cross_validation) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d0a2f-8f3b-45cd-9f25-d8db281db3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Distributed cross-validation with FugueBackend.\n",
    "sf.cross_validation(df=df, h=12, n_windows=2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bc2f1-8ae4-46b3-a324-80a1d1e57dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea06c4d-9577-4c88-9808-8268c08c76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# Generate Synthetic Panel Data.\n",
    "df = generate_series(10).reset_index()\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = dd.from_pandas(df, npartitions=10)\n",
    "\n",
    "# Distribute predictions.\n",
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = sf.forecast(df=df, h=12).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "fcst_stats = sf.forecast(df=df.compute(), h=12).reset_index().astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue, fcst_stats)\n",
    "\n",
    "# Distribute cross-validation predictions.\n",
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = sf.cross_validation(df=df, h=12).compute().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = sf.cross_validation(df=df.compute(), h=12).reset_index().astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue, fcst_stats)\n",
    "\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "    \n",
    "#cross validation fallback model\n",
    "fcst = StatsForecast(models=[FailNaive()], freq='D', fallback_model=Naive())\n",
    "fcst_fugue = fcst.cross_validation(df=df, h=12).compute().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = sf.cross_validation(df=df.compute(), h=12).reset_index().astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue, fcst_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598617b9-2a8c-4fdc-b751-bc43702fa163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# test ray integration\n",
    "import ray\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372bc61-4f39-4c04-8d39-d8270bc89b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# Generate Synthetic Panel Data.\n",
    "df = generate_series(10).reset_index()\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = ray.data.from_pandas(df).repartition(2)\n",
    "\n",
    "# Distribute predictions.\n",
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = sf.forecast(df=df, h=12).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "fcst_stats = sf.forecast(df=df.to_pandas(), h=12).reset_index().astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue, fcst_stats)\n",
    "\n",
    "# Distribute cross-validation predictions.\n",
    "fcst = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = fcst.cross_validation(df=df, h=12).to_pandas().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = sf.cross_validation(df=df.to_pandas(), h=12).reset_index().astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue, fcst_stats)\n",
    "\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "    \n",
    "#cross validation fallback model\n",
    "sf = StatsForecast(models=[FailNaive()], freq='D', fallback_model=Naive())\n",
    "fcst_fugue = sf.cross_validation(df=df, h=12).to_pandas().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = sf.cross_validation(df=df.to_pandas(), h=12).reset_index().astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue, fcst_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628146a-57b0-4b4b-8377-045b08dd2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "sf = StatsForecast(models=[ReturnX()], freq='D')\n",
    "res = sf.forecast(df=train_df, \n",
    "                  X_df=xreg, \n",
    "                  h=4).compute()\n",
    "expected_res = xreg.compute().rename(columns={'x': 'ReturnX'})\n",
    "# we expect strings for unique_id, and ds using exogenous\n",
    "expected_res[['unique_id', 'ds']] = expected_res[['unique_id', 'ds']].astype(str)\n",
    "pd.testing.assert_frame_equal(res.sort_values('unique_id').reset_index(drop=True), \n",
    "                              expected_res, \n",
    "                              check_dtype=False, \n",
    "                              check_index_type=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
