{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp distributed.fugue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15392f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa25a4",
   "metadata": {},
   "source": [
    "# FugueBackend\n",
    "\n",
    "The computational efficiency of `StatsForecast` can be tracked to its two core components:\n",
    "1. Its `models` written in NumBa that optimizes Python code to reach C speeds.\n",
    "2. Its `core.StatsForecast` class that enables distributed computing.\n",
    "\n",
    "Here we use [Fugue](https://github.com/fugue-project/fugue) which is a unified interface for `Dask` and `Spark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06732b96-bd80-4a4d-b9a2-4f95c7a82331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple, Union\n",
    "\n",
    "import cloudpickle\n",
    "import fugue.api as fa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fugue import transform, DataFrame, FugueWorkflow, ExecutionEngine, AnyDataFrame\n",
    "from fugue.collections.yielded import Yielded\n",
    "from fugue.constants import FUGUE_CONF_WORKFLOW_EXCEPTION_INJECT\n",
    "from triad import Schema\n",
    "\n",
    "from statsforecast.core import _StatsForecast, ParallelBackend, _param_descriptions, make_backend\n",
    "from statsforecast.utils import ConformalIntervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a14ea-b3e7-466c-bd38-ab94ebbd279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _cotransform(\n",
    "    df1: Any,\n",
    "    df2: Any,\n",
    "    using: Any,\n",
    "    schema: Any = None,\n",
    "    params: Any = None,\n",
    "    partition: Any = None,\n",
    "    engine: Any = None,\n",
    "    engine_conf: Any = None,\n",
    "    force_output_fugue_dataframe: bool = False,\n",
    "    as_local: bool = False,\n",
    ") -> Any:\n",
    "    dag = FugueWorkflow(compile_conf={FUGUE_CONF_WORKFLOW_EXCEPTION_INJECT: 0})\n",
    "    \n",
    "    src = dag.create_data(df1).zip(dag.create_data(df2), partition=partition)\n",
    "    tdf = src.transform(\n",
    "        using=using,\n",
    "        schema=schema,\n",
    "        params=params,\n",
    "        pre_partition=partition,\n",
    "    )\n",
    "    tdf.yield_dataframe_as(\"result\", as_local=as_local)\n",
    "    dag.run(engine, conf=engine_conf)\n",
    "    result = dag.yields[\"result\"].result  # type:ignore\n",
    "    if force_output_fugue_dataframe or isinstance(df1, (DataFrame, Yielded)):\n",
    "        return result\n",
    "    return result.as_pandas() if result.is_local else result.native  # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d5b82-2be9-41f5-8cd0-3903d0761e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FugueBackend(ParallelBackend):\n",
    "    \"\"\"FugueBackend for Distributed Computation.\n",
    "    [Source code](https://github.com/Nixtla/statsforecast/blob/main/statsforecast/distributed/fugue.py).\n",
    "\n",
    "    This class uses [Fugue](https://github.com/fugue-project/fugue) backend capable of distributing \n",
    "    computation on Spark, Dask and Ray without any rewrites.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    engine : fugue.ExecutionEngine\n",
    "        A selection between Spark, Dask, and Ray.\n",
    "    conf : fugue.Config\n",
    "        Engine configuration.\n",
    "    **transform_kwargs\n",
    "        Additional kwargs for Fugue's transform method.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    A short introduction to Fugue, with examples on how to scale pandas code to Spark, Dask or Ray\n",
    "     is available [here](https://fugue-tutorials.readthedocs.io/tutorials/quick_look/ten_minutes.html).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            engine: Any = None,\n",
    "            conf: Any = None,\n",
    "            **transform_kwargs: Any\n",
    "        ):        \n",
    "        self._engine = engine\n",
    "        self._conf = conf\n",
    "        self._transform_kwargs = dict(transform_kwargs)\n",
    "\n",
    "    def __getstate__(self) -> Dict[str, Any]:\n",
    "        return {}\n",
    "\n",
    "    def _forecast(\n",
    "        self,\n",
    "        *,\n",
    "        df: pd.DataFrame,\n",
    "        X_df: Optional[pd.DataFrame],\n",
    "        models,\n",
    "        fallback_model,        \n",
    "        freq,\n",
    "        h,\n",
    "        level,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "        fitted,\n",
    "    ) -> Tuple[_StatsForecast, pd.DataFrame]:\n",
    "        model = _StatsForecast(\n",
    "            models=models,\n",
    "            freq=freq, \n",
    "            fallback_model=fallback_model,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "        result = model.forecast(\n",
    "            df=df,\n",
    "            h=h,\n",
    "            X_df=X_df,\n",
    "            level=level,\n",
    "            fitted=fitted,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        return model, result\n",
    "\n",
    "    def _forecast_noX(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        *,\n",
    "        models,\n",
    "        fallback_model,        \n",
    "        freq,\n",
    "        h,\n",
    "        level,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> pd.DataFrame:\n",
    "        _, result = self._forecast(\n",
    "            df=df,\n",
    "            X_df=None,\n",
    "            models=models,\n",
    "            fallback_model=fallback_model,\n",
    "            freq=freq,\n",
    "            h=h,\n",
    "            level=level,\n",
    "            fitted=False,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def _forecast_noX_fitted(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        *,\n",
    "        models,\n",
    "        fallback_model,        \n",
    "        freq,\n",
    "        h,\n",
    "        level,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> List[List[Any]]:\n",
    "        model, result = self._forecast(\n",
    "            df=df,\n",
    "            X_df=None,\n",
    "            models=models,\n",
    "            fallback_model=fallback_model,\n",
    "            freq=freq,\n",
    "            h=h,\n",
    "            level=level,\n",
    "            fitted=True,            \n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        fitted_vals = model.forecast_fitted_values()\n",
    "        return [[cloudpickle.dumps(result), cloudpickle.dumps(fitted_vals)]]\n",
    "\n",
    "    def _forecast_X(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        X_df: pd.DataFrame,\n",
    "        *,\n",
    "        models,\n",
    "        fallback_model,        \n",
    "        freq,\n",
    "        h,\n",
    "        level,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> pd.DataFrame:\n",
    "        _, result = self._forecast(\n",
    "            df=df,\n",
    "            X_df=X_df,\n",
    "            models=models,\n",
    "            fallback_model=fallback_model,\n",
    "            freq=freq,\n",
    "            h=h,\n",
    "            level=level,\n",
    "            fitted=False,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def _forecast_X_fitted(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        X_df: pd.DataFrame,\n",
    "        *,\n",
    "        models,\n",
    "        fallback_model,        \n",
    "        freq,\n",
    "        h,\n",
    "        level,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> List[List[Any]]:\n",
    "        model, result = self._forecast(\n",
    "            df=df,\n",
    "            X_df=X_df,\n",
    "            models=models,\n",
    "            fallback_model=fallback_model,\n",
    "            freq=freq,\n",
    "            h=h,\n",
    "            level=level,\n",
    "            fitted=True,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        fitted_vals = model.forecast_fitted_values()\n",
    "        return [[cloudpickle.dumps(result), cloudpickle.dumps(fitted_vals)]]        \n",
    "\n",
    "    def _get_output_schema(\n",
    "        self,\n",
    "        *,\n",
    "        df,\n",
    "        models,\n",
    "        level,\n",
    "        mode,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> Schema:\n",
    "        keep_schema = fa.get_schema(df).extract([id_col, time_col])\n",
    "        cols: List[Any] = []\n",
    "        if level is None:\n",
    "            level = []\n",
    "        for model in models:\n",
    "            has_levels = (\n",
    "                \"level\" in inspect.signature(getattr(model, \"forecast\")).parameters\n",
    "                and len(level) > 0\n",
    "            )\n",
    "            cols.append((repr(model), np.float32))\n",
    "            if has_levels:\n",
    "                cols.extend([(f\"{repr(model)}-lo-{l}\", np.float32) for l in reversed(level)])\n",
    "                cols.extend([(f\"{repr(model)}-hi-{l}\", np.float32) for l in level])\n",
    "        if mode == \"cv\":\n",
    "            cols = [(\"cutoff\", keep_schema[time_col].type), (target_col, np.float32)] + cols\n",
    "        return keep_schema + Schema(cols)\n",
    "\n",
    "    @staticmethod\n",
    "    def _retrieve_forecast_df(items: List[List[Any]]) -> Iterable[pd.DataFrame]:\n",
    "        for serialized_fcst_df, _ in items:\n",
    "            yield cloudpickle.loads(serialized_fcst_df)\n",
    "\n",
    "    @staticmethod\n",
    "    def _retrieve_fitted_df(items: List[List[Any]]) -> Iterable[pd.DataFrame]:\n",
    "        for _, serialized_fitted_df in items:\n",
    "            yield cloudpickle.loads(serialized_fitted_df)    \n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        *,\n",
    "        df: AnyDataFrame,\n",
    "        freq: Union[str, int],\n",
    "        models: List[Any],\n",
    "        fallback_model: Optional[Any],\n",
    "        X_df: Optional[AnyDataFrame],\n",
    "        h: int,\n",
    "        level: Optional[List[int]],\n",
    "        fitted: bool,\n",
    "        prediction_intervals: Optional[ConformalIntervals],\n",
    "        id_col: str,\n",
    "        time_col: str,\n",
    "        target_col: str,\n",
    "    ) -> Any:\n",
    "        \"\"\"Memory Efficient core.StatsForecast predictions with FugueBackend.\n",
    "\n",
    "        This method uses Fugue's transform function, in combination with \n",
    "        `core.StatsForecast`'s forecast to efficiently fit a list of StatsForecast models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        {df}\n",
    "        {freq}\n",
    "        {models}\n",
    "        {fallback_model}\n",
    "        {X_df}\n",
    "        {h}\n",
    "        {level}\n",
    "        {fitted}\n",
    "        {prediction_intervals}\n",
    "        {id_col}\n",
    "        {time_col}\n",
    "        {target_col}\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fcsts_df : pandas.DataFrame\n",
    "            DataFrame with `models` columns for point predictions and probabilistic predictions for all fitted `models`\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        For more information check the \n",
    "        [Fugue's transform](https://fugue-tutorials.readthedocs.io/tutorials/beginner/transform.html)\n",
    "        tutorial.\n",
    "        The [core.StatsForecast's forecast](https://nixtla.github.io/statsforecast/core.html#statsforecast.forecast)\n",
    "        method documentation.\n",
    "        Or the list of available [StatsForecast's models](https://nixtla.github.io/statsforecast/src/core/models.html).\n",
    "        \"\"\"\n",
    "        self._fcst_schema = self._get_output_schema(\n",
    "            df=df,\n",
    "            models=models,\n",
    "            level=level,\n",
    "            mode='forecast',\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        self._fitted_schema = self._fcst_schema + fa.get_schema(df).extract([target_col])\n",
    "        tfm_schema = 'a:binary, b:binary' if fitted else self._fcst_schema\n",
    "        params = dict(\n",
    "            models=models,\n",
    "            freq=freq,\n",
    "            fallback_model=fallback_model,\n",
    "            h=h,\n",
    "            level=level,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        tfm_kwargs = dict(\n",
    "            params=params,\n",
    "            schema=tfm_schema,\n",
    "            partition={\"by\": id_col},\n",
    "            engine=self._engine,\n",
    "            engine_conf=self._conf,            \n",
    "        )\n",
    "        if not fitted:\n",
    "            if X_df is None:\n",
    "                res = transform(df, self._forecast_noX, **tfm_kwargs)\n",
    "            else:\n",
    "                res = _cotransform(df, X_df, self._forecast_X, **tfm_kwargs)\n",
    "        else:\n",
    "            if X_df is None:\n",
    "                res_with_fitted = transform(df, self._forecast_noX_fitted, **tfm_kwargs)\n",
    "            else:\n",
    "                res_with_fitted = _cotransform(\n",
    "                    df, X_df, self._forecast_X_fitted, **tfm_kwargs\n",
    "                )\n",
    "            # the persist here avoids recomputing the whole thing\n",
    "            # when retrieving the fitted values\n",
    "            self._results = fa.persist(res_with_fitted)\n",
    "            res = transform(\n",
    "                self._results,\n",
    "                FugueBackend._retrieve_forecast_df,\n",
    "                schema=self._fcst_schema,\n",
    "                engine=self._engine,\n",
    "            )\n",
    "        return res\n",
    "\n",
    "    forecast.__doc__ = forecast.__doc__.format(**_param_descriptions)  # type: ignore[union-attr]\n",
    "\n",
    "    def forecast_fitted_values(self):\n",
    "        \"\"\"Retrieve in-sample predictions\"\"\"\n",
    "        if not hasattr(self, '_results'):\n",
    "            raise ValueError('You must first call forecast with `fitted=True`.')\n",
    "        return transform(\n",
    "            self._results,\n",
    "            FugueBackend._retrieve_fitted_df,\n",
    "            schema=self._fitted_schema,\n",
    "            engine=self._engine,\n",
    "        )\n",
    "\n",
    "    def _cv(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        *,\n",
    "        models,\n",
    "        freq,\n",
    "        fallback_model,\n",
    "        h,\n",
    "        n_windows,\n",
    "        step_size,\n",
    "        test_size,\n",
    "        input_size,\n",
    "        level,\n",
    "        refit,\n",
    "        fitted,\n",
    "        prediction_intervals,\n",
    "        id_col,\n",
    "        time_col,\n",
    "        target_col,\n",
    "    ) -> pd.DataFrame:\n",
    "        model = _StatsForecast(\n",
    "            models=models,\n",
    "            freq=freq, \n",
    "            fallback_model=fallback_model,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "        result = model.cross_validation(\n",
    "            df=df,\n",
    "            h=h,\n",
    "            n_windows=n_windows,\n",
    "            step_size=step_size,\n",
    "            test_size=test_size,\n",
    "            input_size=input_size,\n",
    "            level=level,\n",
    "            fitted=fitted,\n",
    "            refit=refit,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        return result    \n",
    "\n",
    "    def cross_validation(\n",
    "        self,\n",
    "        *,\n",
    "        df: AnyDataFrame,        \n",
    "        freq: Union[str, int],\n",
    "        models: List[Any],\n",
    "        fallback_model: Optional[Any],        \n",
    "        h: int,\n",
    "        n_windows: int,\n",
    "        step_size: int,\n",
    "        test_size: int,\n",
    "        input_size: int,\n",
    "        level: Optional[List[int]],\n",
    "        refit: bool,\n",
    "        fitted: bool,\n",
    "        prediction_intervals: Optional[ConformalIntervals],\n",
    "        id_col: str,\n",
    "        time_col: str,\n",
    "        target_col: str,\n",
    "    ) -> Any:\n",
    "        \"\"\"Temporal Cross-Validation with core.StatsForecast and FugueBackend.\n",
    "\n",
    "        This method uses Fugue's transform function, in combination with \n",
    "        `core.StatsForecast`'s cross-validation to efficiently fit a list of StatsForecast \n",
    "        models through multiple training windows, in either chained or rolled manner.\n",
    "\n",
    "        `StatsForecast.models`' speed along with Fugue's distributed computation allow to \n",
    "        overcome this evaluation technique high computational costs. Temporal cross-validation \n",
    "        provides better model's generalization measurements by increasing the test's length \n",
    "        and diversity.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        {df}\n",
    "        {freq}\n",
    "        {models}\n",
    "        {fallback_model}\n",
    "        {h}\n",
    "        {n_windows}\n",
    "        {step_size}\n",
    "        {test_size}\n",
    "        {input_size}\n",
    "        {level}\n",
    "        {refit}\n",
    "        {fitted}\n",
    "        {prediction_intervals}\n",
    "        {id_col}\n",
    "        {time_col}\n",
    "        {target_col}\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            DataFrame, with `models` columns for point predictions and probabilistic predictions for all fitted `models`.\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        The [core.StatsForecast's cross validation](https://nixtla.github.io/statsforecast/core.html#statsforecast.cross_validation)\n",
    "        method documentation.\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Temporal Cross-Validation\"](https://otexts.com/fpp3/tscv.html).\n",
    "        \"\"\"\n",
    "        schema = self._get_output_schema(\n",
    "            df=df,\n",
    "            models=models,\n",
    "            level=level,\n",
    "            mode='cv',\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        return transform(\n",
    "            df,\n",
    "            self._cv,\n",
    "            params=dict(\n",
    "                models=models,\n",
    "                freq=freq,\n",
    "                fallback_model=fallback_model,\n",
    "                h=h,\n",
    "                n_windows=n_windows,\n",
    "                step_size=step_size,\n",
    "                test_size=test_size,\n",
    "                input_size=input_size,\n",
    "                level=level,\n",
    "                refit=refit,\n",
    "                fitted=fitted,\n",
    "                prediction_intervals=prediction_intervals,\n",
    "                id_col=id_col,\n",
    "                time_col=time_col,\n",
    "                target_col=target_col,              \n",
    "            ),\n",
    "            schema=schema,\n",
    "            partition={\"by\": id_col},\n",
    "            engine=self._engine,\n",
    "            engine_conf=self._conf,\n",
    "            **self._transform_kwargs,\n",
    "        )\n",
    "\n",
    "    cross_validation.__doc__ = cross_validation.__doc__.format(**_param_descriptions)  # type: ignore[union-attr]\n",
    "\n",
    "\n",
    "@make_backend.candidate(lambda obj, *args, **kwargs: isinstance(obj, ExecutionEngine))\n",
    "def _make_fugue_backend(obj:ExecutionEngine, *args, **kwargs) -> ParallelBackend:\n",
    "    return FugueBackend(obj, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ba783-2d77-47de-aa85-fd41ec068889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import ( \n",
    "    AutoARIMA,\n",
    "    AutoETS,\n",
    ")\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5549b2-14d3-4bb6-9247-6e66acca8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_series = 4\n",
    "horizon = 7\n",
    "\n",
    "series = generate_series(n_series)\n",
    "\n",
    "sf = StatsForecast(\n",
    "    models=[AutoETS(season_length=7)],\n",
    "    freq='D',\n",
    ")\n",
    "\n",
    "sf.cross_validation(df=series, h=horizon, step_size = 24,\n",
    "    n_windows = 2, level=[90]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d3791-9d0a-4510-900e-51db0b5abe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb2a65-efbf-473e-b326-ad108428abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Make unique_id a column\n",
    "series['unique_id'] = series['unique_id'].astype(str)\n",
    "\n",
    "# Convert to Spark\n",
    "sdf = spark.createDataFrame(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298a105-126d-464f-a46f-49a9ce10955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a Spark DataFrame\n",
    "sf = StatsForecast(\n",
    "    models=[AutoETS(season_length=7)],\n",
    "    freq='D',\n",
    ")\n",
    "sf.cross_validation(df=sdf, h=horizon, step_size = 24,\n",
    "    n_windows = 2, level=[90]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53913de1-81b9-401c-93a2-83e42047e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FugueBackend, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97656b86-ae6d-4f5a-b9ff-32091a093942",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FugueBackend.forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65067ded-be81-4ce6-b459-702b76ddc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FugueBackend.cross_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037f72d-4ace-44e8-b4d5-b8399d5e294d",
   "metadata": {},
   "source": [
    "## Dask Distributed Predictions\n",
    "\n",
    "Here we provide an example for the distribution of the `StatsForecast` predictions using `Fugue` to execute the code in a Dask cluster.\n",
    "\n",
    "To do it we instantiate the `FugueBackend` class with a `DaskExecutionEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e38ec9-b093-40fe-9a31-85d84ccb1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from fugue_dask import DaskExecutionEngine\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0174b4d3-1262-48ca-9ca1-9f1ace044b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic Panel Data\n",
    "df = generate_series(10)\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = dd.from_pandas(df, npartitions=10)\n",
    "\n",
    "# Instantiate FugueBackend with DaskExecutionEngine\n",
    "dask_client = Client()\n",
    "engine = DaskExecutionEngine(dask_client=dask_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832937cc-2b7b-4ddc-84d0-e68a650bdc12",
   "metadata": {},
   "source": [
    "We have simply create the class to the usual `StatsForecast` instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08c1f2-3b0a-460f-a1a6-1d25d982104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "sf = StatsForecast(models=[Naive()], freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a44ec-787f-4ef7-8129-71409d2dd32a",
   "metadata": {},
   "source": [
    "### Distributed Forecast\n",
    "\n",
    "For extremely fast distributed predictions we use FugueBackend as backend that operates like the original [StatsForecast.forecast](https://nixtla.github.io/statsforecast/src/core/core.html#statsforecast.forecast) method.\n",
    "\n",
    "It receives as input a pandas.DataFrame with columns [`unique_id`,`ds`,`y`] and exogenous, where the `ds` (datestamp) column should be of a format expected by Pandas. The `y` column must be numeric, and represents the measurement we wish to forecast. And the `unique_id` uniquely identifies the series in the panel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2454a-7683-40d1-8828-877dba0345fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Distributed predictions with FugueBackend.\n",
    "sf.forecast(df=df, h=12).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e7b42-8129-472a-99fd-0725ae4cb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "sf = StatsForecast(models=[Naive()], freq='D', fallback_model=Naive())\n",
    "dask_fcst = sf.forecast(df=df, h=12).compute()\n",
    "fcst_stats = sf.forecast(df=df.compute(), h=12)\n",
    "pd.testing.assert_frame_equal(\n",
    "    (\n",
    "        dask_fcst\n",
    "        .sort_values(by=['unique_id', 'ds'])\n",
    "        .reset_index(drop=True)\n",
    "        .astype({'ds': 'datetime64[ns]', 'Naive': 'float32'})\n",
    "    ),\n",
    "    fcst_stats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9844a-df80-4894-a3a5-ffb8b117a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "xx = sf.forecast(df=df, h=12, fitted=True).compute()\n",
    "yy = sf.forecast_fitted_values().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "class ReturnX:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, y, X):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, h, X):\n",
    "        mean = X\n",
    "        return X\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'ReturnX'\n",
    "    \n",
    "    def forecast(self, y, h, X=None, X_future=None, fitted=False):\n",
    "        return {'mean': X_future.flatten()}\n",
    "    \n",
    "    def new(self):\n",
    "        b = type(self).__new__(type(self))\n",
    "        b.__dict__.update(self.__dict__)\n",
    "        return b\n",
    "    \n",
    "df_w_ex = pd.DataFrame(\n",
    "    {\n",
    "        'ds': np.hstack([np.arange(10), np.arange(10)]),\n",
    "        'y': np.random.rand(20),\n",
    "        'x': np.arange(20, dtype=np.float32),\n",
    "    },\n",
    "    index=pd.Index([0] * 10 + [1] * 10, name='unique_id'),\n",
    ").reset_index()\n",
    "train_mask = df_w_ex['ds'] < 6\n",
    "train_df = dd.from_pandas(df_w_ex[train_mask], npartitions=10)\n",
    "test_df = df_w_ex[~train_mask]\n",
    "xreg = dd.from_pandas(test_df.drop(columns='y').reset_index(drop=True), npartitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee084bc4-7303-4dd6-99df-5a23fa7cb419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "fcst_x = StatsForecast(models=[ReturnX()], freq=1)\n",
    "res = fcst_x.forecast(df=train_df, \n",
    "                      X_df=xreg, \n",
    "                      h=4).compute()\n",
    "expected_res = xreg.rename(columns={'x': 'ReturnX'}).compute()\n",
    "pd.testing.assert_frame_equal(\n",
    "    (\n",
    "        res\n",
    "        .sort_values('unique_id')\n",
    "        .reset_index(drop=True)\n",
    "        .astype(expected_res.dtypes)\n",
    "    ),\n",
    "    expected_res,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4f3de-910d-46eb-842b-579935cfbd10",
   "metadata": {},
   "source": [
    "### Distributed Cross-Validation\n",
    "\n",
    "For extremely fast distributed temporcal cross-validation we use `cross_validation` method that operates like the original [StatsForecast.cross_validation](https://nixtla.github.io/statsforecast/src/core/core.html#statsforecast.cross_validation) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d0a2f-8f3b-45cd-9f25-d8db281db3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Distributed cross-validation with FugueBackend.\n",
    "sf.cross_validation(df=df, h=12, n_windows=2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bc2f1-8ae4-46b3-a324-80a1d1e57dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea06c4d-9577-4c88-9808-8268c08c76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# Generate Synthetic Panel Data.\n",
    "df = generate_series(10).reset_index()\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = dd.from_pandas(df, npartitions=10)\n",
    "\n",
    "# Distribute predictions.\n",
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = sf.forecast(df=df, h=12).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "fcst_stats = sf.forecast(df=df.compute(), h=12).astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue.astype(fcst_stats.dtypes), fcst_stats)\n",
    "\n",
    "# Distribute cross-validation predictions.\n",
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = sf.cross_validation(df=df, h=12).compute().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = sf.cross_validation(df=df.compute(), h=12).astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue.astype(fcst_stats.dtypes), fcst_stats)\n",
    "\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "    \n",
    "#cross validation fallback model\n",
    "fcst = StatsForecast(models=[FailNaive()], freq='D', fallback_model=Naive())\n",
    "fcst_fugue = fcst.cross_validation(df=df, h=12).compute().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = sf.cross_validation(df=df.compute(), h=12).astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue.astype(fcst_stats.dtypes), fcst_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598617b9-2a8c-4fdc-b751-bc43702fa163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# test ray integration\n",
    "import ray\n",
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372bc61-4f39-4c04-8d39-d8270bc89b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# Generate Synthetic Panel Data.\n",
    "df = generate_series(10).reset_index()\n",
    "df['unique_id'] = df['unique_id'].astype(str)\n",
    "df = ray.data.from_pandas(df).repartition(2)\n",
    "\n",
    "# Distribute predictions.\n",
    "sf = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = sf.forecast(df=df, h=12).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "fcst_stats = sf.forecast(df=df.to_pandas(), h=12).astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue.astype(fcst_stats.dtypes), fcst_stats)\n",
    "\n",
    "# Distribute cross-validation predictions.\n",
    "fcst = StatsForecast(models=[Naive()], freq='D')\n",
    "fcst_fugue = fcst.cross_validation(df=df, h=12).to_pandas().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = sf.cross_validation(df=df.to_pandas(), h=12).astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue.astype(fcst_stats.dtypes), fcst_stats)\n",
    "\n",
    "# fallback model\n",
    "class FailNaive:\n",
    "    def forecast(self):\n",
    "        pass\n",
    "    def __repr__(self):\n",
    "        return 'Naive'\n",
    "    \n",
    "#cross validation fallback model\n",
    "sf = StatsForecast(models=[FailNaive()], freq='D', fallback_model=Naive())\n",
    "fcst_fugue = sf.cross_validation(df=df, h=12).to_pandas().sort_values(['unique_id', 'ds', 'cutoff']).reset_index(drop=True)\n",
    "fcst_stats = sf.cross_validation(df=df.to_pandas(), h=12).astype({\"unique_id\": str})\n",
    "test_eq(fcst_fugue.astype(fcst_stats.dtypes), fcst_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628146a-57b0-4b4b-8377-045b08dd2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "\n",
    "# Distributed exogenous regressors\n",
    "sf = StatsForecast(models=[ReturnX()], freq=1)\n",
    "res = sf.forecast(df=train_df, \n",
    "                  X_df=xreg, \n",
    "                  h=4).compute()\n",
    "expected_res = xreg.compute().rename(columns={'x': 'ReturnX'})\n",
    "# we expect strings for unique_id, and ds using exogenous\n",
    "pd.testing.assert_frame_equal(\n",
    "    res.sort_values('unique_id').reset_index(drop=True).astype(expected_res.dtypes), \n",
    "    expected_res\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
