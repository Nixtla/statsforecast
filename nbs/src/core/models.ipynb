{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "> Models currently supported by StatsForecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StatsForecast offers a wide variety of models grouped in the following categories:\n",
    "\n",
    "*  **Auto Forecast:** Automatic forecasting tools search for the best parameters and select the best possible model for a series of time series. These tools are useful for large collections of univariate time series. Includes automatic versions of: Arima, ETS, Theta, CES.\n",
    "\n",
    "* **Exponential Smoothing:**  Uses a weighted average of all past observations where the weights decrease exponentially into the past. Suitable for data with clear trend and/or seasonality. Use the `SimpleExponential` family  for data with no clear trend or seasonality. Examples: SES, Holt's Winters, SSO.\n",
    "\n",
    "* **Benchmark models:** classical models for establishing baselines. Examples: Mean, Naive, Random Walk\n",
    "\n",
    "* **Intermittent or Sparse models:** suited for series with very few non-zero observations. Examples: CROSTON, ADIDA, IMAPA\n",
    "\n",
    "* **Multiple Seasonalities:** suited for signals with more than one clear seasonality. Useful for low-frequency data like electricity and logs. Examples: MSTL and TBATS. \n",
    "\n",
    "* **Theta Models:**  fit two theta lines to a deseasonalized time series, using different techniques to obtain and combine the two theta lines to produce the final forecasts. Examples: Theta, DynamicTheta\n",
    "\n",
    "* **GARCH Model:** suited for modeling time series that exhibit non-constant volatility over time. Commonly used in finance to model stock prices, exchange rates, interest rates, and other financial instruments. The ARCH model is a particular case of GARCH. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import warnings\n",
    "from math import trunc\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "from statsforecast.arima import (\n",
    "    Arima,\n",
    "    auto_arima_f,\n",
    "    fitted_arima,\n",
    "    forecast_arima, \n",
    "    forward_arima,\n",
    "    is_constant,\n",
    ")\n",
    "from statsforecast.ces import (\n",
    "    auto_ces, forecast_ces,\n",
    "    forward_ces\n",
    ")\n",
    "from statsforecast.ets import (\n",
    "    _PHI_LOWER,\n",
    "    _PHI_UPPER,\n",
    "    ets_f, forecast_ets, \n",
    "    forward_ets,\n",
    ")\n",
    "from statsforecast.mfles import MFLES as _MFLES\n",
    "from statsforecast.mstl import mstl\n",
    "from statsforecast.theta import (\n",
    "    auto_theta, forecast_theta, \n",
    "    forward_theta\n",
    ")\n",
    "from statsforecast.garch import (\n",
    "    garch_model, garch_forecast\n",
    ")\n",
    "from statsforecast.tbats import tbats_selection, tbats_forecast, _compute_sigmah\n",
    "from statsforecast.utils import (\n",
    "    _calculate_sigma,\n",
    "    _calculate_intervals,\n",
    "    _ensure_float,\n",
    "    _naive,\n",
    "    _old_kw_to_pos,\n",
    "    _quantiles,\n",
    "    _repeat_val,\n",
    "    _repeat_val_seas,\n",
    "    _seasonal_naive,\n",
    "    CACHE,\n",
    "    ConformalIntervals,\n",
    "    NOGIL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from fastcore.test import test_eq, test_close, test_fail\n",
    "from nbdev.showdoc import add_docs, show_doc\n",
    "\n",
    "from statsforecast.garch import generate_garch_data\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "def _plot_insample_pi(fcst):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (20,7))\n",
    "\n",
    "    sdate = date(1949,1,1) # start date \n",
    "    edate = date(1961,1,1) # end date\n",
    "    dates = pd.date_range(sdate,edate-timedelta(days=1),freq='m')\n",
    "\n",
    "    df = pd.DataFrame({'dates': dates,\n",
    "                       'actual': ap,\n",
    "                       'fitted': fcst['fitted'],\n",
    "                       'fitted_lo_80': fcst['fitted-lo-80'], \n",
    "                       'fitted_lo_95': fcst['fitted-lo-95'], \n",
    "                       'fitted_hi_80': fcst['fitted-hi-80'],\n",
    "                       'fitted_hi_95': fcst['fitted-hi-95']})\n",
    "    plt.plot(df.dates, df.actual, color='firebrick', label='Actual value', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted, color='navy', label='Fitted values', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted_lo_80, color='darkorange', label='fitted-lo-80', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted_lo_95, color='deepskyblue', label='fitted-lo-95', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted_hi_80, color='darkorange', label='fitted-hi-80', linewidth=3)\n",
    "    plt.plot(df.dates, df.fitted_hi_95, color='deepskyblue', label='fitted-hi-95', linewidth=3)\n",
    "    plt.fill_between(df.dates, df.fitted_lo_95, df.fitted_hi_95, color = 'deepskyblue', alpha = 0.2)\n",
    "    plt.fill_between(df.dates, df.fitted_lo_80, df.fitted_hi_80, color = 'darkorange', alpha = 0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "def _plot_fcst(fcst): \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (20,7))\n",
    "    plt.plot(np.arange(0, len(ap)), ap)\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['mean'], label='mean')\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['lo-95'], color = 'r', label='lo-95')\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['hi-95'], color = 'r', label='hi-95')\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['lo-80'], color = 'g', label='lo-80')\n",
    "    plt.plot(np.arange(len(ap), len(ap) + 13), fcst['hi-80'], color = 'g', label='hi-80')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _add_fitted_pi(res, se, level):\n",
    "    level = sorted(level)\n",
    "    level = np.asarray(level)\n",
    "    quantiles = _quantiles(level=level)\n",
    "    lo = res['fitted'].reshape(-1, 1) - quantiles * se.reshape(-1, 1)\n",
    "    hi = res['fitted'].reshape(-1, 1) + quantiles * se.reshape(-1, 1)\n",
    "    lo = lo[:, ::-1]\n",
    "    lo = {f'fitted-lo-{l}': lo[:, i] for i, l in enumerate(reversed(level))}\n",
    "    hi = {f'fitted-hi-{l}': hi[:, i] for i, l in enumerate(level)}\n",
    "    res = {**res, **lo, **hi}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _add_conformal_distribution_intervals(\n",
    "    fcst: Dict,\n",
    "    cs: np.ndarray,\n",
    "    level: List[Union[int, float]],\n",
    ") -> Dict:\n",
    "    r\"\"\"\n",
    "    Adds conformal intervals to the `fcst` dict based on conformal scores `cs`.\n",
    "    `level` should be already sorted. This strategy creates forecasts paths\n",
    "    based on errors and calculate quantiles using those paths.\n",
    "    \"\"\"\n",
    "    alphas = [100 - lv for lv in level]\n",
    "    cuts = [alpha / 200 for alpha in reversed(alphas)]\n",
    "    cuts.extend(1 - alpha / 200 for alpha in alphas)\n",
    "    mean = fcst['mean'].reshape(1, -1)\n",
    "    scores = np.vstack([mean - cs, mean + cs])\n",
    "    quantiles = np.quantile(\n",
    "        scores,\n",
    "        cuts,\n",
    "        axis=0,\n",
    "    )\n",
    "    quantiles = quantiles.reshape(len(cuts), -1)\n",
    "    lo_cols = [f\"lo-{lv}\" for lv in reversed(level)]\n",
    "    hi_cols = [f\"hi-{lv}\" for lv in level]\n",
    "    out_cols = lo_cols + hi_cols\n",
    "    for i, col in enumerate(out_cols):\n",
    "        fcst[col] = quantiles[i]\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _get_conformal_method(method: str):\n",
    "    available_methods = {\n",
    "        \"conformal_distribution\": _add_conformal_distribution_intervals,\n",
    "        #\"conformal_error\": _add_conformal_error_intervals,\n",
    "    }\n",
    "    if method not in available_methods.keys():\n",
    "        raise ValueError(\n",
    "            f\"prediction intervals method {method} not supported \"\n",
    "            f'please choose one of {\", \".join(available_methods.keys())}'\n",
    "        )\n",
    "    return available_methods[method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class _TS:\n",
    "    uses_exog = False\n",
    "    \n",
    "    def new(self):\n",
    "        b = type(self).__new__(type(self))\n",
    "        b.__dict__.update(self.__dict__)\n",
    "        return b\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.alias\n",
    "    \n",
    "    def _conformity_scores(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ) -> np.ndarray:\n",
    "        y = _ensure_float(y)\n",
    "        n_windows = self.prediction_intervals.n_windows # type: ignore[attr-defined]\n",
    "        h = self.prediction_intervals.h # type: ignore[attr-defined]\n",
    "        n_samples = y.size\n",
    "        # use as many windows as possible for short series\n",
    "        # subtract 1 for the training set\n",
    "        n_windows = min(n_windows, (n_samples - 1) // h)\n",
    "        if n_windows < 2:\n",
    "            raise ValueError(\n",
    "                f\"Prediction intervals settings require at least {2 * h + 1:,} samples, serie has {n_samples:,}.\"\n",
    "            )\n",
    "        test_size = n_windows * h\n",
    "        cs = np.empty((n_windows, h), dtype=y.dtype)\n",
    "        for i_window in range(n_windows):\n",
    "            train_end = n_samples - test_size + i_window * h\n",
    "            y_train = y[:train_end]\n",
    "            y_test = y[train_end : train_end + h]\n",
    "            if X is not None:\n",
    "                X_train = X[:train_end]\n",
    "                X_test = X[train_end : train_end + h]\n",
    "            else:\n",
    "                X_train = None\n",
    "                X_test = None\n",
    "            fcst_window = self.forecast(h=h, y=y_train, X=X_train, X_future=X_test)  # type: ignore[attr-defined]\n",
    "            cs[i_window] = np.abs(fcst_window[\"mean\"] - y_test)\n",
    "        return cs\n",
    "    \n",
    "    @property\n",
    "    def _conformal_method(self):\n",
    "        return _get_conformal_method(self.prediction_intervals.method)\n",
    "\n",
    "    def _store_cs(self, y, X):\n",
    "        if self.prediction_intervals is not None:\n",
    "            self._cs = self._conformity_scores(y, X)\n",
    "\n",
    "    def _add_conformal_intervals(self, fcst, y, X, level):\n",
    "        if self.prediction_intervals is not None and level is not None:\n",
    "            cs = self._conformity_scores(y, X) if y is not None else self._cs\n",
    "            res = self._conformal_method(fcst=fcst, cs=cs, level=level)\n",
    "            return res\n",
    "        return fcst\n",
    "\n",
    "    def _add_predict_conformal_intervals(self, fcst, level):\n",
    "        return self._add_conformal_intervals(fcst=fcst, y=None, X=None, level=level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformity scores\n",
    "class ZeroModel(_TS):\n",
    "    \n",
    "    def __init__(self, prediction_intervals: ConformalIntervals = None):\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.alias = 'SumAhead'\n",
    "    \n",
    "    def forecast(self, y, h, X=None, X_future=None, fitted=False, level=None):\n",
    "        res = {'mean': np.zeros(h)}\n",
    "        if self.prediction_intervals is not None and level is not None:\n",
    "            cs = self._conformity_scores(y, X)\n",
    "            res = self._conformal_method(fcst=res, cs=cs, level=level)\n",
    "        return res\n",
    "    \n",
    "    def fit(self, y, X):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, h, X=None, level=None):\n",
    "        res = {'mean': np.zeros(h)}\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "conf_intervals = ConformalIntervals(h=12, n_windows=10)\n",
    "expected_cs = np.full((conf_intervals.n_windows, conf_intervals.h), np.nan)\n",
    "cs_info = ap[-conf_intervals.h*conf_intervals.n_windows:]\n",
    "for i in range(conf_intervals.n_windows):\n",
    "    expected_cs[i] = cs_info[i * conf_intervals.h:(i+1) * conf_intervals.h]\n",
    "current_cs = ZeroModel(conf_intervals)._conformity_scores(ap)\n",
    "test_eq(expected_cs, current_cs)\n",
    "zero_model = ZeroModel(conf_intervals)\n",
    "fcst_conformal = zero_model.forecast(ap, h=12, level=[80, 90])\n",
    "test_eq(list(fcst_conformal.keys()), ['mean', 'lo-90', 'lo-80', 'hi-80', 'hi-90'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoARIMA(_TS):\n",
    "    r\"\"\"AutoARIMA model.\n",
    "\n",
    "    Automatically selects the best ARIMA (AutoRegressive Integrated Moving Average) \n",
    "    model using an information criterion. Default is Akaike Information Criterion (AICc). \n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This implementation is a mirror of Hyndman's [forecast::auto.arima](https://github.com/robjhyndman/forecast).\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Rob J. Hyndman, Yeasmin Khandakar (2008). \"Automatic Time Series Forecasting: The forecast package for R\"](https://www.jstatsoft.org/article/view/v027i03).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d : Optional[int] \n",
    "        Order of first-differencing.\n",
    "    D : Optional[int] \n",
    "        Order of seasonal-differencing.\n",
    "    max_p : int\n",
    "        Max autorregresives p.\n",
    "    max_q : int \n",
    "        Max moving averages q.\n",
    "    max_P : int \n",
    "        Max seasonal autorregresives P.\n",
    "    max_Q : int \n",
    "        Max seasonal moving averages Q.\n",
    "    max_order : int \n",
    "        Max p+q+P+Q value if not stepwise selection.\n",
    "    max_d : int \n",
    "        Max non-seasonal differences.\n",
    "    max_D : int \n",
    "        Max seasonal differences.\n",
    "    start_p : int \n",
    "        Starting value of p in stepwise procedure.\n",
    "    start_q : int \n",
    "        Starting value of q in stepwise procedure.\n",
    "    start_P : int \n",
    "        Starting value of P in stepwise procedure.\n",
    "    start_Q : int \n",
    "        Starting value of Q in stepwise procedure.\n",
    "    stationary : bool \n",
    "        If True, restricts search to stationary models.\n",
    "    seasonal : bool \n",
    "        If False, restricts search to non-seasonal models.\n",
    "    ic : str \n",
    "        Information criterion to be used in model selection.\n",
    "    stepwise : bool\n",
    "        If True, will do stepwise selection (faster).\n",
    "    nmodels : int \n",
    "        Number of models considered in stepwise search.\n",
    "    trace : bool \n",
    "        If True, the searched ARIMA models is reported.\n",
    "    approximation : Optional[bool] \n",
    "        If True, conditional sums-of-squares estimation, final MLE.\n",
    "    method : Optional[str] \n",
    "        Fitting method between maximum likelihood or sums-of-squares.\n",
    "    truncate : Optional[int] \n",
    "        Observations truncated series used in model selection.\n",
    "    test : str \n",
    "        Unit root test to use. See `ndiffs` for details.\n",
    "    test_kwargs : Optional[str] \n",
    "        Unit root test additional arguments.\n",
    "    seasonal_test : str \n",
    "        Selection method for seasonal differences.\n",
    "    seasonal_test_kwargs : Optional[dict] \n",
    "        Seasonal unit root test arguments.\n",
    "    allowdrift : bool (default True)\n",
    "        If True, drift models terms considered.\n",
    "    allowmean : bool (default True)\n",
    "        If True, non-zero mean models considered.\n",
    "    blambda : Optional[float] \n",
    "        Box-Cox transformation parameter.\n",
    "    biasadj : bool \n",
    "        Use adjusted back-transformed mean Box-Cox.\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    alias : str \n",
    "        Custom name of the model.  \n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    uses_exog = True\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        d: Optional[int] = None,\n",
    "        D: Optional[int] = None,\n",
    "        max_p: int = 5,\n",
    "        max_q: int = 5,\n",
    "        max_P: int = 2,\n",
    "        max_Q: int = 2,\n",
    "        max_order: int = 5,\n",
    "        max_d: int = 2,\n",
    "        max_D: int = 1,\n",
    "        start_p: int = 2,\n",
    "        start_q: int = 2,\n",
    "        start_P: int = 1,\n",
    "        start_Q: int = 1,\n",
    "        stationary: bool = False,\n",
    "        seasonal: bool = True,\n",
    "        ic: str = 'aicc',\n",
    "        stepwise: bool = True,\n",
    "        nmodels: int = 94,\n",
    "        trace: bool = False,\n",
    "        approximation: Optional[bool] = False,\n",
    "        method: Optional[str] = None,\n",
    "        truncate: Optional[bool] = None,\n",
    "        test: str = 'kpss',\n",
    "        test_kwargs: Optional[str] = None,\n",
    "        seasonal_test: str = 'seas',\n",
    "        seasonal_test_kwargs: Optional[Dict] = None,\n",
    "        allowdrift: bool = False,\n",
    "        allowmean: bool = False,\n",
    "        blambda: Optional[float] = None,\n",
    "        biasadj: bool = False,\n",
    "        season_length: int = 1,\n",
    "        alias: str = 'AutoARIMA',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        self.d=d\n",
    "        self.D=D\n",
    "        self.max_p=max_p\n",
    "        self.max_q=max_q\n",
    "        self.max_P=max_P\n",
    "        self.max_Q=max_Q\n",
    "        self.max_order=max_order\n",
    "        self.max_d=max_d\n",
    "        self.max_D=max_D\n",
    "        self.start_p=start_p\n",
    "        self.start_q=start_q\n",
    "        self.start_P=start_P\n",
    "        self.start_Q=start_Q\n",
    "        self.stationary=stationary\n",
    "        self.seasonal=seasonal\n",
    "        self.ic=ic\n",
    "        self.stepwise=stepwise\n",
    "        self.nmodels=nmodels\n",
    "        self.trace=trace\n",
    "        self.approximation=approximation\n",
    "        self.method=method\n",
    "        self.truncate=truncate\n",
    "        self.test=test\n",
    "        self.test_kwargs=test_kwargs\n",
    "        self.seasonal_test=seasonal_test\n",
    "        self.seasonal_test_kwargs=seasonal_test_kwargs\n",
    "        self.allowdrift=allowdrift\n",
    "        self.allowmean=allowmean\n",
    "        self.blambda=blambda\n",
    "        self.biasadj=biasadj\n",
    "        self.season_length=season_length\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        \n",
    "    def fit(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the AutoARIMA model.\n",
    "\n",
    "        Fit an AutoARIMA to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            AutoARIMA fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            self.model_ = auto_arima_f(\n",
    "                x=y,\n",
    "                d=self.d,\n",
    "                D=self.D,\n",
    "                max_p=self.max_p,\n",
    "                max_q=self.max_q,\n",
    "                max_P=self.max_P,\n",
    "                max_Q=self.max_Q,\n",
    "                max_order=self.max_order,\n",
    "                max_d=self.max_d,\n",
    "                max_D=self.max_D,\n",
    "                start_p=self.start_p,\n",
    "                start_q=self.start_q,\n",
    "                start_P=self.start_P,\n",
    "                start_Q=self.start_Q,\n",
    "                stationary=self.stationary,\n",
    "                seasonal=self.seasonal,\n",
    "                ic=self.ic,\n",
    "                stepwise=self.stepwise,\n",
    "                nmodels=self.nmodels,\n",
    "                trace=self.trace,\n",
    "                approximation=self.approximation,\n",
    "                method=self.method,\n",
    "                truncate=self.truncate,\n",
    "                xreg=X,\n",
    "                test=self.test,\n",
    "                test_kwargs=self.test_kwargs,\n",
    "                seasonal_test=self.seasonal_test,\n",
    "                seasonal_test_kwargs=self.seasonal_test_kwargs,\n",
    "                allowdrift=self.allowdrift,\n",
    "                allowmean=self.allowmean,\n",
    "                blambda=self.blambda,\n",
    "                biasadj=self.biasadj,\n",
    "                period=self.season_length\n",
    "            )\n",
    "\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self, \n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted AutoArima.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fcst = forecast_arima(self.model_, h=h, xreg=X, level=level)\n",
    "        mean = fcst['mean']\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            res = {\n",
    "                'mean': mean,\n",
    "                **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "                **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "            }\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted AutoArima insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = fitted_arima(self.model_)\n",
    "        res = {'fitted': mean}\n",
    "        if level is not None:\n",
    "            se = np.sqrt(self.model_['sigma2'])\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient AutoARIMA predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenpus of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x) optional exogenous. \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            mod = auto_arima_f(\n",
    "                x=y,\n",
    "                d=self.d,\n",
    "                D=self.D,\n",
    "                max_p=self.max_p,\n",
    "                max_q=self.max_q,\n",
    "                max_P=self.max_P,\n",
    "                max_Q=self.max_Q,\n",
    "                max_order=self.max_order,\n",
    "                max_d=self.max_d,\n",
    "                max_D=self.max_D,\n",
    "                start_p=self.start_p,\n",
    "                start_q=self.start_q,\n",
    "                start_P=self.start_P,\n",
    "                start_Q=self.start_Q,\n",
    "                stationary=self.stationary,\n",
    "                seasonal=self.seasonal,\n",
    "                ic=self.ic,\n",
    "                stepwise=self.stepwise,\n",
    "                nmodels=self.nmodels,\n",
    "                trace=self.trace,\n",
    "                approximation=self.approximation,\n",
    "                method=self.method,\n",
    "                truncate=self.truncate,\n",
    "                xreg=X,\n",
    "                test=self.test,\n",
    "                test_kwargs=self.test_kwargs,\n",
    "                seasonal_test=self.seasonal_test,\n",
    "                seasonal_test_kwargs=self.seasonal_test_kwargs,\n",
    "                allowdrift=self.allowdrift,\n",
    "                allowmean=self.allowmean,\n",
    "                blambda=self.blambda,\n",
    "                biasadj=self.biasadj,\n",
    "                period=self.season_length\n",
    "            )\n",
    "        fcst = forecast_arima(mod, h, xreg=X_future, level=level)\n",
    "        res = {'mean': fcst['mean']}\n",
    "        if fitted:\n",
    "            res['fitted'] = fitted_arima(mod)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                res = {\n",
    "                    **res,\n",
    "                    **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "                    **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "                }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = np.sqrt(mod['sigma2'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Apply fitted ARIMA model to a new time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'model_'):\n",
    "            raise Exception('You have to use the `fit` method first')\n",
    "        y = _ensure_float(y)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            mod = forward_arima(self.model_, y=y, xreg=X, method=self.method)\n",
    "        fcst = forecast_arima(mod, h, xreg=X_future, level=level)\n",
    "        res = {'mean': fcst['mean']}\n",
    "        if fitted:\n",
    "            res['fitted'] = fitted_arima(mod)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                res = {\n",
    "                    **res,\n",
    "                    **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "                    **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "                }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = np.sqrt(mod['sigma2'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_class(\n",
    "    cls_, x, h, skip_insample=False, level=None, test_forward=False, X=None, X_future=None\n",
    "):\n",
    "    cls_ = cls_.fit(x, X=X)\n",
    "    fcst_cls = cls_.predict(h=h, X=X_future)\n",
    "    test_eq(len(fcst_cls['mean']), h)\n",
    "    # test fit + predict equals forecast\n",
    "    test_eq(\n",
    "        cls_.forecast(y=x, h=h, X=X, X_future=X_future)['mean'],\n",
    "        fcst_cls['mean']\n",
    "    )\n",
    "    if not skip_insample:\n",
    "        test_eq(len(cls_.predict_in_sample()['fitted']), len(x))\n",
    "        assert isinstance(cls_.predict_in_sample()['fitted'], np.ndarray)\n",
    "        np.testing.assert_array_equal(\n",
    "            cls_.forecast(y=x, h=h, X=X, X_future=X_future, fitted=True)['fitted'],\n",
    "            cls_.predict_in_sample()['fitted'], \n",
    "        )\n",
    "        if test_forward:\n",
    "            np.testing.assert_array_equal(\n",
    "                cls_.forward(y=x, h=h, X=X, X_future=X_future, fitted=True)['fitted'],\n",
    "                cls_.predict_in_sample()['fitted'], \n",
    "            )\n",
    "\n",
    "    if test_forward:\n",
    "        try:\n",
    "            pd.testing.assert_frame_equal(\n",
    "                pd.DataFrame(cls_.predict(h=h, X=X_future)),\n",
    "                pd.DataFrame(cls_.forward(y=x, X=X, X_future=X_future, h=h)),\n",
    "            )\n",
    "        except AssertionError:\n",
    "            raise Exception('predict and forward methods are not equal')\n",
    "    \n",
    "    if level is not None:\n",
    "        fcst_cls = pd.DataFrame(cls_.predict(h=h, X=X_future, level=level))\n",
    "        fcst_forecast = pd.DataFrame(cls_.forecast(y=x, h=h, X=X, X_future=X_future, level=level))\n",
    "        try:\n",
    "            pd.testing.assert_frame_equal(fcst_cls, fcst_forecast)\n",
    "        except AssertionError:\n",
    "            raise Exception('predict and forecast methods are not equal with levels')\n",
    "            \n",
    "        if test_forward:\n",
    "            try:\n",
    "                pd.testing.assert_frame_equal(\n",
    "                    pd.DataFrame(cls_.predict(h=h, X=X_future, level=level)),\n",
    "                    pd.DataFrame(cls_.forward(y=x, h=h, X=X, X_future=X_future, level=level))\n",
    "                )\n",
    "            except AssertionError:\n",
    "                raise Exception('predict and forward methods are not equal with levels')\n",
    "        \n",
    "        if not skip_insample:\n",
    "            fcst_cls = pd.DataFrame(cls_.predict_in_sample(level=level))\n",
    "            fcst_forecast = cls_.forecast(y=x, h=h, X=X, X_future=X_future, level=level, fitted=True)\n",
    "            fcst_forecast = pd.DataFrame({key: val for key, val in fcst_forecast.items() if 'fitted' in key})\n",
    "            try:\n",
    "                pd.testing.assert_frame_equal(fcst_cls, fcst_forecast)\n",
    "            except AssertionError:\n",
    "                raise Exception(\n",
    "                    'predict and forecast methods are not equal with ' \n",
    "                    'levels for fitted values '\n",
    "                )\n",
    "            if test_forward:\n",
    "                fcst_forward = cls_.forecast(y=x, h=h, X=X, X_future=X_future, level=level, fitted=True)\n",
    "                fcst_forward = pd.DataFrame({key: val for key, val in fcst_forward.items() if 'fitted' in key})\n",
    "                try:\n",
    "                    pd.testing.assert_frame_equal(fcst_cls, fcst_forward)\n",
    "                except AssertionError:\n",
    "                    raise Exception(\n",
    "                        'predict and forward methods are not equal with ' \n",
    "                        'levels for fitted values '\n",
    "                    )\n",
    "\n",
    "def _test_fitted_sparse(model_factory):\n",
    "    y1 = np.array([2, 5, 0, 1, 3, 0, 1, 1, 0], dtype=np.float64)\n",
    "    y2 = np.array([0, 0, 1, 0, 0, 7, 1, 0, 1], dtype=np.float64)\n",
    "    y3 = np.array([0, 0, 1, 0, 0, 7, 1, 0, 0], dtype=np.float64)\n",
    "    y4 = np.zeros(9, dtype=np.float64)\n",
    "    for y in [y1, y2, y3, y4]:\n",
    "        expected_fitted = np.hstack(\n",
    "            [\n",
    "                model_factory().forecast(y=y[:i + 1], h=1)['mean']\n",
    "                for i in range(y.size - 1)]\n",
    "        )\n",
    "        np.testing.assert_allclose(\n",
    "            model_factory().forecast(y=y, h=1, fitted=True)['fitted'],\n",
    "            np.append(np.nan, expected_fitted),\n",
    "            atol=1e-6,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "arima = AutoARIMA(season_length=12) \n",
    "test_class(arima, x=ap, h=12, level=[90, 80], test_forward=True)\n",
    "fcst_arima = arima.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "arima_c = AutoARIMA(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(arima_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_arima_c = arima_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_arima_c[\"mean\"],\n",
    "    fcst_arima[\"mean\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_arima_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoARIMA()),\n",
    "    'AutoARIMA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoARIMA(alias='AutoARIMA_seasonality')),\n",
    "    'AutoARIMA_seasonality'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoARIMA.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import AutoARIMA\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoARIMA's usage example\n",
    "arima = AutoARIMA(season_length=4)\n",
    "arima = arima.fit(y=ap)\n",
    "y_hat_dict = arima.predict(h=4, level=[80])\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoETS(_TS):\n",
    "    r\"\"\"Automatic Exponential Smoothing model.\n",
    "\n",
    "    Automatically selects the best ETS (Error, Trend, Seasonality) \n",
    "    model using an information criterion. Default is Akaike Information Criterion (AICc), while particular models are estimated using maximum likelihood.\n",
    "    The state-space equations can be determined based on their $M$ multiplicative, $A$ additive, \n",
    "    $Z$ optimized or $N$ ommited components. The `model` string parameter defines the ETS equations: \n",
    "    E in [$M, A, Z$], T in [$N, A, M, Z$], and S in [$N, A, M, Z$].\n",
    "    \n",
    "    For example when model='ANN' (additive error, no trend, and no seasonality), ETS will \n",
    "    explore only a simple exponential smoothing.\n",
    "    \n",
    "    If the component is selected as 'Z', it operates as a placeholder to ask the AutoETS model\n",
    "    to figure out the best parameter.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This implementation is a mirror of Hyndman's [forecast::ets](https://github.com/robjhyndman/forecast).\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Rob J. Hyndman, Yeasmin Khandakar (2008). \"Automatic Time Series Forecasting: The forecast package for R\"](https://www.jstatsoft.org/article/view/v027i03).\n",
    "    \n",
    "    [Hyndman, Rob, et al (2008). \"Forecasting with exponential smoothing: the state space approach\"](https://robjhyndman.com/expsmooth/).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str\n",
    "        Controlling state-space-equations.\n",
    "    season_length : int\n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    damped : bool\n",
    "        A parameter that 'dampens' the trend.\n",
    "    phi : float, optional (default=None)\n",
    "        Smoothing parameter for trend damping. Only used when `damped=True`.\n",
    "    alias : str\n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals],\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int = 1,\n",
    "        model: str = 'ZZZ',\n",
    "        damped: Optional[bool] = None,\n",
    "        phi: Optional[float] = None,\n",
    "        alias: str = 'AutoETS',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        self.season_length = season_length\n",
    "        self.model = model\n",
    "        self.damped = damped\n",
    "        if phi is not None:\n",
    "            if not isinstance(phi, float):\n",
    "                raise ValueError('phi must be `None` or float.')\n",
    "            if not _PHI_LOWER <= phi <= _PHI_UPPER:\n",
    "                raise ValueError(f'Valid range for phi is [{_PHI_LOWER}, {_PHI_UPPER}]')\n",
    "        self.phi = phi\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the Exponential Smoothing model.\n",
    "\n",
    "        Fit an Exponential Smoothing model to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            Exponential Smoothing fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = ets_f(y, m=self.season_length, model=self.model, damped=self.damped, phi=self.phi)\n",
    "        self.model_['actual_residuals'] = y - self.model_['fitted']\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None \n",
    "    ):\n",
    "        r\"\"\"Predict with fitted Exponential Smoothing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional exogenpus of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fcst = forecast_ets(self.model_, h=h, level=level)\n",
    "        res = {'mean': fcst['mean']}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            res = {\n",
    "                **res,\n",
    "                **{f\"lo-{l}\": fcst[f\"lo-{l}\"] for l in reversed(level)},\n",
    "                **{f\"hi-{l}\": fcst[f\"hi-{l}\"] for l in level},\n",
    "            }\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted Exponential Smoothing insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            residuals = self.model_['actual_residuals']\n",
    "            se = _calculate_sigma(residuals, len(residuals) - self.model_['n_params'])\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient Exponential Smoothing predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenpus of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = ets_f(y, m=self.season_length, model=self.model, damped=self.damped, phi=self.phi)\n",
    "        fcst = forecast_ets(mod, h=h, level=level)\n",
    "        keys = ['mean']\n",
    "        if fitted:\n",
    "            keys.append('fitted')\n",
    "        res = {key: fcst[key] for key in keys}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                res = {\n",
    "                    **res,\n",
    "                    **{f\"lo-{l}\": fcst[f\"lo-{l}\"] for l in reversed(level)},\n",
    "                    **{f\"hi-{l}\": fcst[f\"hi-{l}\"] for l in level},\n",
    "                }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = _calculate_sigma(y - mod['fitted'], len(y) - mod['n_params'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Apply fitted Exponential Smoothing model to a new time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenpus of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'model_'):\n",
    "            raise Exception('You have to use the `fit` method first')\n",
    "        y = _ensure_float(y)\n",
    "        mod = forward_ets(self.model_, y=y)\n",
    "        fcst = forecast_ets(mod, h=h, level=level)\n",
    "        keys = ['mean']\n",
    "        if fitted:\n",
    "            keys.append('fitted')\n",
    "        res = {key: fcst[key] for key in keys}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                res = {\n",
    "                    **res,\n",
    "                    **{f\"lo-{l}\": fcst[f\"lo-{l}\"] for l in reversed(level)},\n",
    "                    **{f\"hi-{l}\": fcst[f\"hi-{l}\"] for l in level},\n",
    "                }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = _calculate_sigma(y - mod['fitted'], len(y) - mod['n_params'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "autoets = AutoETS(season_length=12)\n",
    "test_class(autoets, x=ap, h=12, level=[90, 80], test_forward=True)\n",
    "fcst_ets = autoets.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoETS()),\n",
    "    'AutoETS'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoETS(alias='AutoETS_custom')),\n",
    "    'AutoETS_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "autoets = AutoETS(season_length=12, model='AAA')\n",
    "test_class(autoets, x=ap, h=12, level=[90, 80])\n",
    "fcst_ets = autoets.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "autoets_c = AutoETS(season_length=12, model='AAA', prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(autoets_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_ets_c = autoets_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(fcst_ets_c['mean'],\n",
    "    fcst_ets['mean'])\n",
    "_plot_fcst(fcst_ets_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| hide \n",
    "# Test whether forecast and fit-predict generate the same result \n",
    "models = ['ANNN', 'AANN', 'ANAN', 'AAAN', 'AAND', 'AAAD', # class 1 \n",
    "          'MNNN', 'MANN', 'MAND', 'MNAN', 'MAAN', 'MAAD', # class 2 \n",
    "          'MNMN', 'MAMN', 'MAMD'] # class 3 \n",
    "\n",
    "for k in range(0,len(models)): \n",
    "    mod = models[k][0:3]\n",
    "    damped_val = models[k][-1]\n",
    "    if damped_val == 'N': \n",
    "        damped = False\n",
    "    else: \n",
    "        damped = True\n",
    "        \n",
    "    ets = AutoETS(season_length=12, model=mod, damped=damped) \n",
    "    test_class(ets, x=ap, h=13, level=[90, 80], test_forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoETS.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import AutoETS\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoETS' usage example\n",
    "# Multiplicative trend, optimal error and seasonality\n",
    "autoets = AutoETS(model='ZMZ', season_length=4)\n",
    "autoets = autoets.fit(y=ap)\n",
    "y_hat_dict = autoets.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ETS(AutoETS):\n",
    "    @classmethod\n",
    "    def _warn(cls):\n",
    "        warnings.warn(\n",
    "            '`ETS` will be deprecated in future versions of `StatsForecast`. Please use `AutoETS` instead.',\n",
    "            category=FutureWarning,\n",
    "            stacklevel=2\n",
    "        )\n",
    "        \n",
    "    def __init__(self, season_length: int = 1, model: str = 'ZZZ', \n",
    "                 damped: Optional[bool] = None,\n",
    "                 phi: Optional[float] = None,\n",
    "                 alias: str = 'ETS',\n",
    "                 prediction_intervals: Optional[ConformalIntervals] = None):\n",
    "        ETS._warn()\n",
    "        super().__init__(\n",
    "            season_length=season_length,\n",
    "            model=model,\n",
    "            damped=damped,\n",
    "            phi=phi,\n",
    "            alias=alias,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets = ETS(model='ZMZ', season_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ets = ETS(model='ZMZ', season_length=4)\n",
    "autoets = AutoETS(model='ZMZ',  \n",
    "              season_length=4)\n",
    "test_eq(ets.forecast(y=ap, h=12)['mean'], \n",
    "        autoets.forecast(y=ap, h=12)['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(ETS()),\n",
    "    'ETS'\n",
    ")\n",
    "test_eq(\n",
    "    repr(ETS(alias='ETS_custom')),\n",
    "    'ETS_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoCES(_TS):\n",
    "    r\"\"\"Complex Exponential Smoothing model.\n",
    "\n",
    "    Automatically selects the best Complex Exponential Smoothing\n",
    "    model using an information criterion. Default is Akaike Information Criterion (AICc), while particular \n",
    "    models are estimated using maximum likelihood.\n",
    "    The state-space equations can be determined based on their $S$ simple, $P$ parial, \n",
    "    $Z$ optimized or $N$ ommited components. The `model` string parameter defines the \n",
    "    kind of CES model: $N$ for simple CES (withous seasonality), $S$ for simple seasonality (lagged CES),\n",
    "    $P$ for partial seasonality (without complex part), $F$ for full seasonality (lagged CES\n",
    "    with real and complex seasonal parts).\n",
    "    \n",
    "    If the component is selected as 'Z', it operates as a placeholder to ask the AutoCES model\n",
    "    to figure out the best parameter.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Svetunkov, Ivan & Kourentzes, Nikolaos. (2015). \"Complex Exponential Smoothing\". 10.13140/RG.2.1.3757.2562. ](https://onlinelibrary.wiley.com/doi/full/10.1002/nav.22074).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str \n",
    "        Controlling state-space-equations.\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    alias : str \n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int = 1,\n",
    "        model: str = 'Z',\n",
    "        alias: str = 'CES',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        self.season_length = season_length\n",
    "        self.model = model\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the Complex Exponential Smoothing model.\n",
    "\n",
    "        Fit the Complex Exponential Smoothing model to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            Complex Exponential Smoothing fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        if is_constant(y):\n",
    "            model = Naive(alias=self.alias, prediction_intervals=self.prediction_intervals)\n",
    "            model.fit(y=y, X=X)\n",
    "            return model\n",
    "        self.model_ = auto_ces(y, m=self.season_length, model=self.model)\n",
    "        self.model_['actual_residuals'] = y - self.model_['fitted']        \n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted Exponential Smoothing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level: List[float] \n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fcst = forecast_ces(self.model_, h=h, level=level)\n",
    "        res = {\"mean\": fcst[\"mean\"]}\n",
    "        if level is None: \n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            res = {\n",
    "                **res,\n",
    "                **{f\"lo-{l}\": fcst[f\"lo-{l}\"] for l in reversed(level)},\n",
    "                **{f\"hi-{l}\": fcst[f\"hi-{l}\"] for l in level},\n",
    "            }\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted Exponential Smoothing insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None: \n",
    "            residuals = self.model_['actual_residuals']\n",
    "            se = _calculate_sigma(residuals, self.model_['n'])\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None, \n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient Complex Exponential Smoothing predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenpus of shape (h, n_x). \n",
    "        level: List[float]\n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        if is_constant(y):\n",
    "            model = Naive(alias=self.alias, prediction_intervals=self.prediction_intervals)\n",
    "            return model.forecast(y=y, h=h, X=X, X_future=X_future, level=level, fitted=fitted)\n",
    "        mod = auto_ces(y, m=self.season_length, model=self.model)\n",
    "        fcst = forecast_ces(mod, h, level=level)\n",
    "        keys = ['mean']\n",
    "        if fitted:\n",
    "            keys.append('fitted')\n",
    "        res = {key: fcst[key] for key in keys}\n",
    "        if level is not None: \n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                res = {\n",
    "                    **res, \n",
    "                    **{f'lo-{l}': fcst[f'lo-{l}'] for l in reversed(level)}, \n",
    "                    **{f'hi-{l}': fcst[f'hi-{l}'] for l in level}, \n",
    "                }\n",
    "            if fitted: \n",
    "                # add prediction intervals for fitted values \n",
    "                se = _calculate_sigma(y - mod['fitted'], len(y)) \n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Apply fitted Complex Exponential Smoothing to a new time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenpus of shape (h, n_x). \n",
    "        level: List[float]\n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'model_'):\n",
    "            raise Exception('You have to use the `fit` method first')\n",
    "        y = _ensure_float(y)\n",
    "        mod = forward_ces(self.model_, y=y)\n",
    "        fcst = forecast_ces(mod, h, level=level)\n",
    "        keys = ['mean']\n",
    "        if fitted:\n",
    "            keys.append('fitted')\n",
    "        res = {key: fcst[key] for key in keys}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                res = {\n",
    "                    **res,\n",
    "                    **{f'lo-{l}': fcst[f'lo-{l}'] for l in reversed(level)},\n",
    "                    **{f'hi-{l}': fcst[f'hi-{l}'] for l in level},\n",
    "                }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = _calculate_sigma(y - mod['fitted'], len(y))\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "autoces = AutoCES(season_length=12)\n",
    "fcst_ces = autoces.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_ces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "autoces_c = AutoCES(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(autoces_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_ces_c = autoces_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_ces[\"mean\"],\n",
    "    fcst_ces_c[\"mean\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_ces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_ces_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "fit = autoces.fit(ap) \n",
    "fcst = fit.predict(13, None, (80,95))\n",
    "_plot_fcst(fit.predict(13, None, (80,95)))\n",
    "\n",
    "values = ['mean', 'lo-80', 'lo-95', 'hi-80', 'hi-95']\n",
    "for k in range(0, len(values)): \n",
    "    np.testing.assert_equal(\n",
    "    fcst_ces[values[k]], \n",
    "    fcst[values[k]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "pi_insample = fit.predict_in_sample((80,95))\n",
    "_plot_insample_pi(pi_insample)\n",
    "\n",
    "values = ['fitted', 'fitted-lo-80', 'fitted-lo-95', 'fitted-hi-80', 'fitted-hi-95']\n",
    "for k in range(0, len(values)): \n",
    "    np.testing.assert_equal(\n",
    "    fcst_ces[values[k]], \n",
    "    pi_insample[values[k]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ces = AutoCES(season_length=12)\n",
    "test_class(ces, x=ap, h=12, test_forward=True, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoCES()),\n",
    "    'CES'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoCES(alias='AutoCES_custom')),\n",
    "    'AutoCES_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoCES.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import AutoCES\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CES' usage example\n",
    "# Multiplicative trend, optimal error and seasonality\n",
    "ces = AutoCES(model='Z',  \n",
    "              season_length=4)\n",
    "ces = ces.fit(y=ap)\n",
    "y_hat_dict = ces.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoTheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoTheta(_TS):\n",
    "    r\"\"\"AutoTheta model.\n",
    "\n",
    "    Automatically selects the best Theta (Standard Theta Model ('STM'),\n",
    "    Optimized Theta Model ('OTM'), Dynamic Standard Theta Model ('DSTM'),\n",
    "    Dynamic Optimized Theta Model ('DOTM')) model using mse. \n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting](https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int\n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    decomposition_type : str \n",
    "        Sesonal decomposition type, 'multiplicative' (default) or 'additive'.\n",
    "    model : str \n",
    "        Controlling Theta Model. By default searchs the best model.\n",
    "    alias : str \n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        season_length: int = 1,\n",
    "        decomposition_type: str = 'multiplicative',\n",
    "        model: Optional[str] = None,\n",
    "        alias: str = 'AutoTheta',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        self.season_length = season_length\n",
    "        self.decomposition_type = decomposition_type\n",
    "        self.model = model\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        \n",
    "    def fit(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the AutoTheta model.\n",
    "\n",
    "        Fit an AutoTheta model to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            AutoTheta fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = auto_theta(\n",
    "            y=y,\n",
    "            m=self.season_length, \n",
    "            model=self.model, \n",
    "            decomposition_type=self.decomposition_type,\n",
    "        )\n",
    "        self.model_['fitted'] = y - self.model_['residuals']\n",
    "        self._store_cs(y, X)\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self, \n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted AutoTheta.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fcst = forecast_theta(self.model_, h=h, level=level)\n",
    "        if self.prediction_intervals is not None and level is not None:\n",
    "            fcst = self._add_predict_conformal_intervals(fcst, level)\n",
    "        return fcst\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted AutoTheta insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            se = np.std(self.model_['residuals'][3:], ddof=1)\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient AutoTheta predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = auto_theta(\n",
    "            y=y, \n",
    "            m=self.season_length, \n",
    "            model=self.model, \n",
    "            decomposition_type=self.decomposition_type\n",
    "        )\n",
    "        res = forecast_theta(mod, h, level=level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        if fitted:\n",
    "            res['fitted'] = y - mod['residuals']\n",
    "        if level is not None and fitted:\n",
    "            # add prediction intervals for fitted values\n",
    "            se = np.std(mod['residuals'][3:], ddof=1)\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Apply fitted AutoTheta to a new time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'model_'):\n",
    "            raise Exception('You have to use the `fit` method first')\n",
    "        y = _ensure_float(y)\n",
    "        mod = forward_theta(self.model_, y=y)\n",
    "        res = forecast_theta(mod, h, level=level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        if fitted:\n",
    "            res['fitted'] = y - mod['residuals']\n",
    "        if level is not None and fitted:\n",
    "            # add prediction intervals for fitted values\n",
    "            se = np.std(mod['residuals'][3:], ddof=1)\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "theta = AutoTheta(season_length=12)\n",
    "test_class(theta, x=ap, h=12, level=[80, 90], test_forward=True)\n",
    "fcst_theta = theta.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "theta_c = AutoTheta(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(theta_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_theta_c = theta_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_theta_c['mean'],\n",
    "    fcst_theta['mean'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_theta_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "zero_theta = theta.forward(np.zeros(10), h=12, level=[80, 90], fitted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoTheta()),\n",
    "    'AutoTheta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoTheta(alias='AutoTheta_custom')),\n",
    "    'AutoTheta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTheta.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import AutoTheta\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoTheta's usage example\n",
    "theta = AutoTheta(season_length=4)\n",
    "theta = theta.fit(y=ap)\n",
    "y_hat_dict = theta.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ARIMA(_TS):\n",
    "    r\"\"\"ARIMA model.\n",
    "\n",
    "    AutoRegressive Integrated Moving Average model.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [Rob J. Hyndman, Yeasmin Khandakar (2008). \"Automatic Time Series Forecasting: The forecast package for R\"](https://www.jstatsoft.org/article/view/v027i03).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    order : tuple (default=(0, 0, 0))\n",
    "        A specification of the non-seasonal part of the ARIMA model: the three components (p, d, q) are the AR order, the degree of differencing, and the MA order.\n",
    "    season_length : int (default=1)\n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    seasonal_order : tuple (default=(0, 0, 0))\n",
    "        A specification of the seasonal part of the ARIMA model.\n",
    "        (P, D, Q) for the  AR order, the degree of differencing, the MA order.\n",
    "    include_mean : bool (default=True)\n",
    "        Should the ARIMA model include a mean term? \n",
    "        The default is True for undifferenced series, False for differenced ones (where a mean would not affect the fit nor predictions).\n",
    "    include_drift : bool (default=False)\n",
    "        Should the ARIMA model include a linear drift term? \n",
    "        (i.e., a linear regression with ARIMA errors is fitted.)\n",
    "    include_constant : bool, optional (default=None)\n",
    "        If True, then includ_mean is set to be True for undifferenced series and include_drift is set to be True for differenced series. \n",
    "        Note that if there is more than one difference taken, no constant is included regardless of the value of this argument. \n",
    "        This is deliberate as otherwise quadratic and higher order polynomial trends would be induced.\n",
    "    blambda : float, optional (default=None)\n",
    "        Box-Cox transformation parameter.\n",
    "    biasadj : bool (default=False)\n",
    "        Use adjusted back-transformed mean Box-Cox.\n",
    "    method : str (default='CSS-ML')\n",
    "        Fitting method: maximum likelihood or minimize conditional sum-of-squares. \n",
    "        The default (unless there are missing values) is to use conditional-sum-of-squares to find starting values, then maximum likelihood.\n",
    "    fixed : dict, optional (default=None)\n",
    "        Dictionary containing fixed coefficients for the arima model. Example: `{'ar1': 0.5, 'ma2': 0.75}`.\n",
    "        For autoregressive terms use the `ar{i}` keys. For its seasonal version use `sar{i}`.\n",
    "        For moving average terms use the `ma{i}` keys. For its seasonal version use `sma{i}`.\n",
    "        For intercept and drift use the `intercept` and `drift` keys.\n",
    "        For exogenous variables use the `ex_{i}` keys.\n",
    "    alias : str\n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    uses_exog = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        order: Tuple[int, int, int] = (0, 0, 0),\n",
    "        season_length: int = 1,\n",
    "        seasonal_order: Tuple[int, int, int] = (0, 0, 0),\n",
    "        include_mean: bool = True,\n",
    "        include_drift: bool = False,\n",
    "        include_constant: Optional[bool] = None,\n",
    "        blambda: Optional[float] = None,\n",
    "        biasadj: bool = False,\n",
    "        method: str = 'CSS-ML',\n",
    "        fixed: Optional[dict] = None, \n",
    "        alias: str = 'ARIMA',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        self.order=order\n",
    "        self.season_length=season_length\n",
    "        self.seasonal_order=seasonal_order\n",
    "        self.include_mean=include_mean\n",
    "        self.include_drift=include_drift\n",
    "        self.include_constant=include_constant\n",
    "        self.blambda=blambda\n",
    "        self.biasadj=biasadj\n",
    "        self.method=method\n",
    "        self.fixed=fixed\n",
    "        self.alias=alias\n",
    "        self.prediction_intervals=prediction_intervals\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        Fit the model to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            Fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            self.model_ = Arima(\n",
    "                x=y,\n",
    "                order=self.order,\n",
    "                seasonal={'order': self.seasonal_order, \n",
    "                          'period': self.season_length},\n",
    "                xreg=X,\n",
    "                include_mean=self.include_mean,\n",
    "                include_constant=self.include_constant,\n",
    "                include_drift=self.include_drift,\n",
    "                blambda=self.blambda,\n",
    "                biasadj=self.biasadj,\n",
    "                method=self.method,\n",
    "                fixed=self.fixed\n",
    "            )\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self, \n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fcst = forecast_arima(self.model_, h=h, xreg=X, level=level)\n",
    "        mean = fcst['mean']\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            res = {\n",
    "                \"mean\": mean,\n",
    "                **{f\"lo-{l}\": fcst[\"lower\"][f\"{l}%\"] for l in reversed(level)},\n",
    "                **{f\"hi-{l}\": fcst[\"upper\"][f\"{l}%\"] for l in level},\n",
    "            }\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = fitted_arima(self.model_)\n",
    "        res = {'fitted': mean}\n",
    "        if level is not None:\n",
    "            se = np.sqrt(self.model_['sigma2'])\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory efficient predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x) optional exogenous. \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            mod = Arima(\n",
    "                x=y,\n",
    "                order=self.order,\n",
    "                seasonal={'order': self.seasonal_order, \n",
    "                          'period': self.season_length},\n",
    "                xreg=X,\n",
    "                include_mean=self.include_mean,\n",
    "                include_constant=self.include_constant,\n",
    "                include_drift=self.include_drift,\n",
    "                blambda=self.blambda,\n",
    "                biasadj=self.biasadj,\n",
    "                method=self.method,\n",
    "                fixed=self.fixed\n",
    "            )\n",
    "        fcst = forecast_arima(mod, h, xreg=X_future, level=level)\n",
    "        res = {'mean': fcst['mean']}\n",
    "        if fitted:\n",
    "            res['fitted'] = fitted_arima(mod)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                res = {\n",
    "                    **res,\n",
    "                    **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "                    **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "                }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = np.sqrt(mod['sigma2'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Apply fitted model to a new time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'model_'):\n",
    "            raise Exception('You have to use the `fit` method first')\n",
    "        y = _ensure_float(y)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            mod = forward_arima(self.model_, y=y, xreg=X, method=self.method)\n",
    "        fcst = forecast_arima(mod, h, xreg=X_future, level=level)\n",
    "        res = {'mean': fcst['mean']}\n",
    "        if fitted:\n",
    "            res['fitted'] = fitted_arima(mod)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                res = {\n",
    "                    **res,\n",
    "                    **{f'lo-{l}': fcst['lower'][f'{l}%'] for l in reversed(level)},\n",
    "                    **{f'hi-{l}': fcst['upper'][f'{l}%'] for l in level},\n",
    "                }\n",
    "            if fitted:\n",
    "                # add prediction intervals for fitted values\n",
    "                se = np.sqrt(mod['sigma2'])\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "simple_arima = ARIMA(order=(1, 0, 0), season_length=12) \n",
    "test_class(simple_arima, x=ap, h=12, level=[90, 80], test_forward=True)\n",
    "fcst_simple_arima = simple_arima.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_simple_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "simple_arima_c = ARIMA(order=(1, 0, 0), season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(simple_arima_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_simple_arima_c = simple_arima_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_simple_arima_c['mean'],\n",
    "    fcst_simple_arima['mean'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_simple_arima_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "simple_arima = ARIMA(order=(2, 0, 0), season_length=12, fixed={'ar1': 0.5, 'ar2': 0.5}) \n",
    "test_class(simple_arima, x=ap, h=12, level=[90, 80], test_forward=True)\n",
    "fcst_simple_arima = simple_arima.forecast(ap, 4, None, None, (80,95), True)\n",
    "_plot_insample_pi(fcst_simple_arima)\n",
    "test_eq(\n",
    "    fcst_simple_arima['mean'],\n",
    "    np.array([411., 421.5, 416.25, 418.875])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(ARIMA()),\n",
    "    'ARIMA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(ARIMA(alias='ARIMA_seasonality')),\n",
    "    'ARIMA_seasonality'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARIMA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARIMA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARIMA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARIMA.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARIMA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARIMA.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import ARIMA\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA's usage example\n",
    "arima = ARIMA(order=(1, 0, 0), season_length=12)\n",
    "arima = arima.fit(y=ap)\n",
    "y_hat_dict = arima.predict(h=4, level=[80])\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoRegressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoRegressive(ARIMA):\n",
    "    r\"\"\"Simple Autoregressive model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lags : int or list \n",
    "        Number of lags to include in the model. \n",
    "        If an int is passed then all lags up to `lags` are considered.\n",
    "        If a list, only the elements of the list are considered as lags.\n",
    "    include_mean : bool (default=True)\n",
    "        Should the AutoRegressive model include a mean term? \n",
    "        The default is True for undifferenced series, False for differenced ones (where a mean would not affect the fit nor predictions).\n",
    "    include_drift : bool (default=False)\n",
    "        Should the AutoRegressive model include a linear drift term? \n",
    "        (i.e., a linear regression with AutoRegressive errors is fitted.)\n",
    "    blambda : float, optional (default=None)\n",
    "        Box-Cox transformation parameter.\n",
    "    biasadj : bool (default=False)\n",
    "        Use adjusted back-transformed mean Box-Cox.\n",
    "    method : str (default='CSS-ML')\n",
    "        Fitting method: maximum likelihood or minimize conditional sum-of-squares. \n",
    "        The default (unless there are missing values) is to use conditional-sum-of-squares to find starting values, then maximum likelihood.\n",
    "    fixed : dict, optional (default=None)\n",
    "        Dictionary containing fixed coefficients for the AutoRegressive model. Example: `{'ar1': 0.5, 'ar5': 0.75}`.\n",
    "        For autoregressive terms use the `ar{i}` keys.\n",
    "    alias : str\n",
    "        Custom name of the model.  \n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    uses_exog = True\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        lags: Tuple[int, List],\n",
    "        include_mean: bool = True,\n",
    "        include_drift: bool = False,\n",
    "        blambda: Optional[float] = None,\n",
    "        biasadj: bool = False,\n",
    "        method: str = 'CSS-ML',\n",
    "        fixed: Optional[dict] = None, \n",
    "        alias: str = 'AutoRegressive',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        if isinstance(lags, int):\n",
    "            order = (lags, 0, 0)\n",
    "        elif isinstance(lags, list):\n",
    "            order = (max(lags), 0, 0)\n",
    "            fixed_lags = {f'ar{i+1}': np.nan if (i+1) in lags else 0 for i in range(max(lags))}\n",
    "            if fixed is not None:\n",
    "                fixed_lags.update(fixed)\n",
    "            fixed = fixed_lags\n",
    "        else:\n",
    "            raise ValueError('Please provide an int or a list specifying the lags to use.')\n",
    "        super().__init__(\n",
    "            order=order,\n",
    "            include_mean=include_mean, \n",
    "            include_drift=include_drift,\n",
    "            blambda=blambda,\n",
    "            biasadj=biasadj,\n",
    "            method=method,\n",
    "            alias=alias,\n",
    "            fixed=fixed,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ar = AutoRegressive(lags=[12], fixed={'ar12': 0.9999999}) \n",
    "test_class(ar, x=ap, h=12, level=[90, 80], test_forward=True)\n",
    "fcst_ar = ar.forecast(ap, 13, None, None, (80,95), True)\n",
    "# we should recover seasonal naive\n",
    "test_close(\n",
    "    fcst_ar['mean'][:-1],\n",
    "    ap[-12:], \n",
    "    eps=1e-4\n",
    ")\n",
    "_plot_insample_pi(fcst_simple_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "ar_c = AutoRegressive(lags=[12], fixed={'ar12': 0.9999999}, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(ar_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_ar_c = ar_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "#| hide\n",
    "test_eq(\n",
    "    fcst_ar_c['mean'],\n",
    "    fcst_ar['mean'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_fcst(fcst_ar_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(AutoRegressive(lags=[12])),\n",
    "    'AutoRegressive'\n",
    ")\n",
    "test_eq(\n",
    "    repr(AutoRegressive(lags=[12], alias='AutoRegressive_lag12')),\n",
    "    'AutoRegressive_lag12'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoRegressive, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoRegressive.fit, title_level=3, name='AutoRegressive.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoRegressive.predict, title_level=3, name='AutoRegressive.predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoRegressive.predict_in_sample, title_level=3, name='AutoRegressive.predict_in_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoRegressive.forecast, title_level=3, name='AutoRegressive.forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoRegressive.forward, title_level=3, name='AutoRegressive.forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import AutoRegressive\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoRegressive's usage example\n",
    "ar = AutoRegressive(lags=[12])\n",
    "ar = ar.fit(y=ap)\n",
    "y_hat_dict = ar.predict(h=4, level=[80])\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@njit(nogil=NOGIL, cache=CACHE)\n",
    "def _ses_fcst_mse(x: np.ndarray, alpha: float) -> Tuple[float, float, np.ndarray]:\n",
    "    r\"\"\"Perform simple exponential smoothing on a series.\n",
    "\n",
    "    This function returns the one step ahead prediction\n",
    "    as well as the mean squared error of the fit.\n",
    "    \"\"\"\n",
    "    smoothed = x[0]\n",
    "    n = x.size\n",
    "    mse = 0.\n",
    "    fitted = np.full(n, np.nan, dtype=x.dtype)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        smoothed = (alpha * x[i - 1] + (1 - alpha) * smoothed).item()\n",
    "        error = x[i] - smoothed\n",
    "        mse += error * error\n",
    "        fitted[i] = smoothed\n",
    "\n",
    "    mse /= n\n",
    "    forecast = alpha * x[-1] + (1 - alpha) * smoothed\n",
    "    return forecast, mse, fitted\n",
    "\n",
    "\n",
    "def _ses_mse(alpha: float, x: np.ndarray) -> float:\n",
    "    r\"\"\"Compute the mean squared error of a simple exponential smoothing fit.\"\"\"\n",
    "    _, mse, _ = _ses_fcst_mse(x, alpha)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def _ses_forecast(x: np.ndarray, alpha: float) -> Tuple[float, np.ndarray]:\n",
    "    r\"\"\"One step ahead forecast with simple exponential smoothing.\"\"\"\n",
    "    forecast, _, fitted = _ses_fcst_mse(x, alpha)\n",
    "    return forecast, fitted\n",
    "\n",
    "\n",
    "def _demand(x: np.ndarray) -> np.ndarray:\n",
    "    r\"\"\"Extract the positive elements of a vector.\"\"\"\n",
    "    return x[x > 0]\n",
    "\n",
    "\n",
    "def _intervals(x: np.ndarray) -> np.ndarray:\n",
    "    r\"\"\"Compute the intervals between non zero elements of a vector.\"\"\"\n",
    "    nonzero_idxs = np.where(x != 0)[0]\n",
    "    return np.diff(nonzero_idxs + 1, prepend=0).astype(x.dtype)\n",
    "\n",
    "\n",
    "def _probability(x: np.ndarray) -> np.ndarray:\n",
    "    r\"\"\"Compute the element probabilities of being non zero.\"\"\"\n",
    "    return (x != 0).astype(x.dtype)\n",
    "\n",
    "\n",
    "def _optimized_ses_forecast(\n",
    "        x: np.ndarray,\n",
    "        bounds: Sequence[Tuple[float, float]] = [(0.1, 0.3)]\n",
    "    ) -> Tuple[float, np.ndarray]:\n",
    "    r\"\"\"Searches for the optimal alpha and computes SES one step forecast.\"\"\"\n",
    "    alpha = minimize(\n",
    "        fun=_ses_mse,\n",
    "        x0=(0,),\n",
    "        args=(x,),\n",
    "        bounds=bounds,\n",
    "        method='L-BFGS-B'\n",
    "    ).x[0]\n",
    "    forecast, fitted = _ses_forecast(x, alpha)\n",
    "    return forecast, fitted\n",
    "\n",
    "\n",
    "def _chunk_sums(array: np.ndarray, chunk_size: int) -> np.ndarray:\n",
    "    r\"\"\"Splits an array into chunks and returns the sum of each chunk.\n",
    "    \n",
    "    Incomplete chunks are discarded\"\"\"\n",
    "    n_chunks = array.size // chunk_size\n",
    "    n_elems = n_chunks * chunk_size\n",
    "    return array[:n_elems].reshape(n_chunks, chunk_size).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _ses(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    "    alpha: float, # smoothing parameter\n",
    ") -> Dict[str, np.ndarray]: \n",
    "    fcst, _, fitted_vals = _ses_fcst_mse(y, alpha)\n",
    "    fcst = {'mean': _repeat_val(val=fcst, h=h)}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimpleExponentialSmoothing(_TS):\n",
    "    r\"\"\"SimpleExponentialSmoothing model.\n",
    "\n",
    "    Uses a weighted average of all past observations where the weights decrease exponentially into the past. \n",
    "    Suitable for data with no clear trend or seasonality. \n",
    "    Assuming there are $t$ observations, the one-step forecast is given by: $\\hat{y}_{t+1} = \\alpha y_t + (1-\\alpha) \\hat{y}_{t-1}$\n",
    "\n",
    "    The rate $0 \\leq \\alpha \\leq 1$ at which the weights decrease is called the smoothing parameter. When $\\alpha = 1$, SES is equal to the naive method.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [Charles C Holt (1957). “Forecasting seasonals and trends by exponentially weighted moving averages”](https://doi.org/10.1016/j.ijforecast).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float \n",
    "        Smoothing parameter.\n",
    "    alias : str \n",
    "        Custom name of the model. \n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha: float,\n",
    "        alias: str = 'SES',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        self.alpha = alpha\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "        \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the SimpleExponentialSmoothing model.\n",
    "\n",
    "        Fit an SimpleExponentialSmoothing to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            SimpleExponentialSmoothing fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _ses(y=y, alpha=self.alpha, h=1, fitted=True)\n",
    "        self.model_ = dict(mod)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted SimpleExponentialSmoothing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to \" \"compute them.\")\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        r\"\"\"Access fitted SimpleExponentialSmoothing insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions.\n",
    "            \n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient SimpleExponentialSmoothing predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _ses(y=y, h=h, fitted=fitted, alpha=self.alpha)\n",
    "        res = dict(res)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to \" \"compute them.\")\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ses = SimpleExponentialSmoothing(alpha=0.1)\n",
    "test_class(ses, x=ap, h=12)\n",
    "#more tests\n",
    "ses = ses.fit(ap)\n",
    "fcst_ses = ses.predict(12)\n",
    "test_close(fcst_ses['mean'], np.repeat(460.3028, 12), eps=1e-4)\n",
    "#to recover these residuals from R\n",
    "#you have to pass initial=\"simple\"\n",
    "#in the `ses` function\n",
    "np.testing.assert_allclose(\n",
    "    ses.predict_in_sample()['fitted'][[0, 1, -1]], \n",
    "    np.array([np.nan, 118 - 6., 432 + 31.447525])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "ses_c = SimpleExponentialSmoothing(alpha=0.1, prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(ses_c, x=ap, h=13, level=[90, 80], test_forward=False, skip_insample=True)\n",
    "fcst_ses_c = ses_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_ses_c['mean'][:12],\n",
    "    fcst_ses['mean']\n",
    ")\n",
    "_plot_fcst(fcst_ses_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SimpleExponentialSmoothing(alpha=0.1)),\n",
    "    'SES'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SimpleExponentialSmoothing(alpha=0.1, alias='SES_custom')),\n",
    "    'SES_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothing.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import SimpleExponentialSmoothing\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleExponentialSmoothing's usage example\n",
    "ses = SimpleExponentialSmoothing(alpha=0.5)\n",
    "ses = ses.fit(y=ap)\n",
    "y_hat_dict = ses.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSmoothOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _ses_optimized(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ):\n",
    "    fcst_, fitted_vals = _optimized_ses_forecast(y, [(0.01, 0.99)])\n",
    "    mean = _repeat_val(val=fcst_, h=h)\n",
    "    fcst = {'mean': mean}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimpleExponentialSmoothingOptimized(_TS):\n",
    "    r\"\"\"SimpleExponentialSmoothing model.\n",
    "\n",
    "    Uses a weighted average of all past observations where the weights decrease exponentially into the past. \n",
    "    Suitable for data with no clear trend or seasonality. \n",
    "    Assuming there are $t$ observations, the one-step forecast is given by: $\\hat{y}_{t+1} = \\alpha y_t + (1-\\alpha) \\hat{y}_{t-1}$\n",
    "\n",
    "    The smoothing parameter $\\alpha^*$ is optimized by square error minimization.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [Charles C Holt (1957). “Forecasting seasonals and trends by exponentially weighted moving averages”](https://doi.org/10.1016/j.ijforecast).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alias: str \n",
    "        Custom name of the model.   \n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        This is required for generating future prediction intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        alias: str = \"SESOpt\",\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the SimpleExponentialSmoothingOptimized model.\n",
    "\n",
    "        Fit an SimpleExponentialSmoothingOptimized to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            SimpleExponentialSmoothingOptimized fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _ses_optimized(y=y, h=1, fitted=True)\n",
    "        self.model_ = dict(mod)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted SimpleExponentialSmoothingOptimized.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "\n",
    "    def predict_in_sample(self):\n",
    "        r\"\"\"Access fitted SimpleExponentialSmoothingOptimized insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient SimpleExponentialSmoothingOptimized predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _ses_optimized(y=y, h=h, fitted=fitted)\n",
    "        res = dict(res)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ses_op = SimpleExponentialSmoothingOptimized()\n",
    "test_class(ses_op, x=ap, h=12)\n",
    "ses_op = ses_op.fit(ap)\n",
    "fcst_ses_op = ses_op.predict(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "ses_op_c = SimpleExponentialSmoothingOptimized(prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(ses_op_c, x=ap, h=13, level=[90, 80], skip_insample=True)\n",
    "fcst_ses_op_c = ses_op_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_ses_op_c['mean'][:12],\n",
    "    fcst_ses_op['mean']\n",
    "    )\n",
    "_plot_fcst(fcst_ses_op_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SimpleExponentialSmoothingOptimized()),\n",
    "    'SESOpt'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SimpleExponentialSmoothingOptimized(alias='SESOpt_custom')),\n",
    "    'SESOpt_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SimpleExponentialSmoothingOptimized.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import SimpleExponentialSmoothingOptimized\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleExponentialSmoothingOptimized's usage example\n",
    "seso = SimpleExponentialSmoothingOptimized()\n",
    "seso = seso.fit(y=ap)\n",
    "y_hat_dict = seso.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeasonalSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _seasonal_exponential_smoothing(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    "    season_length: int, # length of season\n",
    "    alpha: float, # smoothing parameter\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    n = y.size\n",
    "    if n < season_length:\n",
    "        return {'mean': np.full(h, np.nan, dtype=y.dtype)}\n",
    "    season_vals = np.empty(season_length, dtype=y.dtype)\n",
    "    fitted_vals = np.full_like(y, np.nan)\n",
    "    for i in range(season_length):\n",
    "        init_idx = (i + n % season_length)\n",
    "        season_vals[i], fitted_vals[init_idx::season_length] = _ses_forecast(y[init_idx::season_length], alpha)\n",
    "    out = _repeat_val_seas(season_vals=season_vals, h=h)\n",
    "    fcst = {'mean': out}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeasonalExponentialSmoothing(_TS):\n",
    "    r\"\"\"SeasonalExponentialSmoothing model.\n",
    "\n",
    "    Uses a weighted average of all past observations where the weights decrease exponentially into the past. \n",
    "    Suitable for data with no clear trend or seasonality. \n",
    "    Assuming there are $t$ observations and season $s$, the one-step forecast is given by: \n",
    "    $\\hat{y}_{t+1,s} = \\alpha y_t + (1-\\alpha) \\hat{y}_{t-1,s}$\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This method is an extremely simplified of Holt-Winter's method where the trend and level are set to zero.\n",
    "    And a single seasonal smoothing parameter $\\alpha$ is shared across seasons.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [Charles. C. Holt (1957). \"Forecasting seasonals and trends by exponentially weighted moving averages\", ONR Research Memorandum, Carnegie Institute of Technology 52.](https://www.sciencedirect.com/science/article/abs/pii/S0169207003001134).\n",
    "    [Peter R. Winters (1960). \"Forecasting sales by exponentially weighted moving averages\". Management Science](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.3.324).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float \n",
    "        Smoothing parameter.\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    alias : str \n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        This is required for generating future prediction intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            season_length: int,\n",
    "            alpha: float,\n",
    "            alias: str = 'SeasonalES',\n",
    "            prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "        ):\n",
    "        self.season_length = season_length\n",
    "        self.alpha = alpha\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the SeasonalExponentialSmoothing model.\n",
    "\n",
    "        Fit an SeasonalExponentialSmoothing to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            SeasonalExponentialSmoothing fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _seasonal_exponential_smoothing(\n",
    "            y=y, \n",
    "            season_length=self.season_length, \n",
    "            alpha=self.alpha,\n",
    "            fitted=True,\n",
    "            h=self.season_length,\n",
    "        )\n",
    "        self.model_ = dict(mod)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted SeasonalExponentialSmoothing.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val_seas(self.model_['mean'], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        r\"\"\"Access fitted SeasonalExponentialSmoothing insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient SeasonalExponentialSmoothing predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x).\n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _seasonal_exponential_smoothing(\n",
    "            y=y, h=h, fitted=fitted, alpha=self.alpha, season_length=self.season_length\n",
    "        )\n",
    "        res = dict(res)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "seas_es = SeasonalExponentialSmoothing(season_length=12, alpha=1.)\n",
    "test_class(seas_es, x=ap, h=12)\n",
    "test_eq(seas_es.predict_in_sample()['fitted'][-3:],  np.array([461 - 54., 390 - 28., 432 - 27.]))\n",
    "seas_es = seas_es.fit(ap)\n",
    "fcst_seas_es = seas_es.predict(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "seas_es_c = SeasonalExponentialSmoothing(season_length=12, alpha=1., prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(seas_es_c, x=ap, h=13, level=[90, 80], test_forward=False, skip_insample=True)\n",
    "fcst_seas_es_c = seas_es_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_seas_es_c['mean'][:12],\n",
    "    fcst_seas_es['mean']\n",
    ")\n",
    "_plot_fcst(fcst_seas_es_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test we can recover the expected seasonality\n",
    "test_eq(\n",
    "    seas_es.forecast(ap[4:], h=12)['mean'],\n",
    "    seas_es.forecast(ap, h=12)['mean']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test close to seasonal naive\n",
    "for i in range(1, 13):\n",
    "    test_close(\n",
    "        ap[i:][-12:],\n",
    "        seas_es.forecast(ap[i:], h=12)['mean'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.concatenate([ap[6:], seas_es.forecast(ap[6:], h=12)['mean']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SeasonalExponentialSmoothing(season_length=12, alpha=1.)),\n",
    "    'SeasonalES'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SeasonalExponentialSmoothing(season_length=12, alpha=1., alias='SeasonalES_custom')),\n",
    "    'SeasonalES_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothing.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import SeasonalExponentialSmoothing\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeasonalExponentialSmoothing's usage example\n",
    "model = SeasonalExponentialSmoothing(alpha=0.5, season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeasonalSmoothOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _seasonal_ses_optimized(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool , # fitted values\n",
    "    season_length: int, # season length\n",
    "): \n",
    "    n = y.size\n",
    "    if n < season_length:\n",
    "        return {'mean': np.full(h, np.nan, dtype=y.dtype)}\n",
    "    season_vals = np.empty(season_length, dtype=y.dtype)\n",
    "    fitted_vals = np.full_like(y, np.nan)\n",
    "    for i in range(season_length):\n",
    "        init_idx = (i + n % season_length)\n",
    "        season_vals[i], fitted_vals[init_idx::season_length] = _optimized_ses_forecast(y[init_idx::season_length], [(0.01, 0.99)])\n",
    "    out = _repeat_val_seas(season_vals=season_vals, h=h)\n",
    "    fcst = {'mean': out}\n",
    "    if fitted:\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeasonalExponentialSmoothingOptimized(_TS):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int,\n",
    "        alias: str = 'SeasESOpt',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        r\"\"\"SeasonalExponentialSmoothingOptimized model.\n",
    "\n",
    "        Uses a weighted average of all past observations where the weights decrease exponentially into the past. \n",
    "        Suitable for data with no clear trend or seasonality. \n",
    "        Assuming there are $t$ observations and season $s$, the one-step forecast is given by: \n",
    "        $\\hat{y}_{t+1,s} = \\alpha y_t + (1-\\alpha) \\hat{y}_{t-1,s}$\n",
    "        \n",
    "        The smoothing parameter $\\alpha^*$ is optimized by square error minimization.        \n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        This method is an extremely simplified of Holt-Winter's method where the trend and level are set to zero.\n",
    "        And a single seasonal smoothing parameter $\\alpha$ is shared across seasons.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Charles. C. Holt (1957). \"Forecasting seasonals and trends by exponentially weighted moving averages\", ONR Research Memorandum, Carnegie Institute of Technology 52.](https://www.sciencedirect.com/science/article/abs/pii/S0169207003001134).\n",
    "        [Peter R. Winters (1960). \"Forecasting sales by exponentially weighted moving averages\". Management Science](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.3.324).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        season_length : int  \n",
    "            Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "        alias : str \n",
    "            Custom name of the model.  \n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            This is required for generating future prediction intervals.\n",
    "        \"\"\"\n",
    "        self.season_length = season_length\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the SeasonalExponentialSmoothingOptimized model.\n",
    "\n",
    "        Fit an SeasonalExponentialSmoothingOptimized to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            SeasonalExponentialSmoothingOptimized fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _seasonal_ses_optimized(\n",
    "            y=y, \n",
    "            season_length=self.season_length, \n",
    "            fitted=True,\n",
    "            h=self.season_length,\n",
    "        )\n",
    "        self.model_ = dict(mod)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted SeasonalExponentialSmoothingOptimized.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val_seas(self.model_['mean'], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        r\"\"\"Access fitted SeasonalExponentialSmoothingOptimized insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient SeasonalExponentialSmoothingOptimized predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _seasonal_ses_optimized(\n",
    "            y=y, h=h, fitted=fitted, \n",
    "            season_length=self.season_length\n",
    "        )\n",
    "        res = dict(res)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "seas_es_opt = SeasonalExponentialSmoothingOptimized(season_length=12)\n",
    "test_class(seas_es_opt, x=ap, h=12)\n",
    "fcst_seas_es_opt = seas_es_opt.forecast(ap, h=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "seas_es_opt_c = SeasonalExponentialSmoothingOptimized(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(seas_es_opt_c, x=ap, h=13, level=[90, 80], test_forward=False, skip_insample=True)\n",
    "fcst_seas_es_opt_c = seas_es_opt_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_seas_es_opt_c['mean'][:12],\n",
    "    fcst_seas_es_opt['mean']\n",
    ")\n",
    "_plot_fcst(fcst_seas_es_opt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "for i in range(1, 13):\n",
    "    test_close(\n",
    "        ap[i:][-12:],\n",
    "        seas_es_opt.forecast(ap[i:], h=12)['mean'],\n",
    "        eps=0.8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SeasonalExponentialSmoothingOptimized(season_length=12)),\n",
    "    'SeasESOpt'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SeasonalExponentialSmoothingOptimized(season_length=12, alias='SeasESOpt_custom')),\n",
    "    'SeasESOpt_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalExponentialSmoothingOptimized.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import SeasonalExponentialSmoothingOptimized\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeasonalExponentialSmoothingOptimized's usage example\n",
    "model = SeasonalExponentialSmoothingOptimized(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt's method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Holt(AutoETS): \n",
    "    r\"\"\" Holt's method. \n",
    "\n",
    "    Also known as double exponential smoothing, Holt's method is an extension of exponential smoothing for series with a trend.\n",
    "    This implementation returns the corresponding `ETS` model with additive (A) or multiplicative (M) errors (so either 'AAN' or 'MAN'). \n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Methods with trend\"](https://otexts.com/fpp3/holt.html).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 12 Monthly data. \n",
    "    error_type : str \n",
    "        The type of error of the ETS model. Can be additive (A) or multiplicative (M). \n",
    "    alias : str \n",
    "        Custom name of the model. \n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int = 1, \n",
    "        error_type: str = 'A',\n",
    "        alias: str = 'Holt',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ): \n",
    "        self.season_length = season_length\n",
    "        self.error_type = error_type\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        model = error_type + 'AN'\n",
    "        super().__init__(\n",
    "            season_length, model, alias=alias, prediction_intervals=prediction_intervals\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "holt = Holt(season_length=12, error_type='A')\n",
    "fcast_holt = holt.forecast(ap,12)\n",
    "\n",
    "ets = AutoETS(season_length=12, model='AAN')\n",
    "fcast_ets = ets.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_holt, \n",
    "    fcast_ets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "holt = Holt(season_length=12, error_type='A')\n",
    "holt.fit(ap)\n",
    "fcast_holt = holt.predict(12)\n",
    "\n",
    "ets = AutoETS(season_length=12, model='AAN')\n",
    "fcast_ets = ets.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_holt, \n",
    "    fcast_ets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "holt_c = Holt(season_length=12, error_type='A', prediction_intervals=ConformalIntervals(h=12, n_windows=2))\n",
    "fcast_holt_c = holt_c.forecast(ap, 12, level=[80, 90])\n",
    "\n",
    "ets_c = AutoETS(season_length=12, model='AAN', prediction_intervals=ConformalIntervals(h=12, n_windows=2))\n",
    "fcast_ets_c = ets_c.forecast(ap, 12, level=[80, 90])\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_holt_c, \n",
    "    fcast_ets_c,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(Holt()),\n",
    "    'Holt'\n",
    ")\n",
    "test_eq(\n",
    "    repr(Holt(alias='Holt_custom')),\n",
    "    'Holt_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.forecast, name='Holt.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.fit, name='Holt.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.predict, name='Holt.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.predict_in_sample, name='Holt.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Holt.forward, name='Holt.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import Holt\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holt's usage example\n",
    "model = Holt(season_length=12, error_type='A')\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt-Winters' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class HoltWinters(AutoETS): \n",
    "    r\"\"\" Holt-Winters' method. \n",
    "    \n",
    "    Also known as triple exponential smoothing, Holt-Winters' method is an extension of exponential smoothing for series that contain both trend and seasonality.\n",
    "    This implementation returns the corresponding `ETS` model with additive (A) or multiplicative (M) errors (so either 'AAA' or 'MAM'). \n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Methods with seasonality\"](https://otexts.com/fpp3/holt-winters.html).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 12 Monthly data. \n",
    "    error_type : str\n",
    "        The type of error of the ETS model. Can be additive (A) or multiplicative (M).\n",
    "    alias : str \n",
    "        Custom name of the model. \n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int = 1, # season length\n",
    "        error_type: str = 'A', # error type\n",
    "        alias: str = 'HoltWinters',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ): \n",
    "        self.season_length = season_length\n",
    "        self.error_type = error_type\n",
    "        self.alias = alias\n",
    "        model = error_type + 'A' + error_type\n",
    "        super().__init__(\n",
    "            season_length, model, alias=alias, prediction_intervals=prediction_intervals\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "hw = HoltWinters(season_length=12, error_type='A')\n",
    "fcast_hw = hw.forecast(ap,12)\n",
    "\n",
    "ets = AutoETS(season_length=12, model='AAA')\n",
    "fcast_ets = ets.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_hw, \n",
    "    fcast_ets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "hw_c = HoltWinters(season_length=12, error_type='A', prediction_intervals=ConformalIntervals(h=12, n_windows=2))\n",
    "fcast_hw_c = hw_c.forecast(ap, 12, level=[80, 90])\n",
    "\n",
    "ets_c = AutoETS(season_length=12, model='AAA', prediction_intervals=ConformalIntervals(h=12, n_windows=2))\n",
    "fcast_ets_c = ets_c.forecast(ap, 12, level=[80, 90])\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_hw_c, \n",
    "    fcast_ets_c,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "hw = HoltWinters(season_length=12, error_type='A')\n",
    "hw.fit(ap)\n",
    "fcast_hw = hw.predict(12)\n",
    "\n",
    "ets = AutoETS(season_length=12, model='AAA')\n",
    "fcast_ets = ets.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_hw, \n",
    "    fcast_ets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(HoltWinters()),\n",
    "    'HoltWinters'\n",
    ")\n",
    "test_eq(\n",
    "    repr(HoltWinters(alias='HoltWinters_custom')),\n",
    "    'HoltWinters_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.forecast, name='HoltWinters.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.fit, name='HoltWinters.fit', title_level=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.predict, name='HoltWinters.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.predict_in_sample, name= 'HoltWinters.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HoltWinters.forward, name='HoltWinters.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import HoltWinters\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holt-Winters' usage example\n",
    "model = HoltWinters(season_length=12, error_type='A')\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistoricAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _historic_average(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    fcst = {'mean': _repeat_val(val=y.mean(), h=h)}\n",
    "    if fitted:\n",
    "        fitted_vals = _repeat_val(val=y.mean(), h=len(y))\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HistoricAverage(_TS):\n",
    "\n",
    "    def __init__(self, alias: str = 'HistoricAverage', prediction_intervals: Optional[ConformalIntervals] = None,):\n",
    "        r\"\"\"HistoricAverage model.\n",
    "\n",
    "        Also known as mean method. Uses a simple average of all past observations. \n",
    "        Assuming there are $t$ observations, the one-step forecast is given by: \n",
    "        $$\\hat{y}_{t+1} = \\frac{1}{t} \\sum_{j=1}^t y_j$$\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        alias: str\n",
    "              Custom name of the model. \n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            By default, the model will compute the native prediction\n",
    "            intervals.\n",
    "        \"\"\"\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the HistoricAverage model.\n",
    "\n",
    "        Fit an HistoricAverage to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        y : numpy.array  \n",
    "         Clean time series of shape (t, ).  \n",
    "        X : array-like \n",
    "         Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "            HistoricAverage fitted model.\n",
    "        r\"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _historic_average(y, h=1, fitted=True)\n",
    "        mod = dict(mod) \n",
    "        residuals = y - mod['fitted']\n",
    "        mod['sigma'] = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "        mod['n'] = len(y)\n",
    "        self.model_ = mod\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self, \n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted HistoricAverage.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : numpy.array \n",
    "            Optional exogenous of shape (h, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(1 + (1 / self.model_['n']))\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted HistoricAverage insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(1 + (1 / self.model_['n']))\n",
    "            res = _add_fitted_pi(res, se=sigmah, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):        \n",
    "        r\"\"\"Memory Efficient HistoricAverage predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ).  \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like  \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : list[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict  \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        out = _historic_average(y=y, h=h, fitted=fitted or (level is not None))\n",
    "        res = {'mean': out['mean']}\n",
    "        \n",
    "        if fitted:\n",
    "            res['fitted'] = out['fitted']\n",
    "        if level is not None: \n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                residuals = y - out[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "                sigmah = sigma * np.sqrt(1 + (1 / len(y)))\n",
    "                pred_int = _calculate_intervals(out, level, h, sigmah)\n",
    "                res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                residuals = y - out[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "                sigmah = sigma * np.sqrt(1 + (1 / len(y)))\n",
    "                res = _add_fitted_pi(res=res, se=sigmah, level=level)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "ha = HistoricAverage()\n",
    "test_class(ha, x=ap, h=12, level=[80, 90])\n",
    "#more tests\n",
    "ha.fit(ap)\n",
    "fcst_ha = ha.predict(12)\n",
    "test_close(fcst_ha['mean'], np.repeat(ap.mean(), 12), eps=1e-5)\n",
    "np.testing.assert_almost_equal(\n",
    "    ha.predict_in_sample()['fitted'][:4],\n",
    "    #np.array([np.nan, 112., 115., 120.6666667]), \n",
    "    np.array([280.2986,280.2986,280.2986,280.2986]), \n",
    "    decimal=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "ha = HistoricAverage()\n",
    "fcst_ha = ha.forecast(ap,12,None,None,(80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_ha['lo-80'],\n",
    "    np.repeat(126.0227,12),\n",
    "    decimal=4\n",
    ")\n",
    "_plot_insample_pi(fcst_ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "ha_c = HistoricAverage(prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(ha_c, x=ap, h=13, level=[90, 80], test_forward=False)\n",
    "fcst_ha_c = ha_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_ha_c['mean'][:12],\n",
    "    fcst_ha['mean'],\n",
    ")\n",
    "_plot_fcst(fcst_ha_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(HistoricAverage()),\n",
    "    'HistoricAverage'\n",
    ")\n",
    "test_eq(\n",
    "    repr(HistoricAverage(alias='HistoricAverage_custom')),\n",
    "    'HistoricAverage_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(HistoricAverage.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import HistoricAverage\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HistoricAverage's usage example\n",
    "model = HistoricAverage()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Naive(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'Naive', prediction_intervals: Optional[ConformalIntervals] = None):\n",
    "        r\"\"\"Naive model.\n",
    "        \n",
    "        All forecasts have the value of the last observation:  \n",
    "        $\\hat{y}_{t+1} = y_t$ for all $t$\n",
    "         \n",
    "        References\n",
    "        ----------\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html). \n",
    "        \n",
    "        Parameters \n",
    "        ----------\n",
    "        alias: str\n",
    "            Custom name of the model.\n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            By default, the model will compute the native prediction\n",
    "            intervals.\n",
    "        \"\"\"\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the Naive model.\n",
    "\n",
    "        Fit an Naive to a time series (numpy.array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like\n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self:\n",
    "            Naive fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _naive(y, h=1, fitted=True)\n",
    "        mod = dict(mod) \n",
    "        residuals = y - mod['fitted']\n",
    "        sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "        mod['sigma'] = sigma\n",
    "        self.model_ = mod\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self, \n",
    "        h: int, # forecasting horizon \n",
    "        X: Optional[np.ndarray] = None, # exogenous regressors\n",
    "        level: Optional[List[int]] = None # confidence level\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted Naive.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            steps = np.arange(1,h+1)\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(steps)\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted Naive insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `fitted` for point predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient Naive predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n,). \n",
    "        h: int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like\n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        out = _naive(y=y, h=h, fitted=fitted or (level is not None))\n",
    "        res = {'mean': out['mean']}\n",
    "        if fitted:\n",
    "            res['fitted'] = out['fitted']\n",
    "        if level is not None: \n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                steps = np.arange(1, h + 1)\n",
    "                residuals = y - out[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "                sigmah = sigma * np.sqrt(steps)\n",
    "                pred_int = _calculate_intervals(out, level, h, sigmah)\n",
    "                res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                residuals = y - out[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\" Apply fitted model to an new/updated series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n,). \n",
    "        h: int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like\n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = self.forecast(y=y, h=h, X=X, X_future=X_future, level=level, fitted=fitted)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - forecast\n",
    "naive = Naive()\n",
    "naive.forecast(ap, 12)\n",
    "naive.forecast(ap, 12, None, None, (80,95), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - fit & predict\n",
    "naive.fit(ap)\n",
    "naive.predict(12)\n",
    "naive.predict(12, None, (80,95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "naive = Naive()\n",
    "test_class(naive, x=ap, h=12, level=[90, 80])\n",
    "naive.fit(ap)\n",
    "fcst_naive = naive.predict(12)\n",
    "test_close(fcst_naive['mean'], np.repeat(ap[-1], 12), eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "naive = Naive()\n",
    "fcst_naive = naive.forecast(ap,12,None,None,(80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_naive['lo-80'],\n",
    "    np.array([388.7984, 370.9037, 357.1726, 345.5967, 335.3982, 326.1781, 317.6992, 309.8073, 302.3951, 295.3845, 288.7164, 282.3452]),\n",
    "    decimal=4\n",
    ") # this is almost equal since Hyndman's forecasts are rounded up to 4 decimals\n",
    "_plot_insample_pi(fcst_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Unit test forward:=forecast\n",
    "naive = Naive()\n",
    "fcst_naive = naive.forward(ap,12,None,None,(80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_naive['lo-80'],\n",
    "    np.array([388.7984, 370.9037, 357.1726, 345.5967, 335.3982, 326.1781, 317.6992, 309.8073, 302.3951, 295.3845, 288.7164, 282.3452]),\n",
    "    decimal=4\n",
    ") # this is almost equal since Hyndman's forecasts are rounded up to 4 decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "naive_c = Naive(prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(naive_c, x=ap, h=13, level=[90, 80], test_forward=False)\n",
    "fcst_naive_c = naive_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_naive_c['mean'][:12],\n",
    "    fcst_naive['mean']\n",
    ")\n",
    "_plot_fcst(fcst_naive_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(Naive()),\n",
    "    'Naive'\n",
    ")\n",
    "test_eq(\n",
    "    repr(Naive(alias='Naive_custom')),\n",
    "    'Naive_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Naive.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import Naive\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive's usage example\n",
    "model = Naive()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomWalkWithDrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _random_walk_with_drift(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    ") -> Dict[str, np.ndarray]: \n",
    "    slope = (y[-1] - y[0]) / (y.size - 1)\n",
    "    mean = slope * (1 + np.arange(h, dtype=y.dtype)) + y[-1]\n",
    "    fcst = {'mean': mean,\n",
    "            'slope': np.array([slope], dtype=y.dtype),\n",
    "            'last_y': np.array([y[-1]], dtype=y.dtype)}\n",
    "    if fitted:\n",
    "        fitted_vals = np.full_like(y, np.nan)\n",
    "        fitted_vals[1:] = slope + y[:-1]\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RandomWalkWithDrift(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'RWD', prediction_intervals: Optional[ConformalIntervals] = None):\n",
    "        r\"\"\"RandomWalkWithDrift model.\n",
    "\n",
    "        A variation of the naive method allows the forecasts to change over time. \n",
    "        The amout of change, called drift, is the average change seen in the historical data. \n",
    "\n",
    "        $$\\hat{y}_{t+1} = y_t+\\frac{1}{t-1}\\sum_{j=1}^t (y_j-y_{j-1}) = y_t+ \\frac{y_t-y_1}{t-1}$$\n",
    "\n",
    "        From the previous equation, we can see that this is equivalent to extrapolating a line between \n",
    "        the first and the last observation. \n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alias : str \n",
    "            Custom name of the model.\n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            By default, the model will compute the native prediction\n",
    "            intervals.\n",
    "        \"\"\"\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the RandomWalkWithDrift model.\n",
    "\n",
    "        Fit an RandomWalkWithDrift to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y: numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            RandomWalkWithDrift fitted model.\n",
    "        r\"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _random_walk_with_drift(y, h=1, fitted=True)\n",
    "        mod = dict(mod) \n",
    "        residuals = y - mod['fitted']\n",
    "        sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "        mod['sigma'] = sigma\n",
    "        mod['n'] = len(y)\n",
    "        self.model_ = mod\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int, \n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted RandomWalkWithDrift.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        hrange = np.arange(h, dtype=self.model_['last_y'].dtype)\n",
    "        mean = self.model_['slope'] * (1 + hrange) + self.model_['last_y']\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            steps = np.arange(1, h + 1)\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(steps * (1 + steps / (self.model_['n'] - 1)))\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted RandomWalkWithDrift insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient RandomWalkWithDrift predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (n,). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts: dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        out = _random_walk_with_drift(y=y, h=h, fitted=fitted or (level is not None))\n",
    "        res = {'mean': out['mean']}\n",
    "        \n",
    "        if fitted:\n",
    "            res['fitted'] = out['fitted']\n",
    "        \n",
    "        if level is not None: \n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                steps = np.arange(1, h + 1)\n",
    "                residuals = y - out[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "                sigmah = sigma * np.sqrt(steps * (1 + steps / (len(y) - 1)))\n",
    "                pred_int = _calculate_intervals(out, level, h, sigmah)\n",
    "                res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                residuals = y - out[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - forecast\n",
    "rwd = RandomWalkWithDrift()\n",
    "rwd.forecast(ap, 12)\n",
    "rwd.forecast(ap, 12, None, None, (80,95), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - fit & predict \n",
    "rwd = RandomWalkWithDrift()\n",
    "rwd.fit(ap)\n",
    "rwd.predict(12)\n",
    "rwd.predict(12, None, (80,95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "rwd = RandomWalkWithDrift()\n",
    "test_class(rwd, x=ap, h=12, level=[90, 80])\n",
    "rwd = rwd.fit(ap)\n",
    "fcst_rwd = rwd.predict(12)\n",
    "test_close(fcst_rwd['mean'][:2], np.array([434.2378, 436.4755]), eps=1e-4)\n",
    "np.testing.assert_almost_equal(\n",
    "    rwd.predict_in_sample()['fitted'][:3], \n",
    "    np.array([np.nan, 118 - 3.7622378, 132 - 11.7622378]),\n",
    "    decimal=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "rwd_c = RandomWalkWithDrift(prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(rwd_c, x=ap, h=13, level=[90, 80], test_forward=False)\n",
    "fcst_rwd_c = rwd_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_rwd_c['mean'][:12],\n",
    "    fcst_rwd['mean']\n",
    ")\n",
    "_plot_fcst(fcst_rwd_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "rwd = RandomWalkWithDrift()\n",
    "fcst_rwd = rwd.forecast(ap,12,None,None,(80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_rwd['lo-80'],\n",
    "    np.array([390.9799, 375.0862, 363.2664, 353.5325, 345.1178, 337.6304, 330.8384, 324.5916, 318.7857, 313.3453, 308.2136, 303.3469]),\n",
    "    decimal=1\n",
    ")\n",
    "_plot_insample_pi(fcst_rwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(RandomWalkWithDrift()),\n",
    "    'RWD'\n",
    ")\n",
    "test_eq(\n",
    "    repr(RandomWalkWithDrift(alias='RWD_custom')),\n",
    "    'RWD_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomWalkWithDrift.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import RandomWalkWithDrift\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomWalkWithDrift's usage example\n",
    "model = RandomWalkWithDrift()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeasonalNaive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeasonalNaive(_TS):\n",
    "    \n",
    "    def __init__(self, season_length: int, alias: str = 'SeasonalNaive', prediction_intervals: Optional[ConformalIntervals] = None):\n",
    "        r\"\"\"Seasonal naive model.\n",
    "\n",
    "        A method similar to the naive, but uses the last known observation of the same period (e.g. the same month of the previous year) in order to capture seasonal variations.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html#seasonal-na%C3%AFve-method).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        season_length : int\n",
    "            Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "        alias : str\n",
    "            Custom name of the model.\n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            By default, the model will compute the native prediction\n",
    "            intervals.\n",
    "        \"\"\"\n",
    "        self.season_length = season_length\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the SeasonalNaive model.\n",
    "\n",
    "        Fit an SeasonalNaive to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X: array-like\n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            SeasonalNaive fitted model.\n",
    "        r\"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _seasonal_naive(\n",
    "            y=y, \n",
    "            season_length=self.season_length, \n",
    "            h=self.season_length, \n",
    "            fitted=True,\n",
    "        )\n",
    "        mod = dict(mod) \n",
    "        residuals = y - mod['fitted']\n",
    "        mod['sigma'] = _calculate_sigma(residuals, \n",
    "                                        len(y) - self.season_length)\n",
    "        self.model_ = mod\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,  \n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None, \n",
    "    ):\n",
    "        r\"\"\"Predict with fitted Naive.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X: array-like\n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level: List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val_seas(season_vals=self.model_['mean'], h=h)\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)            \n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            k = np.floor((h - 1) / self.season_length)\n",
    "            sigma = self.model_['sigma']\n",
    "            sigmah = sigma * np.sqrt(k + 1)\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        return res\n",
    "        \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted SeasonalNaive insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        r\"\"\"        \n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    " \n",
    "    \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient SeasonalNaive predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like\n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        out = _seasonal_naive(\n",
    "            y=y, h=h, fitted=fitted or (level is not None), \n",
    "            season_length=self.season_length\n",
    "        )\n",
    "        res = {'mean': out['mean']}\n",
    "        if fitted:\n",
    "            res['fitted'] = out['fitted']\n",
    "        if level is not None: \n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                k = np.floor((h - 1) / self.season_length)\n",
    "                residuals = y - out[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, len(y) - self.season_length)\n",
    "                sigmah = sigma * np.sqrt(k + 1)\n",
    "                pred_int = _calculate_intervals(out, level, h, sigmah)\n",
    "                res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                k = np.floor((h - 1) / self.season_length)\n",
    "                residuals = y - out[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, len(y) - self.season_length)\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - forecast\n",
    "seas_naive = SeasonalNaive(season_length=12)\n",
    "seas_naive.forecast(ap, 12)\n",
    "seas_naive.forecast(ap, 12, None, None, (80,95), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Test prediction intervals - fit and predict \n",
    "seas_naive = SeasonalNaive(season_length=12)\n",
    "seas_naive.fit(ap)\n",
    "seas_naive.predict(12)\n",
    "seas_naive.predict(12, None, (80,95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "seas_naive = SeasonalNaive(season_length=12)\n",
    "test_class(seas_naive, x=ap, h=12, level=[90, 80])\n",
    "seas_naive = seas_naive.fit(ap)\n",
    "fcst_seas_naive = seas_naive.predict(12)\n",
    "test_eq(seas_naive.predict_in_sample()['fitted'][-3:], np.array([461 - 54., 390 - 28., 432 - 27.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "seas_naive = SeasonalNaive(season_length=12)\n",
    "fcst_seas_naive = seas_naive.forecast(ap, 12, None, None, (80,95), True)\n",
    "np.testing.assert_almost_equal(\n",
    "    fcst_seas_naive['lo-80'],\n",
    "    np.array([370.4595, 344.4595, 372.4595, 414.4595, 425.4595, 488.4595, \n",
    "              575.4595, 559.4595, 461.4595, 414.4595, 343.4595, 385.4595]),\n",
    "    decimal=4\n",
    ")\n",
    "_plot_insample_pi(fcst_seas_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "seas_naive_c = SeasonalNaive(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(seas_naive_c, x=ap, h=13, level=[90, 80], test_forward=False)\n",
    "fcst_seas_naive_c = seas_naive_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_seas_naive_c['mean'][:12],\n",
    "    fcst_seas_naive['mean']\n",
    ")\n",
    "_plot_fcst(fcst_seas_naive_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SeasonalNaive(12)),\n",
    "    'SeasonalNaive'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SeasonalNaive(12, alias='SeasonalNaive_custom')),\n",
    "    'SeasonalNaive_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalNaive.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import SeasonalNaive\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeasonalNaive's usage example\n",
    "model = SeasonalNaive(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WindowAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _window_average(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    "    window_size: int, # window size\n",
    ") -> Dict[str, np.ndarray]: \n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    if y.size < window_size:\n",
    "        return {'mean': np.full(h, np.nan, dtype=y.dtype)}\n",
    "    wavg = y[-window_size:].mean()\n",
    "    mean = _repeat_val(val=wavg, h=h)\n",
    "    return {'mean': mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class WindowAverage(_TS):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            window_size: int,\n",
    "            alias: str = 'WindowAverage',\n",
    "            prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "        ):\n",
    "        r\"\"\"WindowAverage model.\n",
    "\n",
    "        Uses the average of the last $k$ observations, with $k$ the length of the window.\n",
    "        Wider windows will capture global trends, while narrow windows will reveal local trends.\n",
    "        The length of the window selected should take into account the importance of past\n",
    "        observations and how fast the series changes.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        window_size : int \n",
    "            Size of truncated series on which average is estimated.\n",
    "        alias : str \n",
    "            Custom name of the model. \n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            This is required for generating future prediction intervals.\n",
    "        r\"\"\"        \n",
    "        self.window_size = window_size\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the WindowAverage model.\n",
    "\n",
    "        Fit an WindowAverage to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like\n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            WindowAverage fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _window_average(y=y, h=1, window_size=self.window_size, fitted=False)\n",
    "        self.model_ = dict(mod)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self, \n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted WindowAverage.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : numpy.array\n",
    "            Optional exogenous of shape (h, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        r\"\"\"Access fitted WindowAverage insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient WindowAverage predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x).\n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _window_average(y=y, h=h, fitted=fitted, window_size=self.window_size)\n",
    "        res = dict(res)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "w_avg = WindowAverage(window_size=24)\n",
    "test_class(w_avg, x=ap, h=12, skip_insample=True)\n",
    "w_avg = w_avg.fit(ap)\n",
    "fcst_w_avg = w_avg.predict(12)\n",
    "test_close(fcst_w_avg['mean'], np.repeat(ap[-24:].mean(), 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "w_avg_c = WindowAverage(window_size=24, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(w_avg_c, x=ap, h=13, level=[90, 80], test_forward=False, skip_insample=True)\n",
    "fcst_w_avg_c = w_avg_c.forecast(ap, 13, None, None, (80,95), False)\n",
    "test_eq(\n",
    "    fcst_w_avg_c['mean'][:12],\n",
    "    fcst_w_avg['mean']\n",
    ")\n",
    "_plot_fcst(fcst_w_avg_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(WindowAverage(1)),\n",
    "    'WindowAverage'\n",
    ")\n",
    "test_eq(\n",
    "    repr(WindowAverage(1, alias='WindowAverage_custom')),\n",
    "    'WindowAverage_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(WindowAverage.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import WindowAverage\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WindowAverage's usage example\n",
    "model = WindowAverage(window_size=12*4)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeasonalWindowAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _seasonal_window_average(\n",
    "    y: np.ndarray,\n",
    "    h: int,\n",
    "    fitted: bool,\n",
    "    season_length: int,\n",
    "    window_size: int,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    if fitted:\n",
    "        raise NotImplementedError('return fitted')\n",
    "    min_samples = season_length * window_size\n",
    "    if y.size < min_samples:\n",
    "        return {'mean': np.full(h, np.nan, dtype=y.dtype)}\n",
    "    season_avgs = y[-min_samples:].reshape(window_size, season_length).mean(axis=0)\n",
    "    out = _repeat_val_seas(season_vals=season_avgs, h=h)\n",
    "    return {'mean': out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SeasonalWindowAverage(_TS):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int,\n",
    "        window_size: int,\n",
    "        alias: str = 'SeasWA',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None\n",
    "    ):\n",
    "        r\"\"\"SeasonalWindowAverage model.\n",
    "\n",
    "        An average of the last $k$ observations of the same period, with $k$ the length of the window.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Rob J. Hyndman and George Athanasopoulos (2018). \"forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        window_size : int \n",
    "            Size of truncated series on which average is estimated.\n",
    "        seasonal_length : int \n",
    "            Number of observations per cycle.\n",
    "        alias : str \n",
    "            Custom name of the model. \n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            This is required for generating future prediction intervals.\n",
    "        r\"\"\"        \n",
    "        self.season_length = season_length\n",
    "        self.window_size = window_size\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the SeasonalWindowAverage model.\n",
    "\n",
    "        Fit an SeasonalWindowAverage to a time series (numpy array) `y`\n",
    "        and optionally exogenous variables (numpy array) `X`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like\n",
    "            Optional exogenpus of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            SeasonalWindowAverage fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = _seasonal_window_average(\n",
    "            y=y, \n",
    "            h=self.season_length,\n",
    "            fitted=False,\n",
    "            season_length=self.season_length, \n",
    "            window_size=self.window_size,\n",
    "        )\n",
    "        self.model_ = dict(mod)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted SeasonalWindowAverage.\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional insample exogenous of shape (t, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val_seas(season_vals=self.model_['mean'], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self):\n",
    "        r\"\"\"Access fitted SeasonalWindowAverage insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient SeasonalWindowAverage predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n,). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x).  \n",
    "        level : List[float] \n",
    "            Confidence levels for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "            \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _seasonal_window_average(\n",
    "            y=y, h=h, fitted=fitted, \n",
    "            season_length=self.season_length,\n",
    "            window_size=self.window_size\n",
    "        )\n",
    "        res = dict(res)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "seas_w_avg = SeasonalWindowAverage(season_length=12, window_size=1)\n",
    "test_class(seas_w_avg, x=ap, h=12, skip_insample=True)\n",
    "seas_w_avg = seas_w_avg.fit(ap)\n",
    "fcst_seas_w_avg = seas_w_avg.predict(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "seas_w_avg_c = SeasonalWindowAverage(season_length=12, window_size=1, prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(seas_w_avg_c, x=ap, h=13, level=[90, 80], test_forward=False, skip_insample=True)\n",
    "fcst_seas_w_avg_c = seas_w_avg_c.forecast(ap, 13, None, None, (80,95), False)\n",
    "test_eq(\n",
    "    fcst_seas_w_avg_c['mean'][:12],\n",
    "    fcst_seas_w_avg['mean']\n",
    ")\n",
    "fcst_seas_w_avg_c['mean'][:12]\n",
    "_plot_fcst(fcst_seas_w_avg_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SeasonalWindowAverage(12, 1)),\n",
    "    'SeasWA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SeasonalWindowAverage(12, 1, alias='SeasWA_custom')),\n",
    "    'SeasWA_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SeasonalWindowAverage.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import SeasonalWindowAverage\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeasonalWindowAverage's usage example\n",
    "model = SeasonalWindowAverage(season_length=12, window_size=4)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse or Intermittent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADIDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _chunk_forecast(y, aggregation_level):\n",
    "    lost_remainder_data = len(y) % aggregation_level\n",
    "    y_cut = y[lost_remainder_data:]\n",
    "    aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "    sums_forecast, _ = _optimized_ses_forecast(aggregation_sums)\n",
    "    return sums_forecast\n",
    "\n",
    "@njit(nogil=NOGIL, cache=CACHE)\n",
    "def _expand_fitted_demand(fitted: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    out = np.empty_like(y)\n",
    "    out[0] = np.nan\n",
    "    fitted_idx = 0\n",
    "    for i in range(1, y.size):\n",
    "        if y[i - 1] > 0:\n",
    "            fitted_idx += 1\n",
    "            out[i] = fitted[fitted_idx]\n",
    "        elif fitted_idx > 0:\n",
    "            # if this entry is zero, the model didn't change\n",
    "            out[i] = out[i - 1]\n",
    "        else:\n",
    "            # if we haven't seen any demand, use naive\n",
    "            out[i] = y[i - 1]\n",
    "    return out\n",
    "\n",
    "@njit(nogil=NOGIL, cache=CACHE)\n",
    "def _expand_fitted_intervals(fitted: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    out = np.empty_like(y)\n",
    "    out[0] = np.nan\n",
    "    fitted_idx = 0\n",
    "    for i in range(1, y.size):\n",
    "        if y[i - 1] != 0:\n",
    "            fitted_idx += 1\n",
    "            if fitted[fitted_idx] == 0:\n",
    "                # to avoid division by zero\n",
    "                out[i] = 1\n",
    "            else:\n",
    "                out[i] = fitted[fitted_idx]\n",
    "        elif fitted_idx > 0:\n",
    "            # if this entry is zero, the model didn't change\n",
    "            out[i] = out[i - 1]\n",
    "        else:\n",
    "            # if we haven't seen any intervals, use 1 to avoid division by zero\n",
    "            out[i] = 1\n",
    "    return out\n",
    "    \n",
    "def _adida(\n",
    "        y: np.ndarray, # time series\n",
    "        h: int, # forecasting horizon\n",
    "        fitted: bool, # fitted values\n",
    "    ):\n",
    "    if (y == 0).all():\n",
    "        res = {'mean': np.zeros(h, dtype=y.dtype)}\n",
    "        if fitted:\n",
    "            res['fitted'] = np.zeros_like(y)\n",
    "            res['fitted'][0] = np.nan\n",
    "        return res\n",
    "    y = _ensure_float(y)\n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean()\n",
    "    aggregation_level = round(mean_interval)\n",
    "    sums_forecast = _chunk_forecast(y, aggregation_level)\n",
    "    forecast = sums_forecast / aggregation_level\n",
    "    res = {'mean': _repeat_val(val=forecast, h=h)}\n",
    "    if fitted:\n",
    "        warnings.warn(\"Computing fitted values for ADIDA is very expensive\")\n",
    "        fitted_aggregation_levels = np.round(\n",
    "            y_intervals.cumsum() / np.arange(1, y_intervals.size + 1)\n",
    "        )\n",
    "        fitted_aggregation_levels = _expand_fitted_intervals(\n",
    "            np.append(np.nan, fitted_aggregation_levels), y\n",
    "        )[1:].astype(np.int32)\n",
    "\n",
    "        sums_fitted = np.empty(y.size - 1, dtype=y.dtype)\n",
    "        for i, agg_lvl in enumerate(fitted_aggregation_levels):\n",
    "            sums_fitted[i] = _chunk_forecast(y[:i+1], agg_lvl)\n",
    "\n",
    "        res['fitted'] = np.append(np.nan, sums_fitted / fitted_aggregation_levels)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ADIDA(_TS):\n",
    "\n",
    "    def __init__(self, alias: str = 'ADIDA', prediction_intervals: Optional[ConformalIntervals] = None):\n",
    "        r\"\"\"ADIDA model.\n",
    "\n",
    "        Aggregate-Dissagregate Intermittent Demand Approach: Uses temporal aggregation to reduce the \n",
    "        number of zero observations. Once the data has been agregated, it uses the optimized SES to \n",
    "        generate the forecasts at the new level. It then breaks down the forecast to the original \n",
    "        level using equal weights.\n",
    "\n",
    "        ADIDA specializes on sparse or intermittent series are series with very few non-zero observations. \n",
    "        They are notoriously hard to forecast, and so, different methods have been developed \n",
    "        especifically for them.\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        [Nikolopoulos, K., Syntetos, A. A., Boylan, J. E., Petropoulos, F., & Assimakopoulos, V. (2011). An aggregate–disaggregate intermittent demand approach (ADIDA) to forecasting: an empirical proposition and analysis. Journal of the Operational Research Society, 62(3), 544-554.](https://researchportal.bath.ac.uk/en/publications/an-aggregate-disaggregate-intermittent-demand-approach-adida-to-f).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alias : str \n",
    "            Custom name of the model. \n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            By default, the model will compute the native prediction\n",
    "            intervals.\n",
    "        r\"\"\"        \n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the ADIDA model.\n",
    "\n",
    "        Fit an ADIDA to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            ADIDA fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = _adida(y=y, h=1, fitted=False)\n",
    "        self._y = y\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted ADIDA.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional exogenous of shape (h, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"        \n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate the class with `prediction_intervals`\"\n",
    "                \"to calculate them\"\n",
    "            )\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted ADIDA insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fitted = _adida(y=self._y, h=1, fitted=True)['fitted']\n",
    "        res = {'fitted': fitted}\n",
    "        if level is not None:\n",
    "            sigma = _calculate_sigma(self._y - fitted, self._y.size)            \n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient ADIDA predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n,). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _adida(y=y, h=h, fitted=fitted)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate the class with `prediction_intervals`\"\n",
    "                \"to calculate them\"\n",
    "            )\n",
    "        if fitted:\n",
    "            sigma = _calculate_sigma(y - res['fitted'], y.size)\n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "deg_ts = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "adida = ADIDA()\n",
    "test_class(adida, x=ap, h=12, skip_insample=False)\n",
    "test_class(adida, x=deg_ts, h=12, skip_insample=False)\n",
    "fcst_adida = adida.forecast(ap, 12)\n",
    "\n",
    "_test_fitted_sparse(ADIDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "adida_c = ADIDA(prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(adida_c, x=ap, h=13, level=[90, 80], skip_insample=False)\n",
    "fcst_adida_c = adida_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_adida_c['mean'][:12],\n",
    "    fcst_adida['mean'],\n",
    ")\n",
    "_plot_insample_pi(fcst_adida_c)\n",
    "_plot_fcst(fcst_adida_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(ADIDA()),\n",
    "    'ADIDA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(ADIDA(alias='ADIDA_custom')),\n",
    "    'ADIDA_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ADIDA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import ADIDA\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADIDA's usage example\n",
    "model = ADIDA()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrostonClassic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _croston_classic(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    "): \n",
    "    y = _ensure_float(y)\n",
    "    # demand\n",
    "    yd = _demand(y)\n",
    "    if not yd.size: #no demand\n",
    "        return _naive(y=y, h=h, fitted=fitted)    \n",
    "    ydp, ydf = _ses_forecast(yd, 0.1)\n",
    "\n",
    "    # intervals\n",
    "    yi = _intervals(y)\n",
    "    yip, yif = _ses_forecast(yi, 0.1)\n",
    "\n",
    "    if yip != 0.0:\n",
    "        mean = ydp / yip\n",
    "    else:\n",
    "        mean = ydp\n",
    "    out = {'mean': _repeat_val(val=mean, h=h)}\n",
    "    if fitted:\n",
    "        ydf = _expand_fitted_demand(np.append(ydf, ydp), y)\n",
    "        yif = _expand_fitted_intervals(np.append(yif, yip), y)        \n",
    "        out['fitted'] = ydf / yif\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrostonClassic(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'CrostonClassic', prediction_intervals: Optional[ConformalIntervals] = None):\n",
    "        r\"\"\"CrostonClassic model.\n",
    "\n",
    "        A method to forecast time series that exhibit intermittent demand.\n",
    "        It decomposes the original time series into a non-zero demand size $z_t$ and \n",
    "        inter-demand intervals $p_t$. Then the forecast is given by:\n",
    "        $$\\hat{y}_t = \\frac{\\hat{z}_t}{\\hat{p}_t}$$ \n",
    "\n",
    "        where $\\hat{z}_t$ and $\\hat{p}_t$ are forecasted using SES. The smoothing parameter \n",
    "        of both components is set equal to 0.1\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.](https://link.springer.com/article/10.1057/jors.1972.50)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alias : str \n",
    "            Custom name of the model.\n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            By default, the model will compute the native prediction\n",
    "            intervals.\n",
    "        \"\"\"        \n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the CrostonClassic model.\n",
    "\n",
    "        Fit an CrostonClassic to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            CrostonClassic fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = _croston_classic(y=y, h=1, fitted=True)\n",
    "        self.model_['sigma'] = _calculate_sigma(y - self.model_['fitted'], y.size)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted CrostonClassic.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional exogenous of shape (h, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate the class with `prediction_intervals` to calculate them\"\n",
    "            )\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted CrostonClassic insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level: List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "        \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient CrostonClassic predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _croston_classic(y=y, h=h, fitted=fitted)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=dict(res), y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate the class with `prediction_intervals` to calculate them\"\n",
    "            )\n",
    "        if fitted:\n",
    "            sigma = _calculate_sigma(y - res['fitted'], y.size)\n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "croston = CrostonClassic(prediction_intervals=ConformalIntervals(2, 1))\n",
    "test_class(croston, x=ap, h=12, skip_insample=False, level=[80])\n",
    "test_class(croston, x=deg_ts, h=12, skip_insample=False, level=[80])\n",
    "fcst_croston = croston.forecast(ap, 12)\n",
    "\n",
    "_test_fitted_sparse(CrostonClassic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "croston_c = CrostonClassic(prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(croston_c, x=ap, h=13, level=[90.0, 80.0], skip_insample=False)\n",
    "fcst_croston_c = croston_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_croston_c['mean'][:12],\n",
    "    fcst_croston['mean'],\n",
    ")\n",
    "_plot_insample_pi(fcst_croston_c)\n",
    "_plot_fcst(fcst_croston_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(CrostonClassic()),\n",
    "    'CrostonClassic'\n",
    ")\n",
    "test_eq(\n",
    "    repr(CrostonClassic(alias='CrostonClassic_custom')),\n",
    "    'CrostonClassic_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonClassic.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import CrostonClassic\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrostonClassic's usage example\n",
    "model = CrostonClassic()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrostonOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _croston_optimized(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    "):\n",
    "    y = _ensure_float(y)\n",
    "    # demand\n",
    "    yd = _demand(y)\n",
    "    if not yd.size:\n",
    "        return _naive(y=y, h=h, fitted=fitted)\n",
    "    ydp, _ = _optimized_ses_forecast(yd)\n",
    "\n",
    "    # intervals\n",
    "    yi = _intervals(y)\n",
    "    yip, _ = _optimized_ses_forecast(yi)\n",
    "\n",
    "    if yip != 0.0:\n",
    "        mean = ydp / yip\n",
    "    else:\n",
    "        mean = ydp\n",
    "    out = {'mean': _repeat_val(val=mean, h=h)}\n",
    "    if fitted:\n",
    "        warnings.warn(\"Computing fitted values for CrostonOptimized is very expensive\")\n",
    "        ydf = np.empty(yd.size + 1, dtype=y.dtype)\n",
    "        ydf[0] = np.nan\n",
    "        for i in range(yd.size):\n",
    "            ydf[i + 1] = _optimized_ses_forecast(yd[:i + 1])[0]\n",
    "\n",
    "        yif = np.empty(yi.size + 1, dtype=y.dtype)\n",
    "        yif[0] = np.nan\n",
    "        for i in range(yi.size):\n",
    "            yiff = _optimized_ses_forecast(yi[:i + 1])[0]\n",
    "            if yiff == 0:\n",
    "                yiff = 1.0\n",
    "            yif[i + 1] = yiff\n",
    "\n",
    "        ydf = _expand_fitted_demand(ydf, y)\n",
    "        yif = _expand_fitted_intervals(yif, y)\n",
    "        out['fitted'] = ydf / yif\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrostonOptimized(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'CrostonOptimized', prediction_intervals: Optional[ConformalIntervals] = None,):\n",
    "        r\"\"\"CrostonOptimized model.\n",
    "\n",
    "        A method to forecast time series that exhibit intermittent demand.\n",
    "        It decomposes the original time series into a non-zero demand size $z_t$ and \n",
    "        inter-demand intervals $p_t$. Then the forecast is given by:\n",
    "        $$\\hat{y}_t = \\frac{\\hat{z}_t}{\\hat{p}_t}$$\n",
    "\n",
    "        A variation of the classic Croston's method where the smooting paramater is optimally \n",
    "        selected from the range $[0.1,0.3]$. Both the non-zero demand $z_t$ and the inter-demand \n",
    "        intervals $p_t$ are smoothed separately, so their smoothing parameters can be different.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.](https://link.springer.com/article/10.1057/jors.1972.50).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alias : str \n",
    "            Custom name of the model.\n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            This is required for generating future prediction intervals.\n",
    "        r\"\"\"        \n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the CrostonOptimized model.\n",
    "\n",
    "        Fit an CrostonOptimized to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            CrostonOptimized fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = _croston_optimized(y=y, h=1, fitted=False)\n",
    "        self._y = y\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted CrostonOptimized.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional insample exogenous of shape (t, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted CrostonOptimized insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fitted = _croston_optimized(y=self._y, h=1, fitted=True)['fitted']\n",
    "        res = {'fitted': fitted}\n",
    "        if level is not None:\n",
    "            sigma = _calculate_sigma(self._y - fitted, self._y.size)            \n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient CrostonOptimized predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _croston_optimized(y=y, h=h, fitted=fitted)\n",
    "        res = dict(res)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        if fitted:\n",
    "            sigma = _calculate_sigma(y - res['fitted'], y.size)\n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "croston_op = CrostonOptimized(prediction_intervals=ConformalIntervals(2, 1))\n",
    "test_class(croston_op, x=ap, h=12, skip_insample=False, level=[80])\n",
    "test_class(croston_op, x=deg_ts, h=12, skip_insample=False, level=[80])\n",
    "fcst_croston_op = croston_op.forecast(ap, 12)\n",
    "\n",
    "_test_fitted_sparse(CrostonOptimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "croston_op_c = CrostonOptimized(prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(croston_op_c, x=ap, h=13, level=[90, 80], skip_insample=False)\n",
    "fcst_croston_op_c = croston_op_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_croston_op_c['mean'][:12],\n",
    "    fcst_croston_op['mean'],\n",
    ")\n",
    "_plot_insample_pi(fcst_croston_op_c)\n",
    "_plot_fcst(fcst_croston_op_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(CrostonOptimized()),\n",
    "    'CrostonOptimized'\n",
    ")\n",
    "test_eq(\n",
    "    repr(CrostonOptimized(alias='CrostonOptimized_custom')),\n",
    "    'CrostonOptimized_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonOptimized.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import CrostonOptimized\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrostonOptimized's usage example\n",
    "model = CrostonOptimized()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrostonSBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _croston_sba(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool,  # fitted values\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    out = _croston_classic(y=y, h=h, fitted=fitted)\n",
    "    out['mean'] *= 0.95    \n",
    "    if fitted:\n",
    "        out['fitted'] *= 0.95\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrostonSBA(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'CrostonSBA', prediction_intervals: Optional[ConformalIntervals] = None,):\n",
    "        r\"\"\"CrostonSBA model.\n",
    "\n",
    "        A method to forecast time series that exhibit intermittent demand.\n",
    "        It decomposes the original time series into a non-zero demand size $z_t$ and \n",
    "        inter-demand intervals $p_t$. Then the forecast is given by:\n",
    "        $$\\hat{y}_t = \\frac{\\hat{z}_t}{\\hat{p}_t}$$\n",
    "\n",
    "        A variation of the classic Croston's method that uses a debiasing factor, so that the \n",
    "        forecast is given by:\n",
    "        $$\\hat{y}_t = 0.95  \\frac{\\hat{z}_t}{\\hat{p}_t}$$\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Croston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.](https://link.springer.com/article/10.1057/jors.1972.50).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alias : str \n",
    "            Custom name of the model.\n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            By default, the model will compute the native prediction\n",
    "            intervals.\n",
    "        r\"\"\"        \n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the CrostonSBA model.\n",
    "\n",
    "        Fit an CrostonSBA to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            CrostonSBA fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = _croston_sba(y=y, h=1, fitted=True)\n",
    "        self.model_['sigma'] = _calculate_sigma(y - self.model_['fitted'], y.size)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted CrostonSBA.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional exogenous of shape (h, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate the class with `prediction_intervals` to calculate them\"\n",
    "            )\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted CrostonSBA insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level: List[float]\n",
    "            Confidence levels (0-100) prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "        \n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient CrostonSBA predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _croston_sba(y=y, h=h, fitted=fitted)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=dict(res), y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate the class with `prediction_intervals`\"\n",
    "                \"to calculate them\"\n",
    "            )\n",
    "        if fitted:\n",
    "            sigma = _calculate_sigma(y - res['fitted'], y.size)\n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "croston_sba = CrostonSBA(prediction_intervals=ConformalIntervals(2, 1))\n",
    "test_class(croston_sba, x=ap, h=12, skip_insample=False, level=[80])\n",
    "test_class(croston_sba, x=deg_ts, h=12, skip_insample=False, level=[80])\n",
    "fcst_croston_sba = croston_sba.forecast(ap, 12)\n",
    "\n",
    "_test_fitted_sparse(CrostonSBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "croston_sba_c = CrostonSBA(prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(croston_sba_c, x=ap, h=13, level=[90, 80], skip_insample=False)\n",
    "fcst_croston_sba_c = croston_sba_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_croston_sba_c['mean'][:12],\n",
    "    fcst_croston_sba['mean'],\n",
    ")\n",
    "_plot_insample_pi(fcst_croston_sba_c)\n",
    "_plot_fcst(fcst_croston_sba_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(CrostonSBA()),\n",
    "    'CrostonSBA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(CrostonSBA(alias='CrostonSBA_custom')),\n",
    "    'CrostonSBA_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CrostonSBA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import CrostonSBA\n",
    "from statsforecast.utils import AirPassengers as ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrostonSBA's usage example\n",
    "model = CrostonSBA()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _imapa(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    "):\n",
    "    if (y == 0).all():\n",
    "        res = {'mean': np.zeros(h, dtype=y.dtype)}\n",
    "        if fitted:\n",
    "            res['fitted'] = np.zeros_like(y)\n",
    "            res['fitted'][0] = np.nan\n",
    "        return res\n",
    "    y = _ensure_float(y)        \n",
    "    y_intervals = _intervals(y)\n",
    "    mean_interval = y_intervals.mean().item()\n",
    "    max_aggregation_level = round(mean_interval)\n",
    "    forecasts = np.empty(max_aggregation_level, dtype=y.dtype)\n",
    "    for aggregation_level in range(1, max_aggregation_level + 1):\n",
    "        lost_remainder_data = len(y) % aggregation_level\n",
    "        y_cut = y[lost_remainder_data:]\n",
    "        aggregation_sums = _chunk_sums(y_cut, aggregation_level)\n",
    "        forecast, _ = _optimized_ses_forecast(aggregation_sums)\n",
    "        forecasts[aggregation_level - 1] = forecast / aggregation_level\n",
    "    forecast = forecasts.mean()\n",
    "    res = {'mean': _repeat_val(val=forecast, h=h)}\n",
    "    if fitted:\n",
    "        warnings.warn(\"Computing fitted values for IMAPA is very expensive.\")\n",
    "        fitted_vals = np.empty_like(y)\n",
    "        fitted_vals[0] = np.nan\n",
    "        for i in range(y.size - 1):\n",
    "            fitted_vals[i + 1] = _imapa(y[:i+1], h=1, fitted=False)['mean'].item()\n",
    "        res['fitted'] = fitted_vals\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IMAPA(_TS):\n",
    "    \n",
    "    def __init__(self, alias: str = 'IMAPA', prediction_intervals: Optional[ConformalIntervals] = None,):\n",
    "        r\"\"\"IMAPA model.\n",
    "\n",
    "        Intermittent Multiple Aggregation Prediction Algorithm: Similar to ADIDA, but instead of\n",
    "        using a single aggregation level, it considers multiple in order to capture different\n",
    "        dynamics of the data. Uses the optimized SES to generate the forecasts at the new levels\n",
    "        and then combines them using a simple average.\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        [Syntetos, A. A., & Boylan, J. E. (2021). Intermittent demand forecasting: Context, methods and applications. John Wiley & Sons.](https://www.ifors.org/intermittent-demand-forecasting-context-methods-and-applications/).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alias : str \n",
    "            Custom name of the model. \n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            By default, the model will compute the native prediction\n",
    "            intervals.\n",
    "        \"\"\"\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the IMAPA model.\n",
    "\n",
    "        Fit an IMAPA to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            IMAPA fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = _imapa(y=y, h=1, fitted=False)\n",
    "        self._y = y\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted IMAPA.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        X : array-like\n",
    "            Optional exogenous of shape (h, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        \"\"\"\n",
    "        mean = _repeat_val(val=self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate the class with `prediction_intervals`\"\n",
    "                \"to calculate them\"\n",
    "            )\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted IMAPA insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fitted = _imapa(y=self._y, h=1, fitted=True)['fitted']\n",
    "        res = {'fitted': fitted}\n",
    "        if level is not None:\n",
    "            sigma = _calculate_sigma(self._y - fitted, self._y.size)\n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res\n",
    "        \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient IMAPA predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (n, ). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _imapa(y=y, h=h, fitted=fitted)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate the class with `prediction_intervals`\"\n",
    "                \"to calculate them\"\n",
    "            )\n",
    "        if fitted:\n",
    "            sigma = _calculate_sigma(y - res['fitted'], y.size)\n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "imapa = IMAPA(prediction_intervals=ConformalIntervals(2, 1))\n",
    "test_class(imapa, x=ap, h=12, skip_insample=False, level=[80])\n",
    "test_class(imapa, x=deg_ts, h=12, skip_insample=False, level=[80])\n",
    "fcst_imapa = imapa.forecast(ap, 12)\n",
    "\n",
    "_test_fitted_sparse(IMAPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "imapa_c = IMAPA(prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(imapa_c, x=ap, h=13, level=[90, 80], skip_insample=False)\n",
    "fcst_imapa_c = imapa_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_imapa_c['mean'][:12],\n",
    "    fcst_imapa['mean'],\n",
    ")\n",
    "_plot_insample_pi(fcst_imapa_c)\n",
    "_plot_fcst(fcst_imapa_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(IMAPA()),\n",
    "    'IMAPA'\n",
    ")\n",
    "test_eq(\n",
    "    repr(IMAPA(alias='IMAPA_custom')),\n",
    "    'IMAPA_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(IMAPA.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import IMAPA\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAPA's usage example\n",
    "model = IMAPA()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _tsb(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: int, # fitted values\n",
    "    alpha_d: float,\n",
    "    alpha_p: float,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    if (y == 0).all():\n",
    "        res = {'mean': np.zeros(h, dtype=y.dtype)}\n",
    "        if fitted:\n",
    "            res['fitted'] = np.zeros_like(y)\n",
    "            res['fitted'][0] = np.nan\n",
    "        return res\n",
    "    y = _ensure_float(y)\n",
    "    yd = _demand(y)\n",
    "    yp = _probability(y)\n",
    "    ypf, ypft = _ses_forecast(yp, alpha_p)\n",
    "    ydf, ydft = _ses_forecast(yd, alpha_d)\n",
    "    res = {'mean': _repeat_val(val=ypf * ydf, h=h)}\n",
    "    if fitted:\n",
    "        ydft = _expand_fitted_demand(np.append(ydft, ydf), y)\n",
    "        res['fitted'] = ypft * ydft\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TSB(_TS):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha_d: float,\n",
    "        alpha_p: float,\n",
    "        alias: str = 'TSB',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        r\"\"\"TSB model.\n",
    "\n",
    "        Teunter-Syntetos-Babai: A modification of Croston's method that replaces the inter-demand\n",
    "        intervals with the demand probability $d_t$, which is defined as follows.\n",
    "\n",
    "        $$\n",
    "        d_t = \\begin{cases}\n",
    "            1  & \\text{if demand occurs at time t} \\\\\n",
    "            0  & \\text{otherwise.}\n",
    "        \\end{cases}\n",
    "        $$\n",
    "\n",
    "        Hence, the forecast is given by\n",
    "\n",
    "        $$\\hat{y}_t= \\hat{d}_t\\hat{z_t}$$\n",
    "\n",
    "        Both $d_t$ and $z_t$ are forecasted using SES. The smooting paramaters of each may differ,\n",
    "        like in the optimized Croston's method.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [Teunter, R. H., Syntetos, A. A., & Babai, M. Z. (2011). Intermittent demand: Linking forecasting to inventory obsolescence. European Journal of Operational Research, 214(3), 606-615.](https://www.sciencedirect.com/science/article/abs/pii/S0377221711004437)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha_d : float\n",
    "            Smoothing parameter for demand.\n",
    "        alpha_p : float\n",
    "            Smoothing parameter for probability.\n",
    "        alias : str\n",
    "            Custom name of the model.\n",
    "        prediction_intervals : Optional[ConformalIntervals]\n",
    "            Information to compute conformal prediction intervals.\n",
    "            This is required for generating future prediction intervals.\n",
    "        \"\"\"\n",
    "        self.alpha_d = alpha_d\n",
    "        self.alpha_p = alpha_p\n",
    "        self.alias = alias\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.only_conformal_intervals = True\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the TSB model.\n",
    "\n",
    "        Fit an TSB to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            TSB fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = _tsb(\n",
    "            y=y,\n",
    "            h=1, \n",
    "            fitted=True, \n",
    "            alpha_d=self.alpha_d, \n",
    "            alpha_p=self.alpha_p\n",
    "        )\n",
    "        self.model_['sigma'] = _calculate_sigma(y - self.model_['fitted'], y.size)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted TSB.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"        \n",
    "        mean = _repeat_val(self.model_['mean'][0], h=h)\n",
    "        res = {'mean': mean}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted TSB insample predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "        \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient TSB predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        res = _tsb(\n",
    "            y=y, h=h, \n",
    "            fitted=fitted, \n",
    "            alpha_d=self.alpha_d, \n",
    "            alpha_p=self.alpha_p\n",
    "        )\n",
    "        res = dict(res)\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        if fitted:\n",
    "            sigma = _calculate_sigma(y - res['fitted'], y.size)\n",
    "            res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "tsb = TSB(alpha_d=0.9, alpha_p=0.1, prediction_intervals=ConformalIntervals(2, 1))\n",
    "test_class(tsb, x=ap, h=12, skip_insample=False, level=[80])\n",
    "test_class(tsb, x=deg_ts, h=12, skip_insample=False, level=[80])\n",
    "fcst_tsb = tsb.forecast(ap, 12)\n",
    "\n",
    "_test_fitted_sparse(lambda: TSB(alpha_d=0.9, alpha_p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "tsb_c = TSB(alpha_d=0.9, alpha_p=0.1,prediction_intervals=ConformalIntervals(h=13, n_windows=2))\n",
    "test_class(tsb_c, x=ap, h=13, level=[90, 80], skip_insample=True)\n",
    "fcst_tsb_c = tsb_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_tsb_c['mean'][:12],\n",
    "    fcst_tsb['mean'],\n",
    ")\n",
    "_plot_insample_pi(fcst_tsb_c)\n",
    "_plot_fcst(fcst_tsb_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(TSB(0.9, 0.1)),\n",
    "    'TSB'\n",
    ")\n",
    "test_eq(\n",
    "    repr(TSB(0.9, 0.1, alias='TSB_custom')),\n",
    "    'TSB_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TSB.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import TSB\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSB's usage example\n",
    "model = TSB(alpha_d=0.5, alpha_p=0.5)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Seasonalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _predict_mstl_components(mstl_ob, h, season_length):\n",
    "    seasoncolumns = mstl_ob.filter(regex='seasonal*').columns\n",
    "    nseasons = len(seasoncolumns)\n",
    "    seascomp = np.full((h, nseasons), np.nan)\n",
    "    seasonal_periods = [season_length] if isinstance(season_length, int) else season_length\n",
    "    for i in range(nseasons):\n",
    "        mp = seasonal_periods[i]\n",
    "        colname = seasoncolumns[i]\n",
    "        seascomp[:, i] = np.tile(mstl_ob[colname].values[-mp:], trunc(1 + (h-1)/mp))[:h]\n",
    "    return seascomp\n",
    "\n",
    "def _predict_mstl_seas(mstl_ob, h, season_length):\n",
    "    seascomp = _predict_mstl_components(mstl_ob, h, season_length)\n",
    "    return seascomp.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSTL(_TS):\n",
    "    r\"\"\"MSTL model.\n",
    "    \n",
    "    The MSTL (Multiple Seasonal-Trend decomposition using LOESS) decomposes the time series\n",
    "    in multiple seasonalities using LOESS. Then forecasts the trend using \n",
    "    a custom non-seaonal model and each seasonality using a SeasonalNaive model.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Bandara, Kasun & Hyndman, Rob & Bergmeir, Christoph. (2021). \"MSTL: A Seasonal-Trend Decomposition Algorithm for Time Series with Multiple Seasonal Patterns\".](https://arxiv.org/abs/2107.13462).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : Union[int, List[int] \n",
    "        Number of observations per unit of time. For multiple seasonalities use a list.\n",
    "    trend_forecaster : model, default=AutoETS(model='ZZN')\n",
    "        StatsForecast model used to forecast the trend component.\n",
    "    stl_kwargs : dict\n",
    "        Extra arguments to pass to [`statsmodels.tsa.seasonal.STL`](https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.STL.html#statsmodels.tsa.seasonal.STL).\n",
    "        The `period` and `seasonal` arguments are reserved.\n",
    "    alias : str\n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: Union[int, List[int]],\n",
    "        trend_forecaster = AutoETS(model='ZZN'),\n",
    "        stl_kwargs: Optional[Dict] = None,\n",
    "        alias: str = 'MSTL',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):  \n",
    "        # check ETS model doesnt have seasonality\n",
    "        if repr(trend_forecaster) == 'AutoETS':\n",
    "            if trend_forecaster.model[2] != 'N':\n",
    "                raise Exception(\n",
    "                    'Trend forecaster should not adjust '\n",
    "                    'seasonal models.'\n",
    "                )\n",
    "        # check if trend forecaster has season_length=1\n",
    "        if hasattr(trend_forecaster, 'season_length'):\n",
    "            if trend_forecaster.season_length != 1:\n",
    "                raise Exception(\n",
    "                    'Trend forecaster should not adjust '\n",
    "                    'seasonal models. Please pass `season_length=1` '\n",
    "                    'to your trend forecaster'\n",
    "                )\n",
    "        if isinstance(season_length, int):\n",
    "            season_length = [season_length]\n",
    "        else:\n",
    "            season_length = sorted(season_length)\n",
    "        self.season_length = season_length\n",
    "        self.trend_forecaster = trend_forecaster\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.alias = alias\n",
    "\n",
    "        if self.trend_forecaster.prediction_intervals is None and (self.prediction_intervals is not None):\n",
    "            self.trend_forecaster.prediction_intervals = prediction_intervals\n",
    "        self.stl_kwargs = dict() if stl_kwargs is None else stl_kwargs\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the MSTL model.\n",
    "\n",
    "        Fit MSTL to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "        X: array-like \n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            MSTL fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = mstl(\n",
    "            x=y, \n",
    "            period=self.season_length,\n",
    "            stl_kwargs=self.stl_kwargs,\n",
    "        )\n",
    "        x_sa = self.model_[['trend', 'remainder']].sum(axis=1).values\n",
    "        self.trend_forecaster = self.trend_forecaster.new().fit(y=x_sa, X=X)\n",
    "        self._store_cs(y=x_sa, X=X)\n",
    "        return self\n",
    "        \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted MSTL.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int  \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        kwargs: Dict[str, Any] = {'h': h, 'X': X}\n",
    "        if self.trend_forecaster.prediction_intervals is None:\n",
    "            kwargs['level'] = level\n",
    "        res = self.trend_forecaster.predict(**kwargs)\n",
    "        seas = _predict_mstl_seas(self.model_, h=h, season_length=self.season_length)\n",
    "        res = {key: val + seas for key, val in res.items()}\n",
    "        if level is None or self.trend_forecaster.prediction_intervals is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.trend_forecaster.prediction_intervals is not None:\n",
    "            res = self.trend_forecaster._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"You have to instantiate either the trend forecaster class or MSTL class with `prediction_intervals` to calculate them\"\n",
    "            )\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted MSTL insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = self.trend_forecaster.predict_in_sample(level=level)\n",
    "        seas = self.model_.filter(regex='seasonal*').sum(axis=1).values\n",
    "        res = {key: val + seas for key, val in res.items()}\n",
    "        return res\n",
    "        \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient MSTL predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        model_ = mstl(\n",
    "            x=y, \n",
    "            period=self.season_length,\n",
    "            stl_kwargs=self.stl_kwargs,\n",
    "        )\n",
    "        x_sa = model_[['trend', 'remainder']].sum(axis=1).values\n",
    "        kwargs = {\n",
    "            'y': x_sa,\n",
    "            'h': h,\n",
    "            'X': X,\n",
    "            'X_future': X_future,\n",
    "            'fitted': fitted\n",
    "        }\n",
    "        if fitted or self.trend_forecaster.prediction_intervals is None:\n",
    "            kwargs['level'] = level\n",
    "        res = self.trend_forecaster.forecast(**kwargs)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.trend_forecaster.prediction_intervals is not None:\n",
    "                res = self.trend_forecaster._add_conformal_intervals(fcst=res, y=x_sa, X=X, level=level)\n",
    "            elif f'lo-{level[0]}' not in res:\n",
    "                raise Exception(\n",
    "                    \"You have to instantiate either the trend forecaster class or MSTL class with `prediction_intervals` to calculate them\"\n",
    "                )        \n",
    "        #reseasonalize results\n",
    "        seas_h = _predict_mstl_seas(model_, h=h, season_length=self.season_length)\n",
    "        seas_insample = model_.filter(regex='seasonal*').sum(axis=1).values\n",
    "        res = {\n",
    "            key: val + (seas_insample if 'fitted' in key else seas_h) \\\n",
    "            for key, val in res.items()\n",
    "        }\n",
    "        return res\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Apply fitted MSTL model to a new time series.\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not to return insample predictions. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        if not hasattr(self.trend_forecaster, 'model_'):\n",
    "            raise Exception('You have to use the `fit` method first')\n",
    "        y = _ensure_float(y)\n",
    "        model_ = mstl(\n",
    "            x=y, \n",
    "            period=self.season_length,\n",
    "            stl_kwargs=self.stl_kwargs,\n",
    "        )\n",
    "        x_sa = model_[['trend', 'remainder']].sum(axis=1).values\n",
    "        kwargs = {\n",
    "            'y': x_sa,\n",
    "            'h': h,\n",
    "            'X': X,\n",
    "            'X_future': X_future,\n",
    "            'fitted': fitted\n",
    "        }\n",
    "        if fitted or self.trend_forecaster.prediction_intervals is None:\n",
    "            kwargs['level'] = level\n",
    "        res = self.trend_forecaster.forward(**kwargs)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.trend_forecaster.prediction_intervals is not None:\n",
    "                res = self.trend_forecaster._add_conformal_intervals(fcst=res, y=x_sa, X=X, level=level)        \n",
    "        #reseasonalize results\n",
    "        seas_h = _predict_mstl_seas(model_, h=h, season_length=self.season_length)\n",
    "        seas_insample = model_.filter(regex='seasonal*').sum(axis=1).values\n",
    "        res = {\n",
    "            key: val + (seas_insample if 'fitted' in key else seas_h) \\\n",
    "            for key, val in res.items()\n",
    "        }\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "trend_forecasters = [\n",
    "    AutoARIMA(), \n",
    "    AutoCES(), \n",
    "    AutoETS(model='ZZN'),\n",
    "    Naive(),\n",
    "    CrostonClassic(),\n",
    "]\n",
    "skip_insamples = [False, True, False, False, True]\n",
    "test_forwards = [False, True, True, False, False]\n",
    "for trend_forecaster, skip_insample, test_forward in zip(trend_forecasters, skip_insamples, test_forwards):\n",
    "    for stl_kwargs in [None, dict(trend=25)]:\n",
    "        mstl_model = MSTL(\n",
    "            season_length=[12, 14], \n",
    "            trend_forecaster=trend_forecaster,\n",
    "            stl_kwargs=stl_kwargs,\n",
    "        )\n",
    "        test_class(mstl_model, x=ap, h=12, \n",
    "                   skip_insample=skip_insample,\n",
    "                   level=None,\n",
    "                   test_forward=test_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# intervals with & without conformal\n",
    "# trend fcst supports level, use native levels\n",
    "mstl_native = MSTL(season_length=12, trend_forecaster=ARIMA(order=(0, 1, 0)))\n",
    "res_native_fp = pd.DataFrame(mstl_native.fit(y=ap).predict(h=24, level=[80, 95]))\n",
    "res_native_fc = pd.DataFrame(mstl_native.forecast(y=ap, h=24, level=[80, 95]))\n",
    "pd.testing.assert_frame_equal(res_native_fp, res_native_fc)\n",
    "\n",
    "# trend fcst supports level, use conformal\n",
    "mstl_conformal = MSTL(\n",
    "    season_length=12,\n",
    "    trend_forecaster=ARIMA(\n",
    "        order=(0, 1, 0),\n",
    "        prediction_intervals=ConformalIntervals(h=24),\n",
    "    ),\n",
    ")\n",
    "res_conformal_fp = pd.DataFrame(mstl_conformal.fit(y=ap).predict(h=24, level=[80, 95]))\n",
    "res_conformal_fc = pd.DataFrame(mstl_conformal.forecast(y=ap, h=24, level=[80, 95]))\n",
    "pd.testing.assert_frame_equal(res_conformal_fp, res_conformal_fc)\n",
    "test_fail(lambda: pd.testing.assert_frame_equal(test_native_fp, test_conformal_fp))\n",
    "\n",
    "# trend fcst doesn't support level\n",
    "mstl_bad = MSTL(season_length=12, trend_forecaster=CrostonClassic())\n",
    "test_fail(lambda: mstl_bad.fit(y=ap).predict(h=24, level=[80, 95]), contains='prediction_intervals')\n",
    "test_fail(lambda: mstl_bad.forecast(y=ap, h=24, level=[80, 95]), contains='prediction_intervals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# conformal prediction\n",
    "# define the prediction interval in the trend_forecaster\n",
    "trend_forecasters = [\n",
    "    AutoARIMA(prediction_intervals=ConformalIntervals(h=13, n_windows=2)),\n",
    "    AutoCES(prediction_intervals=ConformalIntervals(h=13, n_windows=2)),\n",
    "]\n",
    "skip_insamples = [False, True]\n",
    "test_forwards = [False, True]\n",
    "for trend_forecaster, skip_insample, test_forward in zip(trend_forecasters, skip_insamples, test_forwards):\n",
    "    for stl_kwargs in [None, dict(trend=25)]:\n",
    "        mstl_model = MSTL(\n",
    "            season_length=[12, 14], \n",
    "            trend_forecaster=trend_forecaster,\n",
    "            stl_kwargs=stl_kwargs,\n",
    "        )\n",
    "        test_class(mstl_model, x=ap, h=13, \n",
    "                   skip_insample=skip_insample,\n",
    "                   level=[80, 90] if not skip_insample else None,\n",
    "                   test_forward=test_forward)\n",
    "        _plot_fcst(mstl_model.forecast(ap, 13, None, None, (80,95), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# conformal prediction\n",
    "# define prediction_interval in MSTL\n",
    "trend_forecasters = [\n",
    "    AutoCES()\n",
    "]\n",
    "for stl_kwargs in [None, dict(trend=25)]:\n",
    "    mstl_model = MSTL(\n",
    "        season_length=[12, 14], \n",
    "        trend_forecaster=trend_forecaster,\n",
    "        stl_kwargs=stl_kwargs,\n",
    "        prediction_intervals=ConformalIntervals(h=13, n_windows=2)\n",
    "    )\n",
    "    test_class(mstl_model, x=ap, h=13, \n",
    "                skip_insample=False,\n",
    "                level=[80, 90] if not skip_insample else None,\n",
    "                test_forward=True)\n",
    "    _plot_fcst(mstl_model.forecast(ap, 13, None, None, (80,95), False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#fail with seasonal trend forecasters\n",
    "test_fail(\n",
    "    MSTL,\n",
    "    contains='should not adjust seasonal',\n",
    "    args=([3, 12], AutoETS(model='ZZZ'))\n",
    ")\n",
    "test_fail(\n",
    "    MSTL,\n",
    "    contains='should not adjust seasonal',\n",
    "    args=([3, 12], AutoARIMA(season_length=12))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(MSTL(season_length=7)),\n",
    "    'MSTL'\n",
    ")\n",
    "test_eq(\n",
    "    repr(MSTL(season_length=7, alias='MSTL_custom')),\n",
    "    'MSTL_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MSTL.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import MSTL\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSTL's usage example\n",
    "mstl_model = MSTL(season_length=[3, 12], trend_forecaster=AutoARIMA(prediction_intervals=ConformalIntervals(h=4, n_windows=2)))\n",
    "mstl_model = mstl_model.fit(y=ap)\n",
    "y_hat_dict = mstl_model.predict(h=4, level=[80])\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TBATS(_TS):\n",
    "    r\"\"\"Trigonometric Box-Cox transform, ARMA errors, Trend and Seasonal components (TBATS) model.\n",
    "\n",
    "    TBATS is an innovations state space model framework used for forecasting time series with multiple seasonalities. It uses a Box-Cox tranformation, ARMA errors, and a trigonometric representation of the seasonal patterns based on Fourier series.\n",
    "\n",
    "    The name TBATS is an acronym for the key features of the model: Trigonometric, Box-Cox transform, ARMA errors, Trend, and Seasonal components. \n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    - [De Livera, A. M., Hyndman, R. J., & Snyder, R. D. (2011). Forecasting time series with complex seasonal patterns using exponential smoothing. Journal of the American statistical association, 106(496), 1513-1527.](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=f3de25596ab60ef0e886366826bf58a02b35a44f)\n",
    "\n",
    "    - [De Livera, Alysha M (2017). Modeling time series with complex seasonal patterns using exponential smoothing. Monash University. Thesis.](https://doi.org/10.4225/03/589299681de3d)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int or list of int.\n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    use_boxcox : bool (default=True)\n",
    "        Whether or not to use a Box-Cox transformation.\n",
    "    bc_lower_bound : float (default=0.0)\n",
    "        Lower bound for the Box-Cox transformation.\n",
    "    bc_upper_bound : float (default=1.0)\n",
    "        Upper bound for the Box-Cox transformation.    \n",
    "    use_trend : bool (default=True)\n",
    "        Whether or not to use a trend component.\n",
    "    use_damped_trend : bool (default=False)\n",
    "        Whether or not to dampen the trend component.\n",
    "    use_arma_errors : bool (default=False)\n",
    "        Whether or not to use a ARMA errors. \n",
    "    alias : str \n",
    "        Custom name of the model. \n",
    "    \"\"\"\n",
    "\n",
    "    @_old_kw_to_pos(['seasonal_periods'], [1])\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: Union[int, List[int]], \n",
    "        use_boxcox: Optional[bool] = True, \n",
    "        bc_lower_bound: float = 0.0,\n",
    "        bc_upper_bound: float = 1.0,\n",
    "        use_trend: Optional[bool] = True,\n",
    "        use_damped_trend: Optional[bool] = False, \n",
    "        use_arma_errors: bool = False,  \n",
    "        alias: str = 'TBATS',\n",
    "        *,\n",
    "        seasonal_periods=None,  # noqa: ARG002\n",
    "    ):\n",
    "        if isinstance(season_length, int):\n",
    "            season_length = [season_length]\n",
    "        self.season_length = list(season_length)\n",
    "        self.use_boxcox = use_boxcox\n",
    "        self.bc_lower_bound = bc_lower_bound\n",
    "        self.bc_upper_bound = bc_upper_bound\n",
    "        self.use_trend = use_trend\n",
    "        self.use_damped_trend = use_damped_trend\n",
    "        self.use_arma_errors = use_arma_errors\n",
    "        self.alias = alias\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None\n",
    "    ):\n",
    "        r\"\"\"Fit TBATS model.\n",
    "\n",
    "        Fit TBATS model to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ).\n",
    "        X : numpy.array, optional (default=None)\n",
    "            Ignored\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            TBATS model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = tbats_selection(\n",
    "            y=y,\n",
    "            seasonal_periods=self.season_length,\n",
    "            use_boxcox=self.use_boxcox,\n",
    "            bc_lower_bound=self.bc_lower_bound,\n",
    "            bc_upper_bound=self.bc_upper_bound,\n",
    "            use_trend=self.use_trend,\n",
    "            use_damped_trend=self.use_damped_trend,\n",
    "            use_arma_errors=self.use_arma_errors\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self, \n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted TBATS model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fcst = tbats_forecast(self.model_, h)\n",
    "        res = {'mean': fcst['mean']}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            sigmah = _compute_sigmah(self.model_, h)\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "        if self.model_['BoxCox_lambda'] is not None:\n",
    "            res_trans = {k: inv_boxcox(v, self.model_['BoxCox_lambda']) for k, v in res.items()}\n",
    "            for k, v in res_trans.items():\n",
    "                res_trans[k] = np.where(np.isnan(v), res[k], v)\n",
    "        else: \n",
    "            res_trans = res\n",
    "        return res_trans\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[Tuple[int]] = None):\n",
    "        r\"\"\"Access fitted TBATS model predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted'].ravel()}\n",
    "        if level is not None:\n",
    "            se = _calculate_sigma(self.model_['errors'], self.model_['errors'].shape[1])\n",
    "            fitted_pred_int = _add_fitted_pi(res, se, level)\n",
    "            res = {**res, **fitted_pred_int}\n",
    "        if self.model_['BoxCox_lambda'] is not None:\n",
    "            res_trans = {k: inv_boxcox(v, self.model_['BoxCox_lambda']) for k, v in res.items()}\n",
    "            for k, v in res_trans.items():\n",
    "                res_trans[k] = np.where(np.isnan(v), res[k], v)\n",
    "        else:\n",
    "            res_trans = res\n",
    "        return res_trans\n",
    "\n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool=False\n",
    "    ): \n",
    "        r\"\"\"Memory Efficient TBATS model.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (n, ).\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = tbats_selection(\n",
    "            y=y,\n",
    "            seasonal_periods=self.season_length,\n",
    "            use_boxcox=self.use_boxcox,\n",
    "            bc_lower_bound=self.bc_lower_bound,\n",
    "            bc_upper_bound=self.bc_upper_bound,\n",
    "            use_trend=self.use_trend,\n",
    "            use_damped_trend=self.use_damped_trend,\n",
    "            use_arma_errors=self.use_arma_errors\n",
    "        )\n",
    "        fcst = tbats_forecast(mod, h)\n",
    "        res = {'mean': fcst['mean']}\n",
    "        if fitted:\n",
    "            res['fitted'] = mod['fitted'].ravel()\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            sigmah = _compute_sigmah(mod, h)\n",
    "            pred_int = _calculate_intervals(res, level, h, sigmah)\n",
    "            res = {**res, **pred_int}\n",
    "            if fitted:\n",
    "                se = _calculate_sigma(mod['errors'], mod['errors'].shape[1])\n",
    "                fitted_pred_int = _add_fitted_pi(res, se, level)\n",
    "                res = {**res, **fitted_pred_int}\n",
    "        if mod['BoxCox_lambda'] is not None:\n",
    "            res_trans = {k : inv_boxcox(v, mod['BoxCox_lambda']) for k, v in res.items()}\n",
    "            for k, v in res_trans.items():\n",
    "                res_trans[k] = np.where(np.isnan(v), res[k], v)\n",
    "        else:\n",
    "            res_trans = res\n",
    "        return res_trans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "tbats = TBATS(season_length=12)\n",
    "test_class(tbats, x=ap, h=12, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TBATS, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TBATS.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TBATS.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TBATS.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TBATS.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoTBATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AutoTBATS(TBATS):\n",
    "    r\"\"\"AutoTBATS model.\n",
    "\n",
    "    Automatically selects the best TBATS model from all feasible combinations of the parameters use_boxcox, use_trend, use_damped_trend, and use_arma_errors. \n",
    "    Selection is made using the AIC. \n",
    "    Default value for use_arma_errors is True since this enables the evaluation of models with and without ARMA errors.  \n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    - [De Livera, A. M., Hyndman, R. J., & Snyder, R. D. (2011). Forecasting time series with complex seasonal patterns using exponential smoothing. Journal of the American statistical association, 106(496), 1513-1527.](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=f3de25596ab60ef0e886366826bf58a02b35a44f)\n",
    "\n",
    "    - [De Livera, Alysha M (2017). Modeling time series with complex seasonal patterns using exponential smoothing. Monash University. Thesis.](https://doi.org/10.4225/03/589299681de3d)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seasonal_periods : int or list of int.\n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    use_boxcox : bool (default=None)\n",
    "        Whether or not to use a Box-Cox transformation. By default tries both. \n",
    "    bc_lower_bound : float (default=0.0)\n",
    "        Lower bound for the Box-Cox transformation.\n",
    "    bc_upper_bound : float (default=1.0)\n",
    "        Upper bound for the Box-Cox transformation.    \n",
    "    use_trend : bool (default=None)\n",
    "        Whether or not to use a trend component. By default tries both. \n",
    "    use_damped_trend : bool (default=None)\n",
    "        Whether or not to dampen the trend component. By default tries both.\n",
    "    use_arma_errors : bool (default=True)\n",
    "        Whether or not to use a ARMA errors. Default is True and this evaluates both models. \n",
    "    alias : str \n",
    "        Custom name of the model. \n",
    "    \"\"\"\n",
    "    @_old_kw_to_pos(['seasonal_periods'], [1])\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: Union[int, List[int]], \n",
    "        use_boxcox: Optional[bool] = None, \n",
    "        bc_lower_bound: float = 0.0,\n",
    "        bc_upper_bound: float = 1.0,\n",
    "        use_trend: Optional[bool] = None,\n",
    "        use_damped_trend: Optional[bool] = None, \n",
    "        use_arma_errors: bool = True,  \n",
    "        alias: str = 'AutoTBATS',\n",
    "        *,\n",
    "        seasonal_periods=None  # noqa: ARG002\n",
    "    ):\n",
    "        super().__init__(\n",
    "            season_length=season_length, \n",
    "            use_boxcox=use_boxcox, \n",
    "            bc_lower_bound=bc_lower_bound,\n",
    "            bc_upper_bound=bc_upper_bound,\n",
    "            use_trend=use_trend, \n",
    "            use_damped_trend=use_damped_trend, \n",
    "            use_arma_errors=use_arma_errors, \n",
    "            alias=alias\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "tbats = AutoTBATS(season_length=12)\n",
    "test_class(tbats, x=ap, h=12, level=[90, 80])\n",
    "fcst_tbats = tbats.forecast(ap, 13, None, None, (80,95), True)\n",
    "_plot_fcst(fcst_tbats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_plot_insample_pi(fcst_tbats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTBATS, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTBATS.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTBATS.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTBATS.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(AutoTBATS.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theta Family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Theta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Theta(AutoTheta): \n",
    "    r\"\"\" Standard Theta Method. \n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting](https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    decomposition_type : str \n",
    "        Sesonal decomposition type, 'multiplicative' (default) or 'additive'.\n",
    "    alias : str \n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int = 1, \n",
    "        decomposition_type: str = 'multiplicative',\n",
    "        alias: str = 'Theta',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ): \n",
    "        super().__init__(\n",
    "            season_length=season_length, \n",
    "            model='STM', \n",
    "            decomposition_type=decomposition_type, \n",
    "            alias=alias,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "stm = Theta(season_length=12)\n",
    "fcast_stm = stm.forecast(ap,12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='STM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_stm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "stm_c = Theta(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=5)) \n",
    "test_class(stm_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_stm_c = stm_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "\n",
    "test_eq(\n",
    "    fcst_stm_c['mean'][:12],\n",
    "    fcast_stm['mean'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "stm = Theta(season_length=12)\n",
    "stm.fit(ap)\n",
    "fcast_stm = stm.predict(12)\n",
    "forward_stm = stm.forward(y=ap, h=12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='STM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "theta.fit(ap)\n",
    "forward_autotheta = theta.forward(y=ap, h=12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_stm,\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    forward_stm,\n",
    "    forward_autotheta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(Theta()),\n",
    "    'Theta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(Theta(alias='Theta_custom')),\n",
    "    'Theta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.forecast, name='Theta.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.fit, name='Theta.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.predict, name='Theta.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.predict_in_sample, name='Theta.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Theta.forward, name='Theta.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import Theta\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta's usage example\n",
    "model = Theta(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Theta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class OptimizedTheta(AutoTheta): \n",
    "    r\"\"\" Optimized Theta Method. \n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting](https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    decomposition_type : str \n",
    "        Sesonal decomposition type, 'multiplicative' (default) or 'additive'.\n",
    "    alias : str \n",
    "        Custom name of the model. Default `OptimizedTheta`.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int = 1, \n",
    "        decomposition_type: str = 'multiplicative',\n",
    "        alias: str = 'OptimizedTheta',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ): \n",
    "        super().__init__(\n",
    "            season_length=season_length, \n",
    "            model='OTM', \n",
    "            decomposition_type=decomposition_type, \n",
    "            alias=alias,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "otm = OptimizedTheta(season_length=12)\n",
    "fcast_otm = otm.forecast(ap,12)\n",
    "otm.fit(ap)\n",
    "forward_otm = otm.forward(y=ap, h=12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='OTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "theta.fit(ap)\n",
    "forward_autotheta = theta.forward(y=ap, h=12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_otm\n",
    ")\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    forward_autotheta, \n",
    "    forward_otm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "otm_c = OptimizedTheta(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=5)) \n",
    "test_class(otm_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_otm_c = otm_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "\n",
    "test_eq(\n",
    "    fcst_otm_c['mean'][:12],\n",
    "    fcast_otm['mean'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "otm = OptimizedTheta(season_length=12)\n",
    "otm.fit(ap)\n",
    "fcast_otm = otm.predict(12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='OTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_otm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(OptimizedTheta()),\n",
    "    'OptimizedTheta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(OptimizedTheta(alias='OptimizedTheta_custom')),\n",
    "    'OptimizedTheta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.forecast, name='OptimizedTheta.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.fit, name='OptimizedTheta.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.predict, name='OptimizedTheta.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.predict_in_sample, name='OptimizedTheta.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizedTheta.forward, name='OptimizedTheta.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import OptimizedTheta\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OptimzedThetA's usage example\n",
    "model = OptimizedTheta(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Standard Theta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DynamicTheta(AutoTheta): \n",
    "    r\"\"\" Dynamic Standard Theta Method. \n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting](https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    decomposition_type : str \n",
    "        Sesonal decomposition type, 'multiplicative' (default) or 'additive'.\n",
    "    alias : str \n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int = 1, \n",
    "        decomposition_type: str = 'multiplicative',\n",
    "        alias: str = 'DynamicTheta',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ): \n",
    "        super().__init__(\n",
    "            season_length=season_length, \n",
    "            model='DSTM', \n",
    "            decomposition_type=decomposition_type, \n",
    "            alias=alias,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "dstm = DynamicTheta(season_length=12)\n",
    "fcast_dstm = dstm.forecast(ap,12)\n",
    "dstm.fit(ap)\n",
    "forward_dstm = dstm.forward(y=ap, h=12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='DSTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "theta.fit(ap)\n",
    "forward_autotheta = theta.forward(y=ap, h=12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_dstm\n",
    ")\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    forward_autotheta, \n",
    "    forward_dstm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "dstm = DynamicTheta(season_length=12)\n",
    "dstm.fit(ap)\n",
    "fcast_dstm = dstm.predict(12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='DSTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_dstm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "dstm_c = DynamicTheta(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=5)) \n",
    "test_class(dstm_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_dstm_c = dstm_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "\n",
    "test_eq(\n",
    "    fcst_dstm_c['mean'][:12],\n",
    "    fcast_dstm['mean'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(DynamicTheta()),\n",
    "    'DynamicTheta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(DynamicTheta(alias='DynamicTheta_custom')),\n",
    "    'DynamicTheta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.forecast, name='DynamicTheta.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.fit, name='DynamicTheta.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.predict, name='DynamicTheta.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.predict_in_sample, name='DynamicTheta.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicTheta.forward, name='DynamicTheta.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import DynamicTheta\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DynStandardThetaMethod's usage example\n",
    "model = DynamicTheta(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Optimized Theta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DynamicOptimizedTheta(AutoTheta): \n",
    "    r\"\"\" Dynamic Optimized Theta Method. \n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting](https://www.sciencedirect.com/science/article/pii/S0169207016300243)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int \n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    decomposition_type : str \n",
    "        Sesonal decomposition type, 'multiplicative' (default) or 'additive'.\n",
    "    alias : str \n",
    "        Custom name of the model.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        season_length: int = 1, \n",
    "        decomposition_type: str = 'multiplicative',\n",
    "        alias: str = 'DynamicOptimizedTheta',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ): \n",
    "        super().__init__(\n",
    "            season_length=season_length, \n",
    "            model='DOTM', \n",
    "            decomposition_type=decomposition_type, \n",
    "            alias=alias,\n",
    "            prediction_intervals=prediction_intervals,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "dotm = DynamicOptimizedTheta(season_length=12)\n",
    "fcast_dotm = dotm.forecast(ap,12)\n",
    "dotm.fit(ap)\n",
    "forward_dotm = dotm.forward(y=ap, h=12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='DOTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "theta.fit(ap)\n",
    "forward_autotheta = theta.forward(y=ap, h=12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_dotm\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    forward_autotheta, \n",
    "    forward_dotm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "dotm = DynamicOptimizedTheta(season_length=12)\n",
    "dotm.fit(ap)\n",
    "fcast_dotm = dotm.predict(12)\n",
    "\n",
    "theta = AutoTheta(season_length=12, model='DOTM')\n",
    "fcast_theta = theta.forecast(ap,12)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_theta, \n",
    "    fcast_dotm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "dotm_c = DynamicOptimizedTheta(season_length=12, prediction_intervals=ConformalIntervals(h=13, n_windows=5)) \n",
    "test_class(dotm_c, x=ap, h=13, level=[90, 80], test_forward=True)\n",
    "fcst_dotm_c = dotm_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "\n",
    "test_eq(\n",
    "    fcst_dotm_c['mean'][:12],\n",
    "    fcast_dotm['mean'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(DynamicOptimizedTheta()),\n",
    "    'DynamicOptimizedTheta'\n",
    ")\n",
    "test_eq(\n",
    "    repr(DynamicOptimizedTheta(alias='DynamicOptimizedTheta_custom')),\n",
    "    'DynamicOptimizedTheta_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.forecast, name='DynamicOptimizedTheta.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.fit, name='DynamicOptimizedTheta.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.predict, name='DynamicOptimizedTheta.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.predict_in_sample, name='DynamicOptimizedTheta.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DynamicOptimizedTheta.forward, name='DynamicOptimizedTheta.forward', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import DynamicOptimizedTheta\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OptimzedThetaMethod's usage example\n",
    "model = DynamicOptimizedTheta(season_length=12)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCH Family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class GARCH(_TS):\n",
    "    r\"\"\"Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model. \n",
    "    \n",
    "    A method for modeling time series that exhibit non-constant volatility over time. \n",
    "    The GARCH model assumes that at time $t$, $y_t$ is given by: \n",
    "    \n",
    "    $$y_t = v_t \\sigma_t$$ \n",
    "    \n",
    "    with \n",
    "    \n",
    "    $$\\sigma_t^2 = w + \\sum_{i=1}^p a_i y_{t-i}^2 + \\sum_{j=1}^q b_j \\sigma_{t-j}^2$$. \n",
    "    \n",
    "    Here $v_t$ is a sequence of iid random variables with zero mean and unit variance. \n",
    "    The coefficients $w$, $a_i$, $i=1,...,p$, and $b_j$, $j=1,...,q$ must satisfy the following conditions: \n",
    "    \n",
    "    1. $w > 0$ and $a_i, b_j \\geq 0$ for all $i$ and $j$. \n",
    "    2. $\\sum_{k=1}^{max(p,q)} a_k + b_k < 1$. Here it is assumed that $a_i=0$ for $i>p$ and $b_j=0$ for $j>q$. \n",
    "    \n",
    "    The ARCH model is a particular case of the GARCH model when $q=0$. \n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation. Econometrica: Journal of the econometric society, 987-1007.](http://www.econ.uiuc.edu/~econ508/Papers/engle82.pdf) \n",
    "    \n",
    "    [Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal of econometrics, 31(3), 307-327.](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7da8bfa5295375c1141d797e80065a599153c19d)\n",
    "\n",
    "    [James D. Hamilton. Time Series Analysis Princeton University Press, Princeton, New Jersey, 1st Edition, 1994.](https://press.princeton.edu/books/hardcover/9780691042893/time-series-analysis)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : int \n",
    "        Number of lagged versions of the series. \n",
    "    q: int \n",
    "        Number of lagged versions of the volatility. \n",
    "    alias : str \n",
    "        Custom name of the model. \n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        p: int = 1,\n",
    "        q: int = 1,\n",
    "        alias: str = 'GARCH',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "    ):\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        if q !=0: \n",
    "            self.alias = alias+'('+str(p)+','+str(q)+')'\n",
    "        else: \n",
    "            self.alias = alias+'('+str(p)+')'\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None\n",
    "    ):\n",
    "        r\"\"\"Fit GARCH model.\n",
    "\n",
    "        Fit GARCH model to a time series (numpy array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (t, ). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : \n",
    "            GARCH model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = garch_model(y, p=self.p, q=self.q)\n",
    "        self.model_['actual_residuals'] = y - self.model_['fitted']\n",
    "        self._store_cs(y, X)\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self,\n",
    "        h: int, \n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted GARCH model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional exogenous of shape (h, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fcst = garch_forecast(self.model_, h)\n",
    "        res = {'mean': fcst['mean'], 'sigma2': fcst['sigma2']}\n",
    "        if level is None: \n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else: \n",
    "            quantiles = _quantiles(level)\n",
    "            lo = res['mean'].reshape(-1, 1) - quantiles * res['sigma2'].reshape(-1, 1)\n",
    "            hi = res['mean'].reshape(-1, 1) + quantiles * res['sigma2'].reshape(-1, 1)\n",
    "            lo = lo[:, ::-1]\n",
    "            lo = {f'lo-{l}': lo[:, i] for i, l in enumerate(reversed(level))}\n",
    "            hi = {f'hi-{l}': hi[:, i] for i, l in enumerate(level)}\n",
    "            res = {**res, **lo, **hi}\n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted GARCH model predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            residuals = self.model_['actual_residuals']\n",
    "            se = _calculate_sigma(residuals, len(residuals) - 1)\n",
    "            res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int, \n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool=False \n",
    "    ):\n",
    "        r\"\"\"Memory Efficient GARCH model.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mod = garch_model(y, p=self.p, q=self.q)\n",
    "        fcst = garch_forecast(mod, h)\n",
    "        keys = ['mean', 'sigma2']\n",
    "        if fitted: \n",
    "            keys.append('fitted')\n",
    "        res = {key: fcst[key] for key in keys}\n",
    "        if level is not None: \n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_predict_conformal_intervals(res, level)\n",
    "            else:\n",
    "                quantiles = _quantiles(level)\n",
    "                lo = res['mean'].reshape(-1, 1) - quantiles * res['sigma2'].reshape(-1, 1)\n",
    "                hi = res['mean'].reshape(-1, 1) + quantiles * res['sigma2'].reshape(-1, 1)\n",
    "                lo = lo[:, ::-1]\n",
    "                lo = {f'lo-{l}': lo[:, i] for i, l in enumerate(reversed(level))}\n",
    "                hi = {f'hi-{l}': hi[:, i] for i, l in enumerate(level)}\n",
    "                res = {**res, **lo, **hi}\n",
    "            if fitted: \n",
    "                se = _calculate_sigma(y - mod['fitted'], len(y) - 1)\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "# Generate GARCH(2,2) data \n",
    "n = 1000 \n",
    "w = 0.5\n",
    "alpha = np.array([0.1, 0.2])\n",
    "beta = np.array([0.4, 0.2])\n",
    "\n",
    "y = generate_garch_data(n, w, alpha, beta) \n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "garch = GARCH(2,2)\n",
    "test_class(garch, x=y, h=12, skip_insample=False, level=[90,80])\n",
    "fcst_garch = garch.forecast(ap, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "garch_c = GARCH(2,2,prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(garch_c, x=ap, h=13, level=[90, 80], test_forward=False)\n",
    "fcst_garch_c = garch_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_garch_c['mean'][:12],\n",
    "    fcst_garch['mean']\n",
    ")\n",
    "_plot_fcst(fcst_garch_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "h=100\n",
    "fcst = garch.forecast(y, h=h, level=[80,95], fitted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "fig, ax = plt.subplots(1, 1, figsize = (20,7))\n",
    "#plt.plot(np.arange(0, len(y)), y) \n",
    "plt.plot(np.arange(len(y), len(y) + h), fcst['mean'], label='mean')\n",
    "plt.plot(np.arange(len(y), len(y) + h), fcst['sigma2'], color = 'c', label='sigma2')\n",
    "plt.plot(np.arange(len(y), len(y) + h), fcst['lo-95'], color = 'r', label='lo-95')\n",
    "plt.plot(np.arange(len(y), len(y) + h), fcst['hi-95'], color = 'r', label='hi-95')\n",
    "plt.plot(np.arange(len(y), len(y) + h), fcst['lo-80'], color = 'g', label='lo-80')\n",
    "plt.plot(np.arange(len(y), len(y) + h), fcst['hi-80'], color = 'g', label='hi-80')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "fig, ax = plt.subplots(1, 1, figsize = (20,7))\n",
    "plt.plot(np.arange(0, len(y)), y) \n",
    "plt.plot(np.arange(0, len(y)), fcst['fitted'], label='fitted') \n",
    "plt.plot(np.arange(0, len(y)), fcst['fitted-lo-95'], color = 'r', label='fitted-lo-95')\n",
    "plt.plot(np.arange(0, len(y)), fcst['fitted-hi-95'], color = 'r', label='fitted-hi-95')\n",
    "plt.plot(np.arange(0, len(y)), fcst['fitted-lo-80'], color = 'g', label='fitted-lo-80')\n",
    "plt.plot(np.arange(0, len(y)), fcst['fitted-hi-80'], color = 'g', label='fitted-hi-80')\n",
    "plt.xlim(len(y)-50, len(y))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(GARCH, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(GARCH.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(GARCH.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(GARCH.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(GARCH.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCH model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ARCH(GARCH): \n",
    "    r\"\"\"Autoregressive Conditional Heteroskedasticity (ARCH) model. \n",
    "    \n",
    "    A particular case of the GARCH(p,q) model where $q=0$. \n",
    "    It assumes that at time $t$, $y_t$ is given by: \n",
    "    \n",
    "    $$y_t = \\epsilon_t \\sigma_t$$ \n",
    "    \n",
    "    with \n",
    "    \n",
    "    $$\\sigma_t^2 = w0 + \\sum_{i=1}^p a_i y_{t-i}^2$$. \n",
    "    \n",
    "    Here $\\epsilon_t$ is a sequence of iid random variables with zero mean and unit variance. \n",
    "    The coefficients $w$ and $a_i$, $i=1,...,p$ must be nonnegative and $\\sum_{k=1}^p a_k < 1$.  \n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    [Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation. Econometrica: Journal of the econometric society, 987-1007.](http://www.econ.uiuc.edu/~econ508/Papers/engle82.pdf) \n",
    "\n",
    "    [James D. Hamilton. Time Series Analysis Princeton University Press, Princeton, New Jersey, 1st Edition, 1994.](https://press.princeton.edu/books/hardcover/9780691042893/time-series-analysis)\n",
    "    \n",
    "     Parameters\n",
    "    ----------\n",
    "    p : int \n",
    "        Number of lagged versions of the series. \n",
    "    alias : str \n",
    "        Custom name of the model. \n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        By default, the model will compute the native prediction\n",
    "        intervals.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(\n",
    "        self, \n",
    "        p: int = 1,\n",
    "        alias: str = 'ARCH',\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None\n",
    "    ):\n",
    "        self.p = p\n",
    "        self.alias = alias\n",
    "        super().__init__(p, q=0, alias=alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "arch = ARCH(1)\n",
    "test_class(arch, x=y, h=12, skip_insample=False, level=[90,80])\n",
    "fcst_arch = arch.forecast(ap, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test conformal prediction\n",
    "arch_c = ARCH(1,prediction_intervals=ConformalIntervals(h=13, n_windows=2)) \n",
    "test_class(arch_c, x=ap, h=13, level=[90, 80], test_forward=False)\n",
    "fcst_arch_c = arch_c.forecast(ap, 13, None, None, (80,95), True)\n",
    "test_eq(\n",
    "    fcst_arch_c['mean'][:12],\n",
    "    fcst_arch['mean']\n",
    ")\n",
    "_plot_fcst(fcst_arch_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "garch = GARCH(p=1, q=0)\n",
    "fcast_garch = garch.forecast(y, h=12, level=[90,80], fitted=True)\n",
    "\n",
    "arch = ARCH(p=1)\n",
    "fcast_arch = arch.forecast(y, h=12, level=[90,80], fitted=True)\n",
    "\n",
    "np.testing.assert_equal(\n",
    "    fcast_garch, \n",
    "    fcast_arch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARCH, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARCH.fit, name='ARCH.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARCH.predict, name='ARCH.predict', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARCH.predict_in_sample, name='ARCH.predict_in_sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ARCH.forecast, name='ARCH.forecast', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SklearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SklearnModel(_TS):\n",
    "    r\"\"\"scikit-learn model wrapper\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn.base.BaseEstimator\n",
    "        scikit-learn estimator\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        This is required for generating future prediction intervals.\n",
    "    alias : str, optional (default=None)\n",
    "        Custom name of the model. If `None` will use the model's class.\n",
    "    \"\"\"\n",
    "    uses_exog = True\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "        alias: Optional[str] = None,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.alias = alias if alias is not None else model.__class__.__name__\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        X: np.ndarray,\n",
    "    ) -> 'SklearnModel':\n",
    "        r\"\"\"Fit the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ).\n",
    "        X : array-like\n",
    "            Exogenous of shape (t, n_x).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : SklearnModel\n",
    "            Fitted SklearnModel object.\n",
    "        r\"\"\"        \n",
    "        from sklearn.base import clone\n",
    "\n",
    "        self.model_ = {'model': clone(self.model)}\n",
    "        self.model_['model'].fit(X, y)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        self.model_['fitted'] = self.model_['model'].predict(X)\n",
    "        residuals = y - self.model_['fitted']\n",
    "        self.model_['sigma'] = _calculate_sigma(residuals, y.size)\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: np.ndarray,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        r\"\"\"Predict with fitted SklearnModel.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Exogenous of shape (h, n_x).\n",
    "        level: List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        r\"\"\"        \n",
    "        res = {'mean': self.model_['model'].predict(X)}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "\n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None) -> Dict[str, Any]:\n",
    "        r\"\"\"Access fitted SklearnModel insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: np.ndarray,\n",
    "        X_future: np.ndarray,\n",
    "        level: Optional[List[int]] = None,        \n",
    "        fitted: bool = False,\n",
    "    ) -> Dict[str, Any]:\n",
    "        r\"\"\"Memory Efficient SklearnModel predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ).\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Insample exogenous of shape (t, n_x).\n",
    "        X_future : array-like\n",
    "            Exogenous of shape (h, n_x).\n",
    "        level : List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        r\"\"\"        \n",
    "        from sklearn.base import clone\n",
    "\n",
    "        model = clone(self.model)\n",
    "        model.fit(X, y)\n",
    "        res = {'mean': model.predict(X_future)}\n",
    "        if fitted:\n",
    "            res['fitted'] = model.predict(X)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "            if fitted:\n",
    "                residuals = y - res['fitted']\n",
    "                sigma = _calculate_sigma(residuals, y.size)\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: np.ndarray,\n",
    "        X_future: np.ndarray,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Apply fitted SklearnModel to a new/updated time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ).\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Insample exogenous of shape (t, n_x).\n",
    "        X_future : array-like\n",
    "            Exogenous of shape (h, n_x).\n",
    "        level : List[float]\n",
    "            Confidence levels for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `constant` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model_\"):\n",
    "            raise Exception(\"You have to use the `fit` method first\")\n",
    "        res = {'mean': self.model_['model'].predict(X_future)}\n",
    "        if fitted:\n",
    "            res['fitted'] = self.model_['model'].predict(X)\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "            if fitted:\n",
    "                se = _calculate_sigma(y - res['fitted'], y.size)\n",
    "                res = _add_fitted_pi(res=res, se=se, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "h = 12\n",
    "skm = SklearnModel(Ridge(), prediction_intervals=ConformalIntervals(h=h))\n",
    "X = np.arange(ap.size).reshape(-1, 1)\n",
    "X_future = ap.size + np.arange(h).reshape(-1, 1)\n",
    "test_class(skm, x=ap, X=X, X_future=X_future, h=h, skip_insample=False, level=[80, 95], test_forward=True)\n",
    "fcst_skm = skm.forecast(ap, h, X=X, X_future=X_future, fitted=True, level=[80, 95])\n",
    "_plot_insample_pi(fcst_skm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(SklearnModel(Ridge())),\n",
    "    'Ridge'\n",
    ")\n",
    "test_eq(\n",
    "    repr(SklearnModel(Ridge(), alias='my_ridge')),\n",
    "    'my_ridge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SklearnModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SklearnModel.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SklearnModel.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SklearnModel.predict_in_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SklearnModel.forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MFLES(_TS):\n",
    "    r\"\"\"MFLES model.\n",
    "\n",
    "    A method to forecast time series based on Gradient Boosted Time Series Decomposition\n",
    "    which treats traditional decomposition as the base estimator in the boosting \n",
    "    process. Unlike normal gradient boosting, slight learning rates are applied at the \n",
    "    component level (trend/seasonality/exogenous).\n",
    "\n",
    "    The method derives its name from some of the underlying estimators that can\n",
    "    enter into the boosting procedure, specifically: a simple Median, Fourier\n",
    "    functions for seasonality, a simple/piecewise Linear trend, and Exponential\n",
    "    Smoothing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    season_length : int or list of int, optional (default=None)\n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    fourier_order : int, optional (default=None)\n",
    "        How many fourier sin/cos pairs to create, the larger the number the more complex of a seasonal pattern can be fitted.\n",
    "        A lower number leads to smoother results.\n",
    "        This is auto-set based on seasonal_period.\n",
    "    max_rounds : int (default=50)\n",
    "        The max number of boosting rounds. The boosting will auto-stop but depending on other parameters such as rs_lr you may want more rounds.\n",
    "        Generally more rounds means a smoother fit.        \n",
    "    ma : int, optional (default=None)\n",
    "        The moving average order to use, this is auto-set based on internal logic.\n",
    "        Passing 4 would fit a 4 period moving average on the residual component.\n",
    "    alpha : float (default=1.0)\n",
    "        The alpha which is used in fitting the underlying LASSO when using piecewise functions.\n",
    "    decay : float (default=-1.0)\n",
    "        Effects the slopes of the piecewise-linear basis function.\n",
    "    changepoints : boolean (default=True)\n",
    "        Whether to fit for changepoints if all other logic allows for it. If False, MFLES will not ever fit a piecewise trend.        \n",
    "    n_changepoints : int or float (default=0.25)\n",
    "        Number (if int) or proportion (if float) of changepoint knots to place. The default of 0.25 will place 0.25 * (series length) number of knots.\n",
    "    seasonal_lr : float (default=0.9)\n",
    "        A shrinkage parameter (0 < seasonal_lr <= 1) which penalizes the seasonal fit.\n",
    "        A value of 0.9 will flatly multiply the seasonal fit by 0.9 each boosting round, this can be used to allow more signal to the exogenous component.\n",
    "    trend_lr : float (default=0.9)\n",
    "        A shrinkage parameter (0 < trend_lr <= 1) which penalizes the linear trend fit\n",
    "        A value of 0.9 will flatly multiply the linear fit by 0.9 each boosting round, this can be used to allow more signal to the seasonality or exogenous components.\n",
    "    exogenous_lr : float (default=1.0)\n",
    "        The shrinkage parameter (0 < exogenous_lr <= 1) which controls how much of the exogenous signal is carried to the next round.\n",
    "    residuals_lr : float (default=1.0)\n",
    "        A shrinkage parameter (0 < residuals_lr <= 1) which penalizes the residual smoothing.\n",
    "        A value of 0.9 will flatly multiply the residual fit by 0.9 each boosting round, this can be used to allow more signal to the seasonality or linear components.\n",
    "    cov_threshold : float (default=0.7)\n",
    "        The deseasonalized cov is used to auto-set some logic, lowering the cov_threshold will result in simpler and less complex residual smoothing.\n",
    "        If you pass something like 1000 then there will be no safeguards applied.\n",
    "    moving_medians : bool (default=False)\n",
    "        The default behavior is to fit an initial median to the time series. If True, then it will fit a median per seasonal period.\n",
    "    min_alpha : float (default=0.05)\n",
    "        The minimum alpha in the SES ensemble.\n",
    "    max_alpha : float (default=1.0)\n",
    "        The maximum alpha used in the SES ensemble.\n",
    "    trend_penalty : bool (default=True)\n",
    "        Whether to apply a simple penalty to the linear trend component, very useful for dealing with the potentially dangerous piecewise trend.\n",
    "    multiplicative : bool, optional (default=None)\n",
    "        Auto-set based on internal logic. If True, it will simply take the log of the time series.\n",
    "    smoother : bool (default=False)\n",
    "        If True, then a simple exponential ensemble will be used rather than auto settings.\n",
    "    robust : bool, optional (default=None)\n",
    "        If True then MFLES will fit using more reserved methods, i.e. not using piecewise trend or moving average residual smoother.\n",
    "        Auto-set based on internal logic.\n",
    "    verbose : bool (default=False)\n",
    "        Print debugging information.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        This is required for generating future prediction intervals.        \n",
    "    alias : str (default='MFLES')\n",
    "        Custom name of the model.\n",
    "    \"\"\"\n",
    "    uses_exog = True\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        season_length: Optional[Union[int, List[int]]] = None,\n",
    "        fourier_order: Optional[int] = None,\n",
    "        max_rounds: int = 50,        \n",
    "        ma: Optional[int] = None,\n",
    "        alpha: float = 1.0,\n",
    "        decay: float = -1.0,\n",
    "        changepoints: bool = True,        \n",
    "        n_changepoints: Union[float, int] = 0.25,\n",
    "        seasonal_lr: float = 0.9,\n",
    "        trend_lr: float = 0.9,\n",
    "        exogenous_lr: float = 1.0,\n",
    "        residuals_lr: float = 1.0,\n",
    "        cov_threshold: float = 0.7,\n",
    "        moving_medians: bool = False,\n",
    "        min_alpha: float = 0.05,\n",
    "        max_alpha: float = 1.0,\n",
    "        trend_penalty: bool = True,\n",
    "        multiplicative: Optional[bool] = None,\n",
    "        smoother: bool = False,\n",
    "        robust: Optional[bool] = None,        \n",
    "        verbose: bool = False,\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,        \n",
    "        alias: str = 'MFLES',\n",
    "    ):\n",
    "        try:\n",
    "            import sklearn  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ImportError(\"MFLES requires scikit-learn.\") from None\n",
    "        self.season_length = season_length\n",
    "        self.fourier_order = fourier_order\n",
    "        self.max_rounds = max_rounds        \n",
    "        self.ma = ma\n",
    "        self.alpha = alpha\n",
    "        self.decay = decay\n",
    "        self.changepoints = changepoints\n",
    "        self.n_changepoints = n_changepoints\n",
    "        self.seasonal_lr = seasonal_lr\n",
    "        self.trend_lr = trend_lr\n",
    "        self.exogenous_lr = exogenous_lr\n",
    "        self.residuals_lr = residuals_lr\n",
    "        self.cov_threshold = cov_threshold\n",
    "        self.moving_medians = moving_medians\n",
    "        self.min_alpha = min_alpha\n",
    "        self.max_alpha = max_alpha\n",
    "        self.trend_penalty = trend_penalty\n",
    "        self.multiplicative = multiplicative\n",
    "        self.smoother = smoother\n",
    "        self.robust = robust\n",
    "        self.verbose = verbose\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.alias = alias\n",
    "\n",
    "    def _fit(self, y: np.ndarray, X: Optional[np.ndarray]) -> Dict[str, Any]:\n",
    "        model = _MFLES(verbose=self.verbose, robust=self.robust)\n",
    "        fitted = model.fit(\n",
    "            y=y,\n",
    "            X=X,\n",
    "            seasonal_period=self.season_length,\n",
    "            fourier_order=self.fourier_order,\n",
    "            ma=self.ma,\n",
    "            alpha=self.alpha,\n",
    "            decay=self.decay,\n",
    "            n_changepoints=self.n_changepoints,\n",
    "            seasonal_lr=self.seasonal_lr,\n",
    "            linear_lr=self.trend_lr, \n",
    "            exogenous_lr=self.exogenous_lr,            \n",
    "            rs_lr=self.residuals_lr,\n",
    "            cov_threshold=self.cov_threshold,\n",
    "            moving_medians=self.moving_medians,\n",
    "            max_rounds=self.max_rounds,\n",
    "            min_alpha=self.min_alpha,\n",
    "            max_alpha=self.max_alpha,\n",
    "            trend_penalty=self.trend_penalty,\n",
    "            multiplicative=self.multiplicative,\n",
    "            changepoints=self.changepoints,\n",
    "            smoother=self.smoother,\n",
    "        )\n",
    "        return {'model': model, 'fitted': fitted}\n",
    "    \n",
    "    def fit(self, y: np.ndarray, X: Optional[np.ndarray] = None) -> 'MFLES':\n",
    "        r\"\"\"Fit the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ).\n",
    "        X : array-like, optional (default=None)\n",
    "            Exogenous of shape (t, n_x).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : MFLES\n",
    "            Fitted MFLES object.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = self._fit(y=y, X=X)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        residuals = y - self.model_['fitted']\n",
    "        self.model_['sigma'] = _calculate_sigma(residuals, y.size)\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        r\"\"\"Predict with fitted MFLES.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like, optional (default=None)\n",
    "            Exogenous of shape (h, n_x).\n",
    "        level: List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {\"mean\": self.model_[\"model\"].predict(forecast_horizon=h, X=X)}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "\n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None) -> Dict[str, Any]:\n",
    "        r\"\"\"Access fitted SklearnModel insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {'fitted': self.model_['fitted']}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            res = _add_fitted_pi(res=res, se=self.model_['sigma'], level=level)\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ) -> Dict[str, Any]:\n",
    "        r\"\"\"Memory Efficient MFLES predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ).\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Insample exogenous of shape (t, n_x).\n",
    "        X_future : array-like\n",
    "            Exogenous of shape (h, n_x).\n",
    "        level : List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        model = self._fit(y=y, X=X)\n",
    "        res = {\"mean\": model['model'].predict(forecast_horizon=h, X=X_future)}\n",
    "        if fitted:\n",
    "            res[\"fitted\"] = model['fitted']\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "            if fitted:\n",
    "                residuals = y - res[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, y.size)\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MFLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MFLES.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MFLES.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MFLES.predict_in_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MFLES.forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "h = 12\n",
    "X = np.random.rand(ap.size, 2)\n",
    "X_future = np.random.rand(h, 2)\n",
    "\n",
    "mfles = MFLES()\n",
    "test_class(mfles, x=deg_ts, X=X, X_future=X_future, h=h, skip_insample=False, test_forward=False)\n",
    "\n",
    "mfles = MFLES(prediction_intervals=ConformalIntervals(h=h, n_windows=2))\n",
    "test_class(mfles, x=ap, X=X, X_future=X_future, h=h, skip_insample=False, level=[80, 95], test_forward=False)\n",
    "fcst_mfles = mfles.forecast(ap, h, X=X, X_future=X_future, fitted=True, level=[80, 95])\n",
    "_plot_insample_pi(fcst_mfles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoMFLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoMFLES(_TS):\n",
    "    r\"\"\"AutoMFLES\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_size : int\n",
    "        Forecast horizon used during cross validation.\n",
    "    season_length : int or list of int, optional (default=None)\n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    n_windows : int (default=2)\n",
    "        Number of windows used for cross validation.\n",
    "    config : dict, optional (default=None)\n",
    "        Mapping from parameter name (from the init arguments of MFLES) to a list of values to try.\n",
    "        If `None`, will use defaults.\n",
    "    step_size : int, optional (default=None)\n",
    "        Step size between each cross validation window. If `None` will be set to test_size.\n",
    "    metric : str (default='smape')\n",
    "        Metric used to select the best model. Possible options are: 'smape', 'mape', 'mse' and 'mae'.\n",
    "    verbose : bool (default=False)\n",
    "        Print debugging information.\n",
    "    prediction_intervals : Optional[ConformalIntervals]\n",
    "        Information to compute conformal prediction intervals.\n",
    "        This is required for generating future prediction intervals.\n",
    "    alias : str (default='AutoMFLES')\n",
    "        Custom name of the model.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        test_size: int,\n",
    "        season_length: Optional[Union[int, List[int]]] = None,\n",
    "        n_windows: int = 2,\n",
    "        config: Optional[Dict[str, Any]] = None,\n",
    "        step_size: Optional[int] = None,\n",
    "        metric: str = 'smape',\n",
    "        verbose: bool = False,\n",
    "        prediction_intervals: Optional[ConformalIntervals] = None,\n",
    "        alias: str = 'AutoMFLES',\n",
    "    ):\n",
    "        try:\n",
    "            import sklearn  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ImportError(\"MFLES requires scikit-learn.\") from None\n",
    "        self.season_length = season_length\n",
    "        self.n_windows = n_windows\n",
    "        self.test_size = test_size\n",
    "        self.config = config\n",
    "        self.step_size = step_size if step_size is not None else test_size\n",
    "        self.metric = metric\n",
    "        self.verbose = verbose\n",
    "        self.prediction_intervals = prediction_intervals\n",
    "        self.alias = alias\n",
    "\n",
    "    def _fit(self, y: np.ndarray, X: Optional[np.ndarray] = None) -> Dict[str, Any]:\n",
    "        model = _MFLES(verbose=self.verbose)\n",
    "        optim_params = model.optimize(\n",
    "            y=y,\n",
    "            X=X,\n",
    "            test_size=self.test_size,\n",
    "            n_steps=self.n_windows,\n",
    "            step_size=self.step_size,\n",
    "            seasonal_period=self.season_length,\n",
    "            metric=self.metric,\n",
    "            params=self.config,\n",
    "        )\n",
    "        # the seasonal_period may've been found during the optimization\n",
    "        seasonal_period = optim_params.pop('seasonal_period', self.season_length)\n",
    "        fitted = model.fit(\n",
    "            y=y,\n",
    "            X=X,\n",
    "            seasonal_period=seasonal_period,\n",
    "            **optim_params,\n",
    "        )\n",
    "        return {'model': model, 'fitted': fitted}\n",
    "\n",
    "    def fit(self, y: np.ndarray, X: Optional[np.ndarray] = None) -> 'AutoMFLES':\n",
    "        r\"\"\"Fit the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ).\n",
    "        X : array-like, optional (default=None)\n",
    "            Exogenous of shape (t, n_x).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : AutoMFLES\n",
    "            Fitted AutoMFLES object.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.model_ = self._fit(y=y, X=X)\n",
    "        self._store_cs(y=y, X=X)\n",
    "        residuals = y - self.model_[\"fitted\"]\n",
    "        self.model_[\"sigma\"] = _calculate_sigma(residuals, y.size)\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        r\"\"\"Predict with fitted AutoMFLES.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like, optional (default=None)\n",
    "            Exogenous of shape (h, n_x).\n",
    "        level: List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        r\"\"\"        \n",
    "        res = {\"mean\": self.model_[\"model\"].predict(forecast_horizon=h, X=X)}\n",
    "        if level is None:\n",
    "            return res\n",
    "        level = sorted(level)\n",
    "        if self.prediction_intervals is not None:\n",
    "            res = self._add_predict_conformal_intervals(res, level)\n",
    "        else:\n",
    "            raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "        return res\n",
    "\n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None) -> Dict[str, Any]:\n",
    "        r\"\"\"Access fitted AutoMFLES insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = {\"fitted\": self.model_[\"fitted\"]}\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            res = _add_fitted_pi(res=res, se=self.model_[\"sigma\"], level=level)\n",
    "        return res\n",
    "\n",
    "    def forecast(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ) -> Dict[str, Any]:\n",
    "        r\"\"\"Memory Efficient AutoMFLES predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ).\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Insample exogenous of shape (t, n_x).\n",
    "        X_future : array-like\n",
    "            Exogenous of shape (h, n_x).\n",
    "        level : List[int]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        model = self._fit(y=y, X=X)\n",
    "        res = {\"mean\": model[\"model\"].predict(forecast_horizon=h, X=X_future)}\n",
    "        if fitted:\n",
    "            res[\"fitted\"] = model[\"fitted\"]\n",
    "        if level is not None:\n",
    "            level = sorted(level)\n",
    "            if self.prediction_intervals is not None:\n",
    "                res = self._add_conformal_intervals(fcst=res, y=y, X=X, level=level)\n",
    "            else:\n",
    "                raise Exception(\"You must pass `prediction_intervals` to compute them.\")\n",
    "            if fitted:\n",
    "                residuals = y - res[\"fitted\"]\n",
    "                sigma = _calculate_sigma(residuals, y.size)\n",
    "                res = _add_fitted_pi(res=res, se=sigma, level=level)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "h = 12\n",
    "X = np.random.rand(ap.size, 2)\n",
    "X_future = np.random.rand(h, 2)\n",
    "\n",
    "auto_mfles = AutoMFLES(test_size=h, season_length=12)\n",
    "test_class(auto_mfles, x=deg_ts, X=X, X_future=X_future, h=h, skip_insample=False, test_forward=False)\n",
    "\n",
    "auto_mfles = AutoMFLES(test_size=h, season_length=12, prediction_intervals=ConformalIntervals(h=h, n_windows=2))\n",
    "test_class(auto_mfles, x=ap, X=X, X_future=X_future, h=h, skip_insample=False, level=[80, 95], test_forward=False)\n",
    "fcst_auto_mfles = auto_mfles.forecast(ap, h, X=X, X_future=X_future, fitted=True, level=[80, 95])\n",
    "_plot_insample_pi(fcst_auto_mfles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fallback Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConstantModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ConstantModel(_TS):\n",
    "    \n",
    "    def __init__(self, constant: float, alias: str = 'ConstantModel'):\n",
    "        r\"\"\"Constant Model.\n",
    "        \n",
    "        Returns Constant values.\n",
    "         \n",
    "        Parameters \n",
    "        ----------\n",
    "        constant: float\n",
    "            Custom value to return as forecast.\n",
    "        alias: str\n",
    "            Custom name of the model.  \n",
    "        \"\"\"\n",
    "        self.constant = constant\n",
    "        self.alias = alias\n",
    "    \n",
    "    def fit(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        r\"\"\"Fit the Constant model.\n",
    "\n",
    "        Fit an Constant Model to a time series (numpy.array) `y`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array\n",
    "            Clean time series of shape (t, ). \n",
    "        X : array-like\n",
    "            Optional exogenous of shape (t, n_x). \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self:\n",
    "            Constant fitted model.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        self.n_y = len(y)\n",
    "        self._dtype = y.dtype\n",
    "        return self\n",
    "    \n",
    "    def predict(\n",
    "        self, \n",
    "        h: int, # forecasting horizon \n",
    "        X: Optional[np.ndarray] = None, # exogenous regressors\n",
    "        level: Optional[List[int]] = None # confidence level\n",
    "    ):\n",
    "        r\"\"\"Predict with fitted ConstantModel.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float] \n",
    "            Confidence levels (0-100) for prediction intervals. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        mean = np.full(h, self.constant, dtype=self._dtype)\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if level is not None: \n",
    "            for lv in sorted(level):\n",
    "                res[f'lo-{lv}'] = mean\n",
    "                res[f'hi-{lv}'] = mean\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def predict_in_sample(self, level: Optional[List[int]] = None):\n",
    "        r\"\"\"Access fitted Constant Model insample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `fitted` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        fitted = np.full(self.n_y, self.constant, dtype=self._dtype)\n",
    "        res = {'fitted': fitted}\n",
    "        if level is not None:\n",
    "            for lv in sorted(level):\n",
    "                res[f'fitted-lo-{lv}'] = fitted\n",
    "                res[f'fitted-hi-{lv}'] = fitted\n",
    "                \n",
    "        return res\n",
    "    \n",
    "    def forecast(\n",
    "        self, \n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Memory Efficient Constant Model predictions.\n",
    "\n",
    "        This method avoids memory burden due from object storage.\n",
    "        It is analogous to `fit_predict` without storing information.\n",
    "        It assumes you know the forecast horizon in advance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n,). \n",
    "        h: int\n",
    "            Forecast horizon.\n",
    "        X : array-like\n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like\n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels (0-100) for prediction intervals.\n",
    "        fitted : bool\n",
    "            Whether or not to return insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict\n",
    "            Dictionary with entries `mean` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        y = _ensure_float(y)\n",
    "        mean = np.full(h, self.constant, dtype=y.dtype)\n",
    "        res = {'mean': mean}\n",
    "        \n",
    "        if fitted:\n",
    "            fitted_vals = np.full_like(y, self.constant)\n",
    "            res['fitted'] = fitted_vals\n",
    "        \n",
    "        if level is not None: \n",
    "            for lv in sorted(level):\n",
    "                res[f'lo-{lv}'] = mean\n",
    "                res[f'hi-{lv}'] = mean\n",
    "                if fitted:\n",
    "                    res[f'fitted-lo-{lv}'] = fitted_vals\n",
    "                    res[f'fitted-hi-{lv}'] = fitted_vals\n",
    "        return res\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        y: np.ndarray,\n",
    "        h: int,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        X_future: Optional[np.ndarray] = None,\n",
    "        level: Optional[List[int]] = None,\n",
    "        fitted: bool = False,\n",
    "    ):\n",
    "        r\"\"\"Apply Constant model predictions to a new/updated time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : numpy.array \n",
    "            Clean time series of shape (n, ). \n",
    "        h : int \n",
    "            Forecast horizon.\n",
    "        X : array-like \n",
    "            Optional insample exogenous of shape (t, n_x). \n",
    "        X_future : array-like \n",
    "            Optional exogenous of shape (h, n_x). \n",
    "        level : List[float]\n",
    "            Confidence levels for prediction intervals.\n",
    "        fitted : bool \n",
    "            Whether or not returns insample predictions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        forecasts : dict \n",
    "            Dictionary with entries `constant` for point predictions and `level_*` for probabilistic predictions.\n",
    "        \"\"\"\n",
    "        res = self.forecast(y=y, h=h, X=X, X_future=X_future, level=level, fitted=fitted)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "constant_model = ConstantModel(constant=1)\n",
    "test_class(constant_model, x=ap, h=12, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "constant_model.forecast(ap, 12, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "constant_model.forward(ap, 12, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(ConstantModel(1)),\n",
    "    'ConstantModel'\n",
    ")\n",
    "test_eq(\n",
    "    repr(ConstantModel(1, alias='ConstantModel_custom')),\n",
    "    'ConstantModel_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ConstantModel, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ConstantModel.forecast, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ConstantModel.fit, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ConstantModel.predict, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ConstantModel.predict_in_sample, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ConstantModel.forward, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import ConstantModel\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConstantModel's usage example\n",
    "model = ConstantModel(1)\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZeroModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ZeroModel(ConstantModel):\n",
    "    \n",
    "    def __init__(self, alias: str = 'ZeroModel'):\n",
    "        r\"\"\"Returns Zero forecasts.\n",
    "        \n",
    "        Returns Zero values.\n",
    "         \n",
    "        Parameters \n",
    "        ----------\n",
    "        alias: str\n",
    "            Custom name of the model.  \n",
    "        \"\"\"\n",
    "        super().__init__(constant=0, alias=alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "zero_model = ZeroModel()\n",
    "test_class(constant_model, x=ap, h=12, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "zero_model.forecast(ap, 12, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "zero_model.forward(ap, 12, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(ZeroModel()),\n",
    "    'ZeroModel'\n",
    ")\n",
    "test_eq(\n",
    "    repr(ZeroModel(alias='ZeroModel_custom')),\n",
    "    'ZeroModel_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ZeroModel, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ZeroModel.forecast, title_level=3, name='ZeroModel.forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ZeroModel.fit, title_level=3, name='ZeroModel.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ZeroModel.predict, title_level=3, name='ZeroModel.predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ZeroModel.predict_in_sample, title_level=3, name='ZeroModel.predict_in_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ZeroModel.forward, title_level=3, name='ZeroModel.forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import ZeroModel\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NanModel's usage example\n",
    "model = ZeroModel()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NaNModel(ConstantModel):\n",
    "    \n",
    "    def __init__(self, alias: str = 'NaNModel'):\n",
    "        r\"\"\"NaN Model.\n",
    "        \n",
    "        Returns NaN values.\n",
    "         \n",
    "        Parameters \n",
    "        ----------\n",
    "        alias: str\n",
    "            Custom name of the model.  \n",
    "        \"\"\"\n",
    "        super().__init__(constant=np.nan, alias=alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "nanmodel = NaNModel()\n",
    "nanmodel.forecast(ap, 12, level=[90, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#test alias argument\n",
    "test_eq(\n",
    "    repr(NaNModel()),\n",
    "    'NaNModel'\n",
    ")\n",
    "test_eq(\n",
    "    repr(NaNModel(alias='NaN_custom')),\n",
    "    'NaN_custom'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(NaNModel, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(NaNModel.forecast, title_level=3, name='NaNModel.forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(NaNModel.fit, title_level=3, name='NaNModel.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(NaNModel.predict, title_level=3, name='NaNModel.predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(NaNModel.predict_in_sample, title_level=3, name='NaNModel.predict_in_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import NaNModel\n",
    "from statsforecast.utils import AirPassengers as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NanModel's usage example\n",
    "model = NaNModel()\n",
    "model = model.fit(y=ap)\n",
    "y_hat_dict = model.predict(h=4)\n",
    "y_hat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **General**\n",
    "-  [Hyndman, R.J., & Athanasopoulos, G. (2021). \"Forecasting: principles and practice, 3rd edition\". OTexts: Melbourne, Australia. OTexts.com/fpp3  Accessed on July 2022](https://otexts.com/fpp3/).\n",
    "\n",
    "- [Shmueli, G., & Lichtendahl Jr, K. C. (2016). \"Practical time series forecasting with R: A hands-on guide\". Axelrod Schnall Publishers](https://www.forecastingbook.com/).\n",
    "\n",
    "#### **Automatic Forecasting**\n",
    "- [Rob J. Hyndman, Yeasmin Khandakar (2008). \"Automatic Time Series Forecasting: The forecast package for R\"](https://www.jstatsoft.org/article/view/v027i03).\n",
    "\n",
    "#### **Exponential Smoothing**\n",
    "- [Charles. C. Holt (1957). \"Forecasting seasonals and trends by exponentially weighted moving averages\", ONR Research Memorandum, Carnegie Institute of Technology 52](https://www.sciencedirect.com/science/article/abs/pii/S0169207003001134).\n",
    "\n",
    "- [Peter R. Winters (1960). \"Forecasting sales by exponentially weighted moving averages\". Management Science](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.3.324).\n",
    "\n",
    "- [Hyndman, Rob, et al (2008). \"Forecasting with exponential smoothing: the state space approach\"](https://robjhyndman.com/expsmooth/).\n",
    "\n",
    "- [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Methods with trend\"](https://otexts.com/fpp3/holt.html).\n",
    "\n",
    "- [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Methods with seasonality\"](https://otexts.com/fpp3/holt-winters.html).\n",
    "\n",
    "#### **Simple Methods**\n",
    "- [Rob J. Hyndman and George Athanasopoulos (2018). \"Forecasting principles and practice, Simple Methods\"](https://otexts.com/fpp3/simple-methods.html).\n",
    "\n",
    "#### **Sparse Intermittent**\n",
    "- [Croston, J. D. (1972). \"Forecasting and stock control for intermittent demands\". Journal of the Operational Research Society, 23(3), 289-303](https://link.springer.com/article/10.1057/jors.1972.50).\n",
    "\n",
    "- [Nikolopoulos, K., Syntetos, A. A., Boylan, J. E., Petropoulos, F., & Assimakopoulos, V. (2011). \"An aggregate–disaggregate intermittent demand approach (ADIDA) to forecasting: an empirical proposition and analysis\". Journal of the Operational Research Society, 62(3), 544-554](https://researchportal.bath.ac.uk/en/publications/an-aggregate-disaggregate-intermittent-demand-approach-adida-to-f).\n",
    "\n",
    "- [Syntetos, A. A., & Boylan, J. E. (2005). \"The accuracy of intermittent demand estimates\". International Journal of forecasting, 21(2), 303-314](https://www.academia.edu/1527250/The_accuracy_of_intermittent_demand_estimates).\n",
    "\n",
    "- [Syntetos, A. A., & Boylan, J. E. (2021). \"Intermittent demand forecasting: Context, methods and applications\". John Wiley & Sons](https://www.ifors.org/intermittent-demand-forecasting-context-methods-and-applications/).\n",
    "\n",
    "- [Teunter, R. H., Syntetos, A. A., & Babai, M. Z. (2011). \"Intermittent demand: Linking forecasting to inventory obsolescence\". European Journal of Operational Research, 214(3), 606-615](https://www.sciencedirect.com/science/article/abs/pii/S0377221711004437).\n",
    "\n",
    "#### **Multiple Seasonalities**\n",
    "\n",
    "- [Bandara, Kasun & Hyndman, Rob & Bergmeir, Christoph. (2021). \"MSTL: A Seasonal-Trend Decomposition Algorithm for Time Series with Multiple Seasonal Patterns\".](https://arxiv.org/abs/2107.13462)\n",
    "\n",
    "#### **Theta Family**\n",
    "\n",
    "- [Jose A. Fiorucci, Tiago R. Pellegrini, Francisco Louzada, Fotios Petropoulos, Anne B. Koehler (2016). \"Models for optimising the theta method and their relationship to state space models\". International Journal of Forecasting]( https://www.sciencedirect.com/science/article/pii/S0169207016300243).\n",
    "\n",
    "\n",
    "#### **GARCH Model**\n",
    "\n",
    "- [Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation. Econometrica: Journal of the econometric society, 987-1007.](http://www.econ.uiuc.edu/~econ508/Papers/engle82.pdf) \n",
    "\n",
    "- [Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal of econometrics, 31(3), 307-327.](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7da8bfa5295375c1141d797e80065a599153c19d)\n",
    "\n",
    "- [Hamilton, J. D. (1994). Time series analysis. Princeton university press.](https://press.princeton.edu/books/hardcover/9780691042893/time-series-analysis)\n",
    "\n",
    "#### **TBATS Model**\n",
    "\n",
    "- [De Livera, A. M., Hyndman, R. J., & Snyder, R. D. (2011). Forecasting time series with complex seasonal patterns using exponential smoothing. Journal of the American statistical association, 106(496), 1513-1527.](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=f3de25596ab60ef0e886366826bf58a02b35a44f)\n",
    "\n",
    "- [De Livera, Alysha M (2017). Modeling time series with complex seasonal patterns using exponential smoothing. Monash University. Thesis.](https://doi.org/10.4225/03/589299681de3d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
