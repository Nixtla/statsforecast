{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> The `core.StatsForecast` class allows you to efficiently fit multiple `StatsForecast` models for large sets of time series. It operates with pandas DataFrame `df` that identifies individual series and datestamps with the `unique_id` and `ds` columns, and the `y` column denotes the target time series variable. To assist development, we declare useful datasets that we use throughout all `StatsForecast`'s unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Dict\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "from utilsforecast.compat import DataFrame\n",
    "from utilsforecast.data import generate_series as utils_generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "# Global variables\n",
    "NOGIL = bool(os.getenv('NIXTLA_NUMBA_RELEASE_GIL', ''))\n",
    "LEGACY_CACHE = bool(os.getenv('NUMBA_CACHE', ''))\n",
    "if LEGACY_CACHE:\n",
    "    warnings.warn(\n",
    "        'The NUMBA_CACHE environment variable has been renamed to NIXTLA_NUMBA_CACHE. '\n",
    "        'Please set that one instead.',\n",
    "        FutureWarning,\n",
    "    )\n",
    "CACHE = bool(os.getenv('NIXTLA_NUMBA_CACHE', '')) or LEGACY_CACHE\n",
    "results = namedtuple(\"results\", \"x fn nit simplex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nbdev.showdoc import add_docs, show_doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Synthetic Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_series(n_series: int,\n",
    "                    freq: str = 'D',\n",
    "                    min_length: int = 50,\n",
    "                    max_length: int = 500,\n",
    "                    n_static_features: int = 0,\n",
    "                    equal_ends: bool = False,\n",
    "                    engine:str = 'pandas', \n",
    "                    seed: int = 0) -> DataFrame:\n",
    "    \"\"\"Generate Synthetic Panel Series.\n",
    "\n",
    "    Generates `n_series` of frequency `freq` of different lengths in the interval [`min_length`, `max_length`].\n",
    "    If `n_static_features > 0`, then each series gets static features with random values.\n",
    "    If `equal_ends == True` then all series end at the same date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_series : int\n",
    "        Number of series for synthetic panel.\n",
    "    freq : str (default='D')\n",
    "        Frequency of the data, 'D' or 'M'.\n",
    "    min_length : int (default=50)\n",
    "        Minimum length of synthetic panel's series.\n",
    "    max_length : int (default=500)\n",
    "        Maximum length of synthetic panel's series.\n",
    "    n_static_features : int (default=0)\n",
    "        Number of static exogenous variables for synthetic panel's series.\n",
    "    equal_ends : bool (default=False)\n",
    "        Series should end in the same date stamp `ds`.\n",
    "    engine : str (default='pandas')\n",
    "        Output Dataframe type ('pandas' or 'polars').\n",
    "    seed : int (default=0)\n",
    "        Random seed used for generating the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas or polars DataFrame\n",
    "        Synthetic panel with columns [`unique_id`, `ds`, `y`] and exogenous.\n",
    "    \"\"\"\n",
    "    return utils_generate_series(\n",
    "        n_series=n_series,\n",
    "        freq=freq,\n",
    "        min_length=min_length,\n",
    "        max_length=max_length,\n",
    "        n_static_features=n_static_features,\n",
    "        equal_ends=equal_ends,\n",
    "        engine=engine,\n",
    "        seed=seed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(generate_series, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_panel = generate_series(n_series=2)\n",
    "synthetic_panel.groupby('unique_id', observed=True).head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AirPassengers Data\n",
    "\n",
    "The classic Box & Jenkins airline data. Monthly totals of international airline passengers, 1949 to 1960.\n",
    "\n",
    "It has been used as a reference on several forecasting libraries, since it is a series that shows clear trends and seasonalities it offers a nice opportunity to quickly showcase a model's predictions performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "AirPassengers = np.array([112., 118., 132., 129., 121., 135., 148., 148., 136., 119., 104.,\n",
    "                          118., 115., 126., 141., 135., 125., 149., 170., 170., 158., 133.,\n",
    "                          114., 140., 145., 150., 178., 163., 172., 178., 199., 199., 184.,\n",
    "                          162., 146., 166., 171., 180., 193., 181., 183., 218., 230., 242.,\n",
    "                          209., 191., 172., 194., 196., 196., 236., 235., 229., 243., 264.,\n",
    "                          272., 237., 211., 180., 201., 204., 188., 235., 227., 234., 264.,\n",
    "                          302., 293., 259., 229., 203., 229., 242., 233., 267., 269., 270.,\n",
    "                          315., 364., 347., 312., 274., 237., 278., 284., 277., 317., 313.,\n",
    "                          318., 374., 413., 405., 355., 306., 271., 306., 315., 301., 356.,\n",
    "                          348., 355., 422., 465., 467., 404., 347., 305., 336., 340., 318.,\n",
    "                          362., 348., 363., 435., 491., 505., 404., 359., 310., 337., 360.,\n",
    "                          342., 406., 396., 420., 472., 548., 559., 463., 407., 362., 405.,\n",
    "                          417., 391., 419., 461., 472., 535., 622., 606., 508., 461., 390.,\n",
    "                          432.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "AirPassengersDF = pd.DataFrame({'unique_id': np.ones(len(AirPassengers)),\n",
    "                                'ds': pd.date_range(start='1949-01-01',\n",
    "                                                    periods=len(AirPassengers), freq='M'),\n",
    "                                'y': AirPassengers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.utils import AirPassengersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AirPassengersDF.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to plot the ARIMA predictions, and the prediction intervals.\n",
    "fig, ax = plt.subplots(1, 1, figsize = (20, 7))\n",
    "plot_df = AirPassengersDF.set_index('ds')\n",
    "\n",
    "plot_df[['y']].plot(ax=ax, linewidth=2)\n",
    "ax.set_title('AirPassengers Forecast', fontsize=22)\n",
    "ax.set_ylabel('Monthly Passengers', fontsize=20)\n",
    "ax.set_xlabel('Timestamp [t]', fontsize=20)\n",
    "ax.legend(prop={'size': 15})\n",
    "ax.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _repeat_val_seas(season_vals: np.ndarray, h: int) -> np.ndarray:\n",
    "    repeats = math.ceil(h / season_vals.size)\n",
    "    return np.tile(season_vals, repeats)[:h]\n",
    "\n",
    "def _seasonal_naive(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, #fitted values\n",
    "    season_length: int, # season length\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    n = y.size\n",
    "    season_vals = np.full(season_length, np.nan, np.float32)\n",
    "    season_samples = min(season_length, n)\n",
    "    season_vals[:season_samples] = y[-season_samples:]\n",
    "    out = _repeat_val_seas(season_vals=season_vals, h=h)\n",
    "    fcst = {\"mean\": out}\n",
    "    if fitted:\n",
    "        fitted_vals = np.empty(n, dtype=np.float32)\n",
    "        fitted_vals[:season_length] = np.nan\n",
    "        if n > season_length:\n",
    "            fitted_vals[season_length:] = y[:n - season_length]\n",
    "        fcst[\"fitted\"] = fitted_vals\n",
    "    return fcst\n",
    "\n",
    "def _repeat_val(val: float, h: int) -> np.ndarray:\n",
    "    return np.full(h, val, np.float32)\n",
    "\n",
    "def _naive(\n",
    "    y: np.ndarray, # time series\n",
    "    h: int, # forecasting horizon\n",
    "    fitted: bool, # fitted values\n",
    ") -> Dict[str, np.ndarray]: \n",
    "    fcst = {'mean': _repeat_val(val=y[-1], h=h)}\n",
    "    if fitted:\n",
    "        fitted_vals = np.full(y.size, np.nan, np.float32)\n",
    "        fitted_vals[1:] = np.roll(y, 1)[1:]\n",
    "        fcst['fitted'] = fitted_vals\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test seasonal naive\n",
    "y = np.array([0.50187596, 0.40536128, 0.33436676, 0.27868117, 0.25251294,\n",
    "       0.18961286, 0.07082107, 2.58699709, 3.06466854, 2.25150509,\n",
    "       1.33027107, 0.73332616, 0.50187596, 0.40536128, 0.33436676,\n",
    "       0.27868117, 0.25251294, 0.18961286, 0.07082107, 2.58699709,\n",
    "       3.06466854, 2.25150509, 1.33027107, 0.73332616, 0.50187596,\n",
    "       0.40536128, 0.33436676, 0.27868117, 0.25251294, 0.18961286,\n",
    "       0.07082107, 2.58699709, 3.06466854, 2.25150509, 1.33027107,\n",
    "       0.73332616, 0.50187596, 0.40536128, 0.33436676, 0.27868117,\n",
    "       0.25251294, 0.18961286, 0.07082107, 2.58699709, 3.06466854,\n",
    "       2.25150509, 1.33027107, 0.73332616, 0.50187596, 0.40536128,\n",
    "       0.33436676, 0.27868117, 0.25251294, 0.18961286, 0.07082107,\n",
    "       2.58699709, 3.06466854, 2.25150509, 1.33027107, 0.73332616,\n",
    "       0.50187596, 0.40536128, 0.33436676, 0.27868117, 0.25251294,\n",
    "       0.18961286, 0.07082107, 2.58699709, 3.06466854, 2.25150509,\n",
    "       1.33027107, 0.73332616, 0.50187596, 0.40536128, 0.33436676,\n",
    "       0.27868117, 0.25251294, 0.18961286, 0.07082107, 2.58699709,\n",
    "       3.06466854, 2.25150509, 1.33027107, 0.73332616, 0.50187596,\n",
    "       0.40536128, 0.33436676, 0.27868117, 0.25251294, 0.18961286,\n",
    "       0.07082107, 2.58699709, 3.06466854, 2.25150509, 1.33027107,\n",
    "       0.73332616, 0.50187596, 0.40536128, 0.33436676, 0.27868117,\n",
    "       0.25251294, 0.18961286, 0.07082107, 2.58699709, 3.06466854,\n",
    "       2.25150509, 1.33027107, 0.73332616, 0.50187596, 0.40536128,\n",
    "       0.33436676, 0.27868117, 0.25251294, 0.18961286, 0.07082107,\n",
    "       2.58699709, 3.06466854, 2.25150509, 1.33027107, 0.73332616,\n",
    "       0.50187596, 0.40536128, 0.33436676, 0.27868117, 0.25251294,\n",
    "       0.18961286])\n",
    "seas_naive_fcst = dict(_seasonal_naive(y=y, h=12, season_length=12, fitted=True))['mean']\n",
    "np.testing.assert_array_almost_equal(seas_naive_fcst, y[-12:])\n",
    "\n",
    "\n",
    "y = np.array([0.05293832, 0.10395079, 0.25626143, 0.61529232, 1.08816604,\n",
    "       0.54493457, 0.43415014, 0.47676606, 5.32806397, 3.00553563,\n",
    "       0.04473598, 0.04920475, 0.05293832, 0.10395079, 0.25626143,\n",
    "       0.61529232, 1.08816604, 0.54493457, 0.43415014, 0.47676606,\n",
    "       5.32806397, 3.00553563, 0.04473598, 0.04920475, 0.05293832,\n",
    "       0.10395079, 0.25626143, 0.61529232, 1.08816604, 0.54493457,\n",
    "       0.43415014, 0.47676606, 5.32806397, 3.00553563, 0.04473598,\n",
    "       0.04920475, 0.05293832, 0.10395079, 0.25626143, 0.61529232,\n",
    "       1.08816604, 0.54493457, 0.43415014, 0.47676606, 5.32806397,\n",
    "       3.00553563, 0.04473598, 0.04920475, 0.05293832, 0.10395079,\n",
    "       0.25626143, 0.61529232, 1.08816604])\n",
    "seas_naive_fcst = dict(_seasonal_naive(y=y, h=12, season_length=12, fitted=True))['mean']\n",
    "np.testing.assert_array_almost_equal(seas_naive_fcst, y[-12:])\n",
    "\n",
    "y = np.arange(23)\n",
    "seas_naive_fcst = _seasonal_naive(y, h=12, fitted=True, season_length=12)\n",
    "np.testing.assert_equal(seas_naive_fcst['fitted'], np.hstack([np.full(12, np.nan), y[:11]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "# Functions used for calculating prediction intervals \n",
    "def _quantiles(level): \n",
    "    level = np.asarray(level)\n",
    "    z = norm.ppf(0.5+level/200)   \n",
    "    return z\n",
    "\n",
    "def _calculate_intervals(out, level, h, sigmah):\n",
    "    z = _quantiles(np.asarray(level))\n",
    "    zz = np.repeat(z, h)\n",
    "    zz = zz.reshape(z.shape[0], h)\n",
    "    lower = out['mean'] - zz * sigmah\n",
    "    upper = out['mean'] + zz * sigmah\n",
    "    pred_int = {**{f'lo-{lv}': lower[i] for i, lv in enumerate(level)}, \n",
    "                **{f'hi-{lv}': upper[i] for i, lv in enumerate(level)}}    \n",
    "    return pred_int\n",
    "\n",
    "def _calculate_sigma(residuals, n): \n",
    "    if n>0:\n",
    "        sigma = np.nansum(residuals ** 2) \n",
    "        sigma = sigma / n\n",
    "        sigma = np.sqrt(sigma)\n",
    "    else:\n",
    "        sigma = 0\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class ConformalIntervals:\n",
    "    \"\"\"Class for storing conformal intervals metadata information.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_windows: int = 2,\n",
    "        h: int = 1,\n",
    "        method: str = \"conformal_distribution\",\n",
    "    ):\n",
    "        if n_windows < 2:\n",
    "            raise ValueError(\n",
    "                \"You need at least two windows to compute conformal intervals\"\n",
    "            )\n",
    "        allowed_methods = [\"conformal_distribution\"]\n",
    "        if method not in allowed_methods:\n",
    "            raise ValueError(f\"method must be one of {allowed_methods}\")\n",
    "        self.n_windows = n_windows\n",
    "        self.h = h\n",
    "        self.method = method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
