{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b714247f-d5f5-4937-a0ce-ea07da9915a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433f56c-136e-404c-a488-ddb05ab947c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp mfles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb487f24-09bd-480d-b672-f8242f6f3850",
   "metadata": {},
   "source": [
    "# MFLES model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a1635-ea8a-454e-a77e-a133e894baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from coreforecast.exponentially_weighted import exponentially_weighted_mean\n",
    "from coreforecast.rolling import rolling_mean\n",
    "from numba import njit\n",
    "\n",
    "from statsforecast.utils import _ensure_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d2a56-4a7d-4062-9cf9-dcaebb218ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "# utility functions\n",
    "def calc_mse(y_true, y_pred):\n",
    "    sq_err = (y_true - y_pred) ** 2\n",
    "    return np.mean(sq_err)\n",
    "\n",
    "def calc_mae(y_true, y_pred):\n",
    "    abs_err = np.abs(y_true - y_pred)\n",
    "    return np.mean(abs_err)\n",
    "\n",
    "def calc_mape(y_true, y_pred):\n",
    "    pct_err = np.abs((y_true - y_pred) / (y_pred + 1e-6))\n",
    "    return np.mean(pct_err)\n",
    "\n",
    "def calc_smape(y_true, y_pred):\n",
    "    pct_err = 2 * np.abs(y_true - y_pred) / np.abs(y_true + y_pred + 1e-6)\n",
    "    return np.mean(pct_err)\n",
    "\n",
    "_metric2fn = {\n",
    "    \"mse\": calc_mse,\n",
    "    \"mae\": calc_mae,\n",
    "    \"mape\": calc_mape,\n",
    "    \"smape\": calc_smape,\n",
    "}\n",
    "\n",
    "def cross_validation(y, X, test_size, n_splits, model_obj, metric, step_size=1, **kwargs):\n",
    "    metrics = []\n",
    "    metric_fn = _metric2fn[metric]\n",
    "    residuals = []\n",
    "    if X is None:\n",
    "        exogenous = None\n",
    "    else:\n",
    "        exogenous = X.copy()\n",
    "    for split in range(n_splits):\n",
    "        train_y = y[:-(split*step_size + test_size)]\n",
    "        test_y = y[len(train_y): len(train_y) + test_size]\n",
    "        if exogenous is not None:\n",
    "            train_X = exogenous[:-(split*step_size + test_size), :]\n",
    "            test_X = exogenous[len(train_y): len(train_y) + test_size, :]\n",
    "        else:\n",
    "            train_X = None\n",
    "            test_X = None\n",
    "        model_obj.fit(train_y, X=train_X, **kwargs)\n",
    "        prediction = model_obj.predict(test_size, X=test_X)\n",
    "        metrics.append(metric_fn(test_y, prediction))\n",
    "        residuals.append(test_y - prediction)\n",
    "    return {'metric': np.mean(metrics), 'residuals': residuals}\n",
    "\n",
    "def logic_check(keys_to_check, keys):\n",
    "    return set(keys_to_check).issubset(keys)\n",
    "\n",
    "def logic_layer(param_dict):\n",
    "    keys = param_dict.keys()\n",
    "    # if param_dict['n_changepoints'] is None:\n",
    "    #     if param_dict['decay'] != -1:\n",
    "    #         return False\n",
    "    if logic_check(['seasonal_period', 'max_rounds'], keys):\n",
    "        if param_dict['seasonal_period'] is None:\n",
    "            if param_dict['max_rounds'] < 4:\n",
    "                return False\n",
    "    if logic_check(['smoother', 'ma'], keys):\n",
    "        if param_dict['smoother']:\n",
    "            if param_dict['ma'] is not None:\n",
    "                return False\n",
    "    if logic_check(['seasonal_period', 'seasonality_weights'], keys):\n",
    "        if param_dict['seasonality_weights']:\n",
    "            if param_dict['seasonal_period'] is None:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def default_configs(seasonal_period, configs=None):\n",
    "    if configs is None:\n",
    "        if seasonal_period is not None:\n",
    "            if not isinstance(seasonal_period, list):\n",
    "                seasonal_period = [seasonal_period]\n",
    "            configs = {\n",
    "                'seasonality_weights': [True, False],\n",
    "                'smoother': [True, False],\n",
    "                'ma': [int(min(seasonal_period)), int(min(seasonal_period)/2),None],\n",
    "                'seasonal_period': [None, seasonal_period],\n",
    "                }\n",
    "        else:\n",
    "            configs = {\n",
    "                'smoother': [True, False],\n",
    "                'cov_threshold': [.5, -1],\n",
    "                'max_rounds': [5, 20],\n",
    "                'seasonal_period': [None],\n",
    "                }\n",
    "    keys = configs.keys()\n",
    "    combinations = itertools.product(*configs.values())\n",
    "    ds = [dict(zip(keys,cc)) for cc in combinations]\n",
    "    ds = [i for i in ds if logic_layer(i)]\n",
    "    return ds\n",
    "\n",
    "def cap_outliers(series, outlier_cap=3):\n",
    "    mean = np.mean(series)\n",
    "    std = np.std(series)\n",
    "    return series.clip(\n",
    "        min=mean - outlier_cap * std,\n",
    "        max=mean + outlier_cap * std\n",
    "    )\n",
    "\n",
    "def set_fourier(period):\n",
    "    if period < 10:\n",
    "        fourier = 5\n",
    "    elif period < 70:\n",
    "        fourier = 10\n",
    "    else:\n",
    "        fourier = 15\n",
    "    return fourier\n",
    "\n",
    "def calc_trend_strength(resids, deseasonalized):\n",
    "    return max(0, 1 - (np.var(resids) / np.var(deseasonalized)))\n",
    "\n",
    "def calc_seas_strength(resids, detrended):\n",
    "    return max(0, 1 - (np.var(resids) / np.var(detrended)))\n",
    "\n",
    "def calc_rsq(y, fitted):\n",
    "    try:\n",
    "        mean_y = np.mean(y)\n",
    "        ssres = np.sum((y - fitted) ** 2)\n",
    "        sstot = np.sum((y - mean_y) ** 2)\n",
    "        return 1 - (ssres / sstot)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calc_cov(y, mult=1):\n",
    "    if mult:\n",
    "        # source http://medcraveonline.com/MOJPB/MOJPB-06-00200.pdf\n",
    "        res = np.sqrt(np.exp(np.log(10)*(np.std(y)**2) - 1))\n",
    "    else:\n",
    "        res = np.std(y)\n",
    "        mean = np.mean(y)\n",
    "        if mean != 0:\n",
    "            res = res / mean\n",
    "    return res\n",
    "\n",
    "def get_seasonality_weights(y, seasonal_period):\n",
    "    return 1 + np.arange(y.size) // seasonal_period\n",
    "\n",
    "# feature engineering functions\n",
    "def get_fourier_series(length, seasonal_period, fourier_order):\n",
    "    x = 2 * np.pi * np.arange(1, fourier_order + 1) / seasonal_period\n",
    "    t = np.arange(1, length + 1).reshape(-1, 1)\n",
    "    x = x * t\n",
    "    return np.hstack([np.cos(x), np.sin(x)])\n",
    "\n",
    "@njit\n",
    "def get_basis(y, n_changepoints, decay=-1, gradient_strategy=0):\n",
    "    if n_changepoints < 1:\n",
    "        return np.arange(y.size, dtype=np.float64).reshape(-1, 1)\n",
    "    y = y.copy()\n",
    "    y -= y[0]\n",
    "    n = len(y)\n",
    "    if gradient_strategy:\n",
    "        gradients = np.abs(y[:-1] - y[1:])\n",
    "    initial_point = y[0]\n",
    "    final_point = y[-1]\n",
    "    mean_y = np.mean(y)\n",
    "    changepoints = np.empty(shape=(len(y), n_changepoints + 1))\n",
    "    array_splits = []\n",
    "    for i in range(1, n_changepoints + 1):\n",
    "        i = n_changepoints - i + 1\n",
    "        if gradient_strategy:\n",
    "            cps = np.argsort(-gradients)\n",
    "            cps = cps[cps > 0.1 * len(gradients)]\n",
    "            cps = cps[cps < 0.9 * len(gradients)]\n",
    "            split_point = cps[i-1]\n",
    "            array_splits.append(y[:split_point])\n",
    "        else:\n",
    "            split_point = len(y)//i\n",
    "            array_splits.append(y[:split_point])\n",
    "            y = y[split_point:]\n",
    "    len_splits = 0\n",
    "    for i in range(n_changepoints):\n",
    "        if gradient_strategy:\n",
    "            len_splits = len(array_splits[i])\n",
    "        else:\n",
    "            len_splits += len(array_splits[i])\n",
    "        moving_point = array_splits[i][-1]\n",
    "        left_basis = np.linspace(initial_point, moving_point, len_splits)\n",
    "        if decay is None:\n",
    "            end_point = final_point\n",
    "        else:\n",
    "            if decay == -1:\n",
    "                dd = moving_point**2\n",
    "                if mean_y != 0:\n",
    "                    dd /= mean_y**2\n",
    "                if dd > 0.99:\n",
    "                    dd = 0.99\n",
    "                if dd < 0.001:\n",
    "                    dd = 0.001\n",
    "                end_point = moving_point - ((moving_point - final_point) * (1 - dd))\n",
    "            else:\n",
    "                end_point = moving_point - ((moving_point - final_point) * (1 - decay))\n",
    "        right_basis = np.linspace(moving_point, end_point, n - len_splits + 1)\n",
    "        changepoints[:, i] = np.append(left_basis, right_basis[1:])\n",
    "    changepoints[:, i+1] = np.ones(n)\n",
    "    return changepoints\n",
    "\n",
    "\n",
    "def get_future_basis(basis_functions, forecast_horizon):\n",
    "    n_components = np.shape(basis_functions)[1]\n",
    "    slopes = np.gradient(basis_functions)[0][-1, :]\n",
    "    future_basis = np.arange(0, forecast_horizon + 1)\n",
    "    future_basis += len(basis_functions)\n",
    "    future_basis = np.transpose([future_basis] * n_components)\n",
    "    future_basis = future_basis * slopes\n",
    "    future_basis = future_basis + (basis_functions[-1, :] - future_basis[0, :])\n",
    "    return future_basis[1:, :]\n",
    "\n",
    "def lasso_nb(X, y, alpha, tol=0.001, maxiter=10000):\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "    with warnings.catch_warnings(record=False):\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        lasso = Lasso(alpha=alpha, fit_intercept=False, tol=tol, max_iter=maxiter)\n",
    "        lasso.fit(X, y)\n",
    "    return lasso.coef_\n",
    "\n",
    "# different models\n",
    "@njit\n",
    "def siegel_repeated_medians(x, y):\n",
    "    # Siegel repeated medians regression\n",
    "    n = y.size\n",
    "    slopes = np.empty_like(y)\n",
    "    slopes_sub = np.empty(shape=n - 1, dtype=y.dtype)\n",
    "    for i in range(n):\n",
    "        k = 0\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            xd = x[j] - x[i]\n",
    "            if xd == 0:\n",
    "                slope = 0\n",
    "            else:\n",
    "                slope = (y[j] - y[i]) / xd\n",
    "            slopes_sub[k] = slope\n",
    "            k += 1\n",
    "        slopes[i] = np.median(slopes_sub)\n",
    "    ints = y - slopes * x\n",
    "    return x * np.median(slopes) + np.median(ints)\n",
    "\n",
    "def ses_ensemble(y, min_alpha=0.05, max_alpha=1.0, smooth=False, order=1):\n",
    "    #bad name but does either a ses ensemble or simple moving average\n",
    "    if smooth:\n",
    "        results = np.zeros_like(y)\n",
    "        alphas = np.arange(min_alpha, max_alpha, 0.05)\n",
    "        for alpha in alphas:\n",
    "            results += exponentially_weighted_mean(y, alpha)\n",
    "        results = results / len(alphas)\n",
    "    else:\n",
    "        results = rolling_mean(y, order + 1)\n",
    "        results[:order + 1] = y[:order + 1]\n",
    "    return results\n",
    "\n",
    "def fast_ols(x, y):\n",
    "    \"\"\"Simple OLS for two data sets.\"\"\"\n",
    "    M = x.size\n",
    "    x_sum = x.sum()\n",
    "    y_sum = y.sum()\n",
    "    x_sq_sum = x @ x\n",
    "    x_y_sum = x @ y\n",
    "    slope = (M * x_y_sum - x_sum * y_sum) / (M * x_sq_sum - x_sum**2)\n",
    "    intercept = (y_sum - slope * x_sum) / M\n",
    "    return slope * x + intercept\n",
    "\n",
    "def median(y, seasonal_period):\n",
    "    if seasonal_period is None:\n",
    "        return np.full_like(y, np.median(y))\n",
    "    full_periods, resid = divmod(len(y), seasonal_period)\n",
    "    period_medians = np.median(\n",
    "        y[:full_periods * seasonal_period].reshape(full_periods, seasonal_period),\n",
    "        axis=1,\n",
    "    )\n",
    "    medians = np.repeat(period_medians, seasonal_period)\n",
    "    if resid:\n",
    "        remainder_median = np.median(y[-seasonal_period:])\n",
    "        medians = np.append(medians, np.repeat(remainder_median, resid))\n",
    "    return medians\n",
    "\n",
    "def ols(X, y):\n",
    "    coefs = np.linalg.pinv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "    return X @ coefs\n",
    "\n",
    "def wls(X, y, weights):\n",
    "    weighted_X_T = X.T @ np.diag(weights)\n",
    "    coefs = np.linalg.pinv(weighted_X_T.dot(X)).dot(weighted_X_T.dot(y))\n",
    "    return X @ coefs\n",
    "\n",
    "def _ols(X, y):\n",
    "    return np.linalg.pinv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "\n",
    "class OLS:\n",
    "    def fit(self, X, y):\n",
    "        self.coefs = _ols(X, y)\n",
    "    def predict(self, X):\n",
    "        return X @ self.coefs\n",
    "\n",
    "class Zeros:\n",
    "    def predict(self, X):\n",
    "        return np.zeros(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c4213-8932-4f89-9f70-9375de577ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MFLES:\n",
    "    def __init__(self, verbose=1, robust=None):\n",
    "        self.penalty = None\n",
    "        self.trend = None\n",
    "        self.seasonality = None\n",
    "        self.robust = robust\n",
    "        self.const = None\n",
    "        self.aic = None\n",
    "        self.upper = None\n",
    "        self.lower= None\n",
    "        self.exogenous_models = None\n",
    "        self.verbose = verbose\n",
    "        self.predicted = None\n",
    "\n",
    "    def fit(self,\n",
    "            y,\n",
    "            seasonal_period=None,\n",
    "            X=None,\n",
    "            fourier_order=None,\n",
    "            ma=None,\n",
    "            alpha=1.0,\n",
    "            decay=-1,\n",
    "            n_changepoints=.25,\n",
    "            seasonal_lr=.9,\n",
    "            rs_lr=1,\n",
    "            exogenous_lr=1,\n",
    "            exogenous_estimator=OLS,\n",
    "            exogenous_params={},\n",
    "            linear_lr=.9,\n",
    "            cov_threshold=.7,\n",
    "            moving_medians=False,\n",
    "            max_rounds=50,\n",
    "            min_alpha=.05,\n",
    "            max_alpha=1.0,\n",
    "            round_penalty=0.0001,\n",
    "            trend_penalty=True,\n",
    "            multiplicative=None,\n",
    "            changepoints=True,\n",
    "            smoother=False,\n",
    "            seasonality_weights=False):\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : np.array\n",
    "            the time series as a numpy array.\n",
    "        seasonal_period : int, optional\n",
    "            DESCRIPTION. The default is None.\n",
    "        fourier_order : int, optional\n",
    "            How many fourier sin/cos pairs to create, the larger the number the more complex of a seasonal pattern can be fitted. A lower number leads to smoother results. This is auto-set based on seasonal_period. The default is None.\n",
    "        ma : int, optional\n",
    "            The moving average order to use, this is auto-set based on internal logic. Passing 4 would fit a 4 period moving average on the residual component. The default is None.\n",
    "        alpha : TYPE, optional\n",
    "            The alpha which is used in fitting the underlying LASSO when using piecewise functions. The default is 1.0.\n",
    "        decay : float, optional\n",
    "            Effects the slopes of the piecewise-linear basis function. The default is -1.\n",
    "        n_changepoints : float, optional\n",
    "            The number of changepoint knots to place, a default of .25 with place .25 * series length number of knots. The default is .25.\n",
    "        seasonal_lr : float, optional\n",
    "            A shrinkage parameter (0<seasonal_lr<=1) which penalizes the seasonal fit, a .9 will flatly multiply the seasonal fit by .9 each boosting round, this can be used to allow more signal to the exogenous component. The default is .9.\n",
    "        rs_lr : float, optional\n",
    "            A shrinkage parameter (0<rs_lr<=1) which penalizes the residual smoothing, a .9 will flatly multiply the residual fit by .9 each boosting round, this can be used to allow more signal to the seasonality or linear components. The default is 1.\n",
    "        linear_lr : float, optional\n",
    "            A shrinkage parameter (0<linear_lr<=1) which penalizes the linear trend fit, a .9 will flatly multiply the linear fit by .9 each boosting round, this can be used to allow more signal to the seasonality or exogenous components. The default is .9.\n",
    "        cov_threshold : float, optional\n",
    "            The deseasonalized cov is used to auto-set some logic, lowering the cov_threshold will result in simpler and less complex residual smoothing. If you pass something like 1000 then there will be no safeguards applied. The default is .7.\n",
    "        moving_medians : boolean, optional\n",
    "            The default behavior is to fit an initial median to the time series, if you pass True to moving_medians then it will fit a median per seasonal period. The default is False.\n",
    "        max_rounds : int, optional\n",
    "            The max number of boosting rounds. The boosting will auto-stop but depending on other parameters such as rs_lr you may want more rounds. Generally, the more rounds => the more smooth your fit. The default is 10.\n",
    "        min_alpha : float, optional\n",
    "            The min alpha in the SES ensemble. The default is .05.\n",
    "        max_alpha : float, optional\n",
    "            The max alpha used in the SES ensemble. The default is 1.0.\n",
    "        trend_penalty : boolean, optional\n",
    "            Whether to apply a simple penalty to the lienar trend component, very useful for dealing with the potentially dangerous piecewise trend. The default is True.\n",
    "        multiplicative : boolean, optional\n",
    "            Auto-set based on internal logic, but if given True it will simply take the log of the time series. The default is None.\n",
    "        changepoints : boolean, optional\n",
    "            Whether to fit for changepoints if all other logic allows for it, by setting False then MFLES will not ever fit a piecewise trend. The default is True.\n",
    "        smoother : boolean, optional\n",
    "            If True then a simple exponential ensemble will be used rather than auto settings. The default is False.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        if cov_threshold == -1:\n",
    "            cov_threshold = 10000\n",
    "        n = len(y)\n",
    "        y = _ensure_float(y)\n",
    "        self.exogenous_lr = exogenous_lr\n",
    "        if multiplicative is None:\n",
    "            if seasonal_period is None:\n",
    "                multiplicative = False\n",
    "            else:\n",
    "                multiplicative = True\n",
    "            if y.min() <= 0:\n",
    "                multiplicative = False\n",
    "        if multiplicative:\n",
    "            self.const = y.min()\n",
    "            y = np.log(y)\n",
    "        else:\n",
    "            self.const = None\n",
    "            self.std = np.std(y)\n",
    "            self.mean = np.mean(y)\n",
    "            y = y - self.mean\n",
    "            if self.std > 0:\n",
    "                y = y / self.std\n",
    "        if seasonal_period is not None:\n",
    "            if not isinstance(seasonal_period, list):\n",
    "                seasonal_period = [seasonal_period]        \n",
    "        if n < 4 or np.all(y == np.mean(y)):\n",
    "            if self.verbose:\n",
    "                if n < 4:\n",
    "                    print('series is too short (<4), defaulting to naive')\n",
    "                else:\n",
    "                    print(f'input is constant with value {y[0]}, defaulting to naive')\n",
    "            self.trend = np.append(y[-1], y[-1])\n",
    "            self.seasonality = np.zeros(len(y))\n",
    "            self.trend_penalty = False\n",
    "            self.mean = y[-1]\n",
    "            self.std = 0\n",
    "            self.exo_model = [Zeros()]\n",
    "            return np.tile(y[-1], len(y))\n",
    "        og_y = y\n",
    "        self.og_y = og_y\n",
    "        y = y.copy()\n",
    "        if n_changepoints is None:\n",
    "            changepoints = False\n",
    "        if isinstance(n_changepoints, float) and n_changepoints < 1:\n",
    "            n_changepoints = int(n_changepoints * n)\n",
    "        self.linear_component = np.zeros(n)\n",
    "        self.seasonal_component = np.zeros(n)\n",
    "        self.ses_component = np.zeros(n)\n",
    "        self.median_component = np.zeros(n)\n",
    "        self.exogenous_component = np.zeros(n)\n",
    "        self.exo_model = []\n",
    "        self.round_cost = []\n",
    "        self.trend_penalty = trend_penalty\n",
    "        if moving_medians and seasonal_period is not None:\n",
    "            fitted = median(y, max(seasonal_period))\n",
    "        else:\n",
    "            fitted = median(y, None)\n",
    "        self.median_component += fitted\n",
    "        self.trend = np.append(fitted.copy()[-1:], fitted.copy()[-1:])\n",
    "        mse = None\n",
    "        equal = 0\n",
    "        if ma is None:\n",
    "            ma_cycle = itertools.cycle([1])\n",
    "        else:\n",
    "            if not isinstance(ma, list):\n",
    "                ma = [ma]\n",
    "            ma_cycle = itertools.cycle(ma)\n",
    "        if seasonal_period is not None:\n",
    "            seasons_cycle = itertools.cycle(list(range(len(seasonal_period))))\n",
    "            self.seasonality = np.zeros(max(seasonal_period))\n",
    "            fourier_series = []\n",
    "            for period in seasonal_period:\n",
    "                if fourier_order is None:\n",
    "                    fourier = set_fourier(period)\n",
    "                else:\n",
    "                    fourier = fourier_order\n",
    "                fourier_series.append(get_fourier_series(n,\n",
    "                                                    period,\n",
    "                                                    fourier))\n",
    "            if seasonality_weights:\n",
    "                cycle_weights = []\n",
    "                for period in seasonal_period:\n",
    "                    cycle_weights.append(get_seasonality_weights(y, period))\n",
    "        else:\n",
    "            self.seasonality = None\n",
    "        for i in range(max_rounds):\n",
    "            resids = y - fitted\n",
    "            if mse is None:\n",
    "                mse = calc_mse(y, fitted)\n",
    "            else:\n",
    "                if mse <= calc_mse(y, fitted):\n",
    "                    if equal == 6:\n",
    "                        break\n",
    "                    equal += 1\n",
    "                else:\n",
    "                    mse = calc_mse(y, fitted)\n",
    "                self.round_cost.append(mse)\n",
    "            if seasonal_period is not None:\n",
    "                seasonal_period_cycle = next(seasons_cycle)\n",
    "                if seasonality_weights:\n",
    "                    seas = wls(fourier_series[seasonal_period_cycle],\n",
    "                               resids,\n",
    "                               cycle_weights[seasonal_period_cycle])\n",
    "                else:\n",
    "                    seas = ols(fourier_series[seasonal_period_cycle],\n",
    "                               resids)\n",
    "                seas = seas * seasonal_lr\n",
    "                component_mse = calc_mse(y, fitted + seas)\n",
    "                if mse > component_mse:\n",
    "                    mse = component_mse\n",
    "                    fitted += seas\n",
    "                    resids = y - fitted\n",
    "                    self.seasonality += np.resize(seas[-seasonal_period[seasonal_period_cycle]:],\n",
    "                                                  len(self.seasonality))\n",
    "                    self.seasonal_component += seas\n",
    "            if X is not None and i > 0:\n",
    "                model_obj = exogenous_estimator(**exogenous_params)\n",
    "                model_obj.fit(X, resids)\n",
    "                self.exo_model.append(model_obj)\n",
    "                _fitted_values = model_obj.predict(X) * exogenous_lr\n",
    "                self.exogenous_component += _fitted_values\n",
    "                fitted += _fitted_values\n",
    "                resids = y - fitted\n",
    "            if i % 2: #if even get linear piece, allows for multiple seasonality fitting a bit more\n",
    "                if self.robust:\n",
    "                    tren = siegel_repeated_medians(x=np.arange(n, dtype=resids.dtype), y=resids)\n",
    "                else:\n",
    "                    if i==1 or not changepoints:\n",
    "                        tren = fast_ols(x=np.arange(n),\n",
    "                                        y=resids)\n",
    "                    else:\n",
    "                        cps = min(n_changepoints, int(.1*n))\n",
    "                        lbf = get_basis(y=resids,\n",
    "                                        n_changepoints=cps,\n",
    "                                        decay=decay)\n",
    "                        tren = np.dot(lbf, lasso_nb(lbf, resids, alpha=alpha))\n",
    "                        tren = tren * linear_lr\n",
    "                component_mse = calc_mse(y, fitted + tren)\n",
    "                if mse > component_mse:\n",
    "                    mse = component_mse\n",
    "                    fitted += tren\n",
    "                    self.linear_component += tren\n",
    "                    self.trend += tren[-2:]\n",
    "                    if i == 1:\n",
    "                        self.penalty = calc_rsq(resids, tren)\n",
    "            elif i > 4 and not i % 2:\n",
    "                if smoother is None:\n",
    "                    if seasonal_period is not None:\n",
    "                        len_check = int(max(seasonal_period))\n",
    "                    else:\n",
    "                        len_check = 12\n",
    "                    if resids[-1] > np.mean(resids[-len_check:-1]) + 3 * np.std(resids[-len_check:-1]):\n",
    "                        smoother = 0\n",
    "                    if resids[-1] < np.mean(resids[-len_check:-1]) - 3 * np.std(resids[-len_check:-1]):\n",
    "                        smoother = 0\n",
    "                    if resids[-2] > np.mean(resids[-len_check:-2]) + 3 * np.std(resids[-len_check:-2]):\n",
    "                        smoother = 0\n",
    "                    if resids[-2] < np.mean(resids[-len_check:-2]) - 3 * np.std(resids[-len_check:-2]):\n",
    "                        smoother = 0\n",
    "                    if smoother is None:\n",
    "                        smoother = 1\n",
    "                    else:\n",
    "                        resids[-2:] = cap_outliers(resids, 3)[-2:]\n",
    "                tren = ses_ensemble(resids,\n",
    "                                    min_alpha=min_alpha,\n",
    "                                    max_alpha=max_alpha,\n",
    "                                    smooth=smoother*1,\n",
    "                                    order=next(ma_cycle)\n",
    "                                    )\n",
    "                tren = tren * rs_lr\n",
    "                component_mse = calc_mse(y, fitted + tren)\n",
    "                if mse > component_mse + round_penalty * mse:\n",
    "                    mse = component_mse\n",
    "                    fitted += tren\n",
    "                    self.ses_component += tren\n",
    "                    self.trend += tren[-1]\n",
    "            if i == 0: #get deasonalized cov for some heuristic logic\n",
    "                if self.robust is None:\n",
    "                    try:\n",
    "                        if calc_cov(resids, multiplicative) > cov_threshold:\n",
    "                            self.robust = True\n",
    "                        else:\n",
    "                            self.robust = False\n",
    "                    except:\n",
    "                        self.robust = True\n",
    "\n",
    "            if i == 1:\n",
    "                resids = cap_outliers(resids, 5) #cap extreme outliers after initial rounds\n",
    "        if multiplicative:\n",
    "            fitted = np.exp(fitted)\n",
    "        else:\n",
    "            fitted = self.mean + (fitted * self.std)\n",
    "        self.multiplicative = multiplicative\n",
    "        return fitted\n",
    "\n",
    "    def predict(self, forecast_horizon, X=None):\n",
    "        last_point = self.trend[1]\n",
    "        slope = last_point - self.trend[0]\n",
    "        if self.trend_penalty and self.penalty is not None:\n",
    "            slope = slope * max(0, self.penalty)\n",
    "        self.predicted_trend = slope * np.arange(1, forecast_horizon + 1) + last_point\n",
    "        if self.seasonality is not None:\n",
    "            predicted = self.predicted_trend + np.resize(self.seasonality, forecast_horizon)\n",
    "        else:\n",
    "            predicted = self.predicted_trend\n",
    "        if X is not None:\n",
    "            for model in self.exo_model:\n",
    "                predicted += model.predict(X) * self.exogenous_lr\n",
    "        if self.const is not None:\n",
    "            predicted = np.exp(predicted)\n",
    "        else:\n",
    "            predicted = self.mean + (predicted * self.std)\n",
    "        return predicted\n",
    "\n",
    "    def optimize(self, y, test_size, n_steps, step_size=1, seasonal_period=None, metric='smape', X=None, params=None):\n",
    "        \"\"\"\n",
    "        Optimization method for MFLES\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : np.array\n",
    "            Your time series as a numpy array.\n",
    "        test_size : int\n",
    "            length of the test set to hold out to calculate test error.\n",
    "        n_steps : int\n",
    "            number of train and test sets to create.\n",
    "        step_size : 1, optional\n",
    "            how many periods to move after each step. The default is 1.\n",
    "        seasonal_period : int or list, optional\n",
    "            the seasonal period to calculate for. The default is None.\n",
    "        metric : TYPE, optional\n",
    "            supported metrics are smape, mape, mse, mae. The default is 'smape'.\n",
    "        params : dict, optional\n",
    "            A user provided dictionary of params to try. The default is None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        opt_param : TYPE\n",
    "            DESCRIPTION.\n",
    "\n",
    "        \"\"\"\n",
    "        configs = default_configs(seasonal_period, params)\n",
    "        # the 4 here is because with less than 4 samples the model defaults to naive\n",
    "        max_steps = (len(y) - test_size - 4) // step_size + 1\n",
    "        if max_steps < 1:\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    'Series does not have enough samples for a single cross validation step '\n",
    "                    f'({test_size + 4}). Choosing the first configuration.'\n",
    "                )\n",
    "            return configs[0]\n",
    "        if max_steps < n_steps:\n",
    "            n_steps = max_steps\n",
    "            if self.verbose:\n",
    "                print(f'Series length too small, setting n_steps to {n_steps}')\n",
    "\n",
    "        self.metrics = []\n",
    "        for param in configs:\n",
    "            cv_results = cross_validation(y,\n",
    "                                          X,\n",
    "                                          test_size,\n",
    "                                          n_steps,\n",
    "                                          MFLES(verbose=self.verbose),\n",
    "                                          step_size=step_size,\n",
    "                                          metric=metric,\n",
    "                                          **param)\n",
    "            self.metrics.append(cv_results['metric'])\n",
    "        return configs[np.argmin(self.metrics)]\n",
    "\n",
    "    def seasonal_decompose(self, y, **kwargs):\n",
    "        fitted = self.fit(y, **kwargs)\n",
    "        trend = self.linear_component\n",
    "        exogenous = self.median_component + self.exogenous_component\n",
    "        level = self.median_component + self.ses_component\n",
    "        seasonality = self.seasonal_component\n",
    "        if self.multiplicative:\n",
    "            trend = np.exp(trend)\n",
    "            level = np.exp(level)\n",
    "            exogenous = np.exp(exogenous) - np.exp(self.median_component)\n",
    "            if kwargs['seasonal_period'] is not None:\n",
    "                seasonality = np.exp(seasonality)\n",
    "            trend = trend * level\n",
    "        else:\n",
    "            trend = self.mean + (trend * self.std)\n",
    "            level = self.mean + (level * self.std)\n",
    "            exogenous = self.mean + (exogenous * self.std)\n",
    "            if kwargs['seasonal_period'] is not None:\n",
    "                seasonality = (seasonality * self.std)\n",
    "            trend = trend + level - self.mean\n",
    "        residuals = y - fitted\n",
    "        self.decomposition = {'y': y,\n",
    "                              'trend': trend,\n",
    "                              'seasonality': seasonality,\n",
    "                              'exogenous': exogenous,\n",
    "                              'residuals': residuals\n",
    "            }\n",
    "        return self.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfab63-842b-47b0-8a7b-942bc31923d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3cae8-f111-4163-812d-6d6e35782f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "url = \"https://raw.githubusercontent.com/tidyverts/tsibbledata/master/data-raw/vic_elec/VIC2015/demand.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df[\"Date\"] = df[\"Date\"].apply(\n",
    "    lambda x: pd.Timestamp(\"1899-12-30\") + pd.Timedelta(x, unit=\"days\")\n",
    ")\n",
    "df[\"ds\"] = df[\"Date\"] + pd.to_timedelta((df[\"Period\"] - 1) * 30, unit=\"m\")\n",
    "timeseries = df[[\"ds\", \"OperationalLessIndustrial\"]]\n",
    "timeseries.columns = [\n",
    "    \"ds\",\n",
    "    \"y\",\n",
    "]  # Rename to OperationalLessIndustrial to y for simplicity.\n",
    "\n",
    "# Filter for first 149 days of 2012.\n",
    "start_date = pd.to_datetime(\"2012-01-01\")\n",
    "end_date = start_date + pd.Timedelta(\"149D\")\n",
    "mask = (timeseries[\"ds\"] >= start_date) & (timeseries[\"ds\"] < end_date)\n",
    "timeseries = timeseries[mask]\n",
    "\n",
    "# Resample to hourly\n",
    "timeseries = timeseries.set_index(\"ds\").resample(\"H\").sum()\n",
    "timeseries.head()\n",
    "\n",
    "# decomposition\n",
    "mfles = MFLES()\n",
    "fitted = mfles.fit(y=timeseries.y.values, seasonal_period=[24, 24 * 7])\n",
    "predicted = mfles.predict(forecast_horizon=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T62OIfir7bpn",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "mfles = MFLES()\n",
    "opt_params = mfles.optimize(timeseries.y.values,\n",
    "                            seasonal_period=[24, 24 * 7],\n",
    "                            n_steps=3,\n",
    "                            test_size=24,\n",
    "                            step_size=24)\n",
    "fitted = mfles.fit(y=timeseries.y.values, seasonal_period=[24, 24 * 7])\n",
    "predicted = mfles.predict(forecast_horizon=24)\n",
    "print(opt_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
