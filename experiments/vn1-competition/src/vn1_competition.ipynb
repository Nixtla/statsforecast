{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VN1 Competition\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The VN1 Forecasting Accuracy Challenge tasked participants with forecasting future sales using historical sales and pricing data. The goal was to develop robust predictive models capable of anticipating sales trends for various products across different clients and warehouses. Submissions were evaluated based on their accuracy and bias against actual sales figures.\n",
    "\n",
    "The competition was structured into two phases:\n",
    "\n",
    "- **Phase 1** (September 12 - October 3, 2024): Participants used the provided Phase 0 sales data to predict sales for Phase 1. This phase lasted three weeks and featured live leaderboard updates to track participant progress.\n",
    "- **Phase 2** (October 3 - October 17, 2024): Participants utilized both Phase 0 and Phase 1 data to predict sales for Phase 2. Unlike Phase 1, there were no leaderboard updates during this phase until the competition concluded.\n",
    "\n",
    "In the following notebook, we'll be showcasing how to create forecasts with ETS, ARIMA, CES and Theta models from  `statsforecast` as well as using an ensemble of this models and a hierarchical reconciliation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up with uv\n",
    "\n",
    "To set up the environment using `uv`, follow these steps:\n",
    "\n",
    "1. Install `uv` if you haven't already:\n",
    "```bash\n",
    "pip install uv\n",
    "```\n",
    "\n",
    "2. Navigate to the `vn1-competition` directory:\n",
    "```bash\n",
    "cd experiments/vn1-competition\n",
    "```\n",
    "\n",
    "3. Create a virtual environment and install dependencies using uv:\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "\n",
    "4. Activate the virtual environment:\n",
    "```bash\n",
    "source .venv/bin/activate  # On macOS/Linux\n",
    "# or\n",
    ".venv\\Scripts\\activate     # On Windows\n",
    "```\n",
    "\n",
    "5. Download data\n",
    "\n",
    "```bash\n",
    "make download_data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.venv/lib/python3.12/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, AutoETS, AutoCES, AutoTheta, Naive\n",
    "from utilsforecast.preprocessing import fill_gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded data is in wide format so we transform the data in order to be used by `statsforecast`. This imply a long dataframe with columns `unique_id` denoting the time serie identifier, `ds` the date stamp and `y` the values to be forecasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_prepare_data(file_path: str, value_name: str = \"y\") -> pd.DataFrame:\n",
    "    \"\"\"Reads data in wide format, and returns it in long format with columns `unique_id`, `ds`, `y`\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    uid_cols = [\"Client\", \"Warehouse\", \"Product\"]\n",
    "    df[\"unique_id\"] = df[uid_cols].astype(str).agg(\"-\".join, axis=1)\n",
    "    df = df.drop(uid_cols, axis=1)\n",
    "    df = df.melt(id_vars=[\"unique_id\"], var_name=\"ds\", value_name=value_name)\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "    df = df.sort_values(by=[\"unique_id\", \"ds\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = read_and_prepare_data(\"../data/phase_0_sales.csv\")\n",
    "df1 = read_and_prepare_data(\"../data/phase_1_sales.csv\")\n",
    "\n",
    "df = pd.concat([df0, df1], ignore_index=True)\n",
    "df = df.sort_values(by=[\"unique_id\", \"ds\"])\n",
    "test_df = read_and_prepare_data(\"../data/phase_2_sales.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Top 5 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare the result that we get with `statsforecast` we load the predictions for top 5 competitors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_competition_forecasts() -> pd.DataFrame|None:\n",
    "    \"\"\"Reads all competition forecasts and returns it in long format with columns `unique_id`, `ds`, `y`\"\"\"\n",
    "    fcst_df: pd.DataFrame | None = None\n",
    "    for place in [\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\"]:\n",
    "        fcst_df_place = read_and_prepare_data(\n",
    "            f\"../data/solution_{place}_place.csv\", place\n",
    "        )\n",
    "        if fcst_df is None:\n",
    "            fcst_df = fcst_df_place\n",
    "        else:\n",
    "            fcst_df = fcst_df.merge(\n",
    "                fcst_df_place,\n",
    "                on=[\"unique_id\", \"ds\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "    return fcst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = get_competition_forecasts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the predictions from any prediction we provide the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vn1_competition_evaluation(forecasts: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Computes competition evaluation scores\"\"\"\n",
    "    actual = read_and_prepare_data(\"../data/phase_2_sales.csv\")\n",
    "    res = actual[[\"unique_id\", \"ds\", \"y\"]].merge(\n",
    "        forecasts, on=[\"unique_id\", \"ds\"], how=\"left\"\n",
    "    )\n",
    "    ids_forecasts = forecasts[\"unique_id\"].unique()\n",
    "    ids_res = res[\"unique_id\"].unique()\n",
    "    res = res.query(\"unique_id in @ ids_forecasts\")\n",
    "    #assert set(ids_forecasts) == set(ids_res), \"Some unique_ids are missing\"\n",
    "    scores = {}\n",
    "    for model in [col for col in forecasts.columns if col not in [\"unique_id\", \"ds\"]]:\n",
    "        abs_err = np.nansum(np.abs(res[model] - res[\"y\"]))\n",
    "        err = np.nansum(res[model] - res[\"y\"])\n",
    "        score = abs_err + abs(err)\n",
    "        score = score / res[\"y\"].sum()\n",
    "        scores[model] = round(score, 4)\n",
    "    score_df = pd.DataFrame(list(scores.items()), columns=[\"model\", \"score\"])\n",
    "    score_df = score_df.sort_values(by=\"score\")\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing\n",
    "### 3.1. Remove leading zeros \n",
    "\n",
    "There are some `unique_id` that have starting values in `0` meaning that the product wasn't present at the time, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559031</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559032</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559033</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559034</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559035</th>\n",
       "      <td>0-1-11000</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id         ds     y\n",
       "170      0-1-11000 2020-07-06   0.0\n",
       "171      0-1-11000 2020-07-13   0.0\n",
       "172      0-1-11000 2020-07-20   0.0\n",
       "173      0-1-11000 2020-07-27   0.0\n",
       "174      0-1-11000 2020-08-03   0.0\n",
       "...            ...        ...   ...\n",
       "2559031  0-1-11000 2023-12-04   5.0\n",
       "2559032  0-1-11000 2023-12-11  20.0\n",
       "2559033  0-1-11000 2023-12-18  10.0\n",
       "2559034  0-1-11000 2023-12-25   6.0\n",
       "2559035  0-1-11000 2024-01-01  15.0\n",
       "\n",
       "[183 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"unique_id == '0-1-11000'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove the leading zeros with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2123139728.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_clean = df.groupby(\"unique_id\").apply(_remove_leading_zeros).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1615437, 3), (2754699, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| warning: false\n",
    "\n",
    "def _remove_leading_zeros(group): \n",
    "    \"\"\"\n",
    "    Removes leading zeros from series \n",
    "    \"\"\"\n",
    "    first_non_zero_index = group['y'].ne(0).idxmax()\n",
    "    return group.loc[first_non_zero_index:]\n",
    "\n",
    "df_clean = df.groupby(\"unique_id\").apply(_remove_leading_zeros).reset_index(drop=True)\n",
    "\n",
    "df_clean.shape, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Identify obsolete series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some products that for a long period haven't been buyed such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1615250</th>\n",
       "      <td>9-82-9800</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615251</th>\n",
       "      <td>9-82-9800</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615252</th>\n",
       "      <td>9-82-9800</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615253</th>\n",
       "      <td>9-82-9800</td>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615254</th>\n",
       "      <td>9-82-9800</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id         ds    y\n",
       "1615250  9-82-9800 2023-12-04  0.0\n",
       "1615251  9-82-9800 2023-12-11  0.0\n",
       "1615252  9-82-9800 2023-12-18  0.0\n",
       "1615253  9-82-9800 2023-12-25  0.0\n",
       "1615254  9-82-9800 2024-01-01  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.query(\"unique_id == '9-82-9800'\").tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to identify them in order to predict 0 demand in this products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/919044482.py:11: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  obsolete_series = df_clean.groupby(\"unique_id\").apply(_is_obsolete, days_obsoletes=days_obsoletes)\n"
     ]
    }
   ],
   "source": [
    "#| warning: false\n",
    "\n",
    "def _is_obsolete(group, days_obsoletes):\n",
    "    \"\"\"\n",
    "    Identify obsolete series\n",
    "    \"\"\"\n",
    "    last_date = group[\"ds\"].max()\n",
    "    cutoff_date = last_date - pd.Timedelta(days=days_obsoletes)\n",
    "    recent_data = group.query(\"ds >= @cutoff_date\")\n",
    "    return (recent_data[\"y\"] == 0).all()\n",
    "\n",
    "days_obsoletes=180 # context-dependent \n",
    "obsolete_series = df_clean.groupby(\"unique_id\").apply(_is_obsolete, days_obsoletes=days_obsoletes)\n",
    "obsolete_ids = obsolete_series[obsolete_series].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to fit the `AutoARIMA`, `AutoETS`, `AutoCES` and `AutoTheta` models to all products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    AutoARIMA(season_length=52), \n",
    "    AutoETS(season_length=52), \n",
    "    AutoCES(season_length=52), \n",
    "    AutoTheta(season_length=52)\n",
    "]\n",
    "\n",
    "sf = StatsForecast(\n",
    "    models=models, \n",
    "    freq='W-MON', \n",
    "    n_jobs=-1, \n",
    "    fallback_model=Naive()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df_clean.unique_id.unique()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| warning: false\n",
    "fc = sf.forecast(\n",
    "    df=df_clean.query(\"unique_id in @first\"), \n",
    "    h=13\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to ensemble the models with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc['Ensemble'] = fc[['AutoARIMA', 'AutoETS', 'CES', 'AutoTheta']].median(axis=1)\n",
    "fc.loc[fc['Ensemble'] <= 1e-1, 'Ensemble'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For obsolete series we provide 0 prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.loc[fc[\"unique_id\"].isin(obsolete_ids), \"Ensemble\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluate results\n",
    "\n",
    "Now we proceed to evaluate the results from the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th</td>\n",
       "      <td>1.4175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CES</td>\n",
       "      <td>1.5778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd</td>\n",
       "      <td>1.5933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AutoTheta</td>\n",
       "      <td>1.6036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>1.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AutoARIMA</td>\n",
       "      <td>1.7497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AutoETS</td>\n",
       "      <td>1.8290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st</td>\n",
       "      <td>1.8337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd</td>\n",
       "      <td>1.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th</td>\n",
       "      <td>2.4011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model   score\n",
       "3        4th  1.4175\n",
       "7        CES  1.5778\n",
       "2        3rd  1.5933\n",
       "8  AutoTheta  1.6036\n",
       "9   Ensemble  1.6961\n",
       "5  AutoARIMA  1.7497\n",
       "6    AutoETS  1.8290\n",
       "0        1st  1.8337\n",
       "1        2nd  1.8602\n",
       "4        5th  2.4011"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts = solutions.merge(fc, on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "vn1_competition_evaluation(forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the median ensemble is much better than models by themselves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vn1-competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
